# 前言

响应徐总关于"将'核心业务应用运维管控系统(通用)'调整为'企业级运维管控平台',依托新核心运维管控平台的技术基础，采用经过生产实践验证的成熟、先进的技术体系，通过纳管现有业务系统，**提升现有业务系统在可观测性**、部署交付、应用管控及智能运维方面的能力。"成功研发实现了新一代全链路观测系统的原型。

## 核心技术架构：

- 基于新核心运维管控平台的链路追踪系统进行深度改造；

<!-- -->

- 融合《可观测性工程》理论体系，构建完整的可观测性技术栈；

<!-- -->

- 在保障现有链路系统功能稳定运行的基础上，实现了全链路监控能力的跨越式提升；

<!-- -->

- 通过纳管现有业务系统，全面提升应用系统在可观测性及智能运维方面的核心能力。

#### 什么是可观察性？

理论基础：从控制论到软件系统

可观测性（Observability）源于1960年Rudolf E.
Kálmán在控制论中的定义：通过系统外部输出推断内部状态的能力。在软件系统中，我们将这一概念扩展为：

> **可观测性是衡量您能够多好地理解和解释系统可能进入的任何状态的指标，无论这种状态多么新颖或奇异。您必须能够在不需要预定义或预测这些调试需求的情况下，通过临时迭代调查跨所有系统状态数据维度及其组合来比较调试这种奇异或新颖状态。**

可观察性是现代软件开发团队发现和理解服务中问题的方式。它为团队提供了一种方法，使他们能够根据数据提出事实调查问题、追踪线索，并全面探索事件发生期间发生的一切。可观察系统允许工程师超越预定义的监控警报，深入系统的各个领域，以寻求他们从未想过的答案。[任意宽度的结构化事件](https://www.honeycomb.io/blog/structured-events-basis-observability)是可观察性的核心，因为它们包含多达数百个事件，可以根据需要进行剖析或组合，以发现异常模式。

当前新核心的"三大支柱"：指标、日志和跟踪，是根据2020年，当时最佳实践建设的。可观察性应该提供系统的完整图像，而不仅仅是手动拼接在一起的各个部分。这三大支柱实际上不能包含真正可观察性所需的所有数据：业务指标、客户反馈以及
SDLC 中的许多其他步骤都可以为整个过程提供有价值的线索和背景信息。

### 新核心当前的监控能力

依托于技术平台APM能力，建设监控、链路、日志三大运维数据支柱，实现新核心系统整体的可观测性。

![](media/image1.png){width="4.529181977252843in"
height="2.9554199475065617in"}

监控领域基于指标、日志和追踪信息提供洞察的解决方案，已经为每种数据类型配备了单独的工具，这种方法存在不足。基于指标、日志和跟踪的传统监控并非旨在评估包含微服务、多数据库和动态基础设施的现代复杂系统。

1，指标是对特定时间发生事件的聚合测量。由于每个指标都是针对特定问题的特定答案，因此无法对其进行分解、添加或动态更改。

2，结构化日志无法提供足够的事件信息来进行探索性分析。许多日志仅提供部分事件的信息。需要通过全局业务跟踪号将多个日志条目拼接在一起，以便更好地理解单个事件。

3，链路跟踪是一系列相互关联的日志和指标，它们显示了请求或操作在系统中的移动轨迹。跟踪固然很好，但是，将错误的
全局业务跟踪号 从日志记录工具复制粘贴到跟踪工具中并发最优的处理方式。

当前以指标、日志和跟踪为基础的监控系统，需要花钱以三种不同的方式存储数据。原本应该由一个工具提供单一数据源，结果却变成了**同一数据的三个的版本。**

### 可观测性的关键特征 {#可观测性的关键特征-1}

一个真正可观测的系统应该满足以下条件：

1.  **理解内部工作原理**：能够理解应用程序的内部运行机制
2.  **处理未知状态**：能够理解系统可能进入的任何状态，包括从未见过和无法预测的新状态
3.  **外部工具查询**：仅通过外部工具观察和查询就能理解内部状态
4.  **无需新代码**：无需编写新的自定义代码来处理未知状态（这意味着您需要先验知识来解释它）

## 技术发展趋势分析

### **行业技术演进方向**

当前，可观测性已成为云原生和微服务架构的核心基础设施。Gartner预测，到2025年，70%的企业将采用可观测性平台替代传统监控工具。从技术演进角度看，传统的指标监控、链路追踪、日志监控正在向统一的可观测性平台融合，这是不可逆转的技术趋势。

### **市场需求变化**

随着业务复杂度的提升，客户对运维系统的要求已经从\"能监控\"转向\"能理解\"。传统的三大支柱（指标、日志、追踪）割裂的监控方式已无法满足现代分布式系统的需求。客户需要的是能够快速定位问题、预测故障、优化性能的智能运维平台。

## 集约化开发资源的价值

### **统一技术栈的优势**

目前团队分散在三个技术方向：指标监控、SkyWalking链路追踪定制化、日志监控。这种分散开发模式存在以下问题：

1.  **技术栈割裂**：三个系统使用不同的技术栈，维护成本高

2.  **数据孤岛**：指标、链路、日志数据关联非结构化（需要人为或外部程序二次关联）

3.  **重复开发**：告警、存储、查询等功能重复实现

4.  **运维复杂**：需要维护三套独立的系统

### **可观测系统的集约化价值**

采用可观测技术路线后，可以实现：

- **统一数据模型**：以结构化事件为核心，统一处理指标、链路、日志数据，减少数据转换和存储成本。

- **统一技术栈**：基于Flink+ClickHouse+Superset+AI的统一技术栈，降低学习成本和维护复杂度。

- **统一开发流程**：一套代码库、一套部署流程、一套运维体系，显著提升开发效率。

- **统一用户体验**：为运维人员提供统一的查询界面和分析工具，提升工作效率。

## 智能化技术路线的契合度

### **大模型+LLM的天然契合**

可观测系统与AI技术的结合具有天然优势：

- **数据基础丰富**：可观测系统采集的高维度、结构化事件数据为AI训练提供了优质的数据基础。

- **应用场景明确**：异常检测、根因分析、性能优化、容量规划等场景都有明确的AI应用价值。

- **技术架构匹配**：实时流处理架构与AI推理的实时性要求高度匹配。

### **智能化运维的竞争优势**

通过集成大模型和LLM技术，可观测系统可以实现：

- **智能异常检测**：基于历史数据训练模型，自动识别异常模式，准确率比传统阈值告警提升90%+。

- **智能根因分析**：LLM驱动的智能分析引擎，能够自动生成根因分析报告和优化建议。

- **智能容量规划**：基于历史趋势和业务预测，提供精准的扩容建议。

- **智能运维助手**：通过自然语言交互，运维人员可以快速查询系统状态和获取分析结果。

## Superset可视化模块的价值

### **数据可视化的重要性**

在可观测系统中，Superset扮演着关键的可视化角色：

- **探索性分析**：Superset强大的SQL编辑器和可视化能力，支持运维人员进行探索性数据分析，快速发现数据中的模式和异常。

- **实时监控仪表板**：基于ClickHouse的高性能查询能力，Superset可以构建实时更新的监控仪表板，提供系统状态的直观展示。

- **多维度分析**：支持任意维度的数据切片和钻取，满足复杂业务场景的分析需求。

- **用户友好界面**：拖拽式操作界面，降低运维人员的使用门槛，提升工作效率。

### **技术架构优势**

- **高性能查询**：Superset与ClickHouse的深度集成，支持亚秒级的复杂查询响应。

- **丰富的可视化**：从简单图表到复杂地理空间可视化，满足不同场景的展示需求。

- **权限管理**：支持细粒度的安全角色控制，确保数据安全。

- **缓存机制**：智能缓存机制减轻ClickHouse负载，提升查询性能。

降低硬件成本和运维成本

## 和云建智能运维可观测系统的关系

云建系统和管控平台有各自的优点、各自最适用领域以及它们可以进行相互补充。**软件层面由管控平台的应用可观测系统覆盖。软件**是指实现业务功能，运行生产服务，具备客户价值的代码。**系统由云建的系统覆盖。系统**是一个涵盖所有底层基础设施和运行时环境的总称。系统是您的业务为了支持软件运行而必要的东西。系统包括基础设施，从数据库（例如，Postgresql或clickhouse）到计算和存储（例如，容器或虚拟机）再到中间件（kafka、es、HAproxy、redis、flink）任何必须在使用软件进行部署和运行之前进行配置和设置的其他一切。

互相补充。将云建的epbf数据关联到链路中，可以大大增强系统的可观测能力，同时最大程度发挥云建系统数据价值。

## 功能、性能验证人力需求2人3个月

代码需要适配测试环境，包依赖调整、例如适配flink1.18，适配测试环境kafka、clickhouse；需要熟悉测试环境、java开发、flink开发的人员对接；预估总工期半年，

- 1人做环境保障：搭建并保障测试环境flink环境、kafka、clickhouse环境，预估需要2个月时间专职搭建、保障、调优；

- 1人做代码开发，包括版本管理以及适配测试环境开发。前期适配测试环境数据，进行代码改造3个月。

## **应用智能可观测性系统的硬件成本优化优势**

传统的应用监控系统需要部署多套独立硬件：业务指标监控的采集服务器、汇聚计算节点、TSDB节点。而应用智能可观测性系统通过统一的Segment事件数据，实现了交易量、成功率、响应时间等所有业务指标的实时监控，仅需汇聚计算、ClickHouse存储集群即可替代传统应用指标监控模块。这种基于可观测性的统一监控方案不仅节省了硬件成本。

## **电力成本优势**

传统监控系统采用固定频率采样（每5秒、60秒），无论是否有业务交易都需要持续消耗电力进行数据采集和处理，造成大量无效能耗。而本系统采用\"有交易才采样\"的事件驱动模式，只有在实际业务交易发生时才会进行数据采集和汇聚，无交易时系统处于低功耗状态。这种按需采样的机制不仅大幅降低了CPU、内存、存储和网络设备的电力消耗，还避免了传统监控系统在业务低峰期（如夜间）的无效采样浪费。通过事件驱动的智能采样策略，可观测性平台在保证监控完整性的同时，实现了电力成本的显著优化，特别适合业务量波动较大的数据中心环境，为绿色数据中心建设提供了技术支撑。

## **对年轻人培养的价值**

我们的系统采用业界最新的可观测性工程实践，集成了Flink流处理、ClickHouse列式存储、多LLM智能分析等前沿技术栈，为年轻开发者提供了接触最新科技潮流的绝佳机会。通过参与这个项目，年轻人能够掌握从传统监控到智能可观测性的技术演进路径，学习事件驱动架构、实时流处理、AI辅助运维等未来技术趋势。平台中的AI编程助手集成、动态阈值生成、智能根因分析等创新功能，让年轻人在实践中体验AI与运维的深度融合，培养面向未来的技术思维。这种前沿技术实践不仅提升了技术竞争力，更重要的是培养了适应数字化转型时代的技术敏感度和创新能力，为年轻人在可观测性、AIOps、云原生等热门技术领域的职业发展奠定了坚实基础，使其在激烈的技术竞争中保持领先优势。

## 硬件需求

每秒 20,000 TPS，每条链路数据约 4KB

实时链路数据流：Flink + Kafka + ClickHouse

需考虑高可用、可扩展、生产环境

1\. 数据量估算

每秒数据量：20,000 × 4KB = 80MB/s

每小时数据量：80MB × 3600 ≈ 288GB

每天数据量：288GB × 24 ≈ 6.9TB

2\. Kafka

Broker 数量：生产 5 台以上，分区数 ≥ Flink 并行度

单台配置：

CPU：8-16 核

内存：32-64GB

磁盘：NVMe SSD，单台 2TB 以上，Raid10/独立盘

网络：万兆

分区数： 48-96 分区（分区数 ≥ Flink 并行度，便于扩展）

3\. Flink

JobManager：2 台（主备）

CPU：4-8 核

内存：16-32GB

TaskManager： 6-10 台

CPU：16-32 核/台

内存：64-128GB/台

每台 4-8 个 slot（并行度总和 ≥ Kafka 分区数）

磁盘：本地 SSD（如有 RocksDB State Backend）

总并行度： 48-96（与 Kafka 分区数一致）

4\. ClickHouse

节点数：5 台（分布式表+副本，生产 5 台以上）

单台配置：

CPU：16-32 核

内存：128-256GB

磁盘：NVMe SSD，单台 4TB 以上

网络：万兆

表设计：MergeTree/ReplicatedMergeTree，分区+分片+副本，合理设置
TTL、索引、压缩

## 总结

可观测技术路线不仅符合技术发展趋势，更能实现团队开发资源的集约化，并为智能化运维奠定基础。通过统一的技术栈、丰富的AI应用场景、广阔的发展前景，可观测系统将为团队带来显著的技术价值和成长机会。建议团队抓住这一技术转型机遇，在可观测性领域建立技术优势，为未来的智能化运维时代做好准备。

## 如何实现应用可观测性

### 基于新核心体系架构进行扩展

继承当前新核心链路系统的体系结构，并进行如下扩充

### 获取事件

事件是特定的请求与服务交互时的所有信息的记录。

可观察性的核心在于根据系统输出的遥测数据了解系统的内部状态，以便有效地排除故障、调试和调优性能。然而，人们倾向于将可观察性简化为日志、指标和跟踪的集合，这会剥夺用户了解当前情况所需的大部分可见性。相反，可观测性将结构化事件视为基石，并将事件的跟踪数据拼接在一起，以便用户能够直观地看到趋势和模式。

结构化广泛事件是实现可观察性的唯一方法。

在skywalking中事件单位可以是一个trace
segment，即一笔交易在一个线程中所有执行信息的记录。一个trace
segment里面只有一个entry span，可以有多个local
span，如果有多次外调那么会有多个exit sapn。（关系有图）

一个完整的链路由多个trace segment组成。

根据skywalking的链路实现，可以在entry span中写入业务代码的运行环境信息。

如图可以展示一笔交易在一个服务中执行的详细信息：dubbo协议的信息、应用的配置信息、容器环境的信息、容器镜像的id、自身执行时间（图二中的70ms）、消息再基础设施间的传递耗时（图二中的3ms）。

#### 集成自动化探针以及自定义tag

Skywalking java
agent能在应用代码不做出修改的情况下通过动态字节码编辑技术就能实现。也就是说如果原始的应用可以不做出任何修改，仅通过安装skywalking
apm包，并配置启动参数javaagent就能实现应用链路追踪能力。

一旦有了自动化探针，我们就有了坚实的基础。接下来可以应用中添加自定义的字段和数值。可以通过在项目中引入apm-toolkit-trace、apm-toolkit-opentracing，并在代码中像写日志一样调用ActiveSpan.tag(key,
value)就能写入一些和交易相关的信息，例如客户id、dus
id、错误堆栈等。这些自定义的探针可以实时地验证代码是否按希望的那样在生产环境中运行。也实现了可观测性驱动开发即左移。这些自定义的tag可以是数十个或者数百个。这一个个tag都将作为一个宽表的字段出现，使用我们的分析工具可以快速的定位问题根因。哪些信息需要记录呢？可以回溯交易执行过程的信息都应该记录。可以是操作系统中环境变量，环境变量可能包含丰富的执行环境信息，有助于还原故障时代码的执行行为。

1.  Map\<String, String\> envVars = System.getenv();

2.  for (Map.Entry\<String, String\> entry : envVars.entrySet()) {

3.      ActiveSpan.tag(\"env.\" + entry.getKey(), entry.getValue());

4.  }

也可以是rpc的上下文信息，其中也包含了丰富的信息，如调用的参数、rul、传递的head等等。HTTP相关、数据库相关、错误相关、服务相关、性能指标、资源消耗、用户信息、上下文信息、业务相关、自定义标签。见附录。通过合理地设置
span 的
tag，可以帮助开发者和运维人员更好地理解系统的行为、快速定位问题并优化性能。

OpenTelemetry是怎么做的呢？如图，应用程序集成 OpenTelemetry
SDK后，会使用OpenTelemetry 协议
(OTLP)，这些收集器将遥测信号发送到与应用程序一起运行或与应用程序位于同一主机上的
collector 实例（sidecar）。collector 再转发给主机外部的backends。

#### 高基数：用数字类型的tag

高基数和高维已经从晦涩的技术概念变成了实现系统可观察性的技术要求的前沿。高基数数据在可观测性中具有双重作用：既为精细化分析提供支持，又对存储、查询和性能提出挑战。高基数数据的核心价值在于

- 提升细粒度分析能力

多维度根因定位：\
高基数数据（如用户Id、设备ID、请求ID、单元ID）可作为标签（Tag），允许从多维度（地域、版本、用户类型）切分指标。通过主机、服务、单元、定位异常行为发生的确切位置。

精准业务洞察：\
结合用户ID（高基数），可分析用户的操作延迟，优化核心业务链路。

- 支持复杂场景的可观测性需求

AI 大模型训练监控：\
大模型训练任务中，每个GPU节点、训练批次（Batch）的ID均为高基数数据，用于分析硬件利用率、梯度异常等细粒度问题。

分布式追踪深度关联：\
链路追踪中的TraceID（唯一标识符）属于典型高基数数据，结合SpanID可还原单次请求的全生命周期状态，实现跨服务故障溯源。

高基数的实现路径。指标不具备处理多维度高基数数据的能力，如果一个指标的tag中出现一个高基数域，那么对存储、缓存的要求是指数级增长。

#### 高维度：将事件存储为宽表

可观测性的基本原理------任意宽度的结构化事件是系统的基本构建块，因为它们提供了适当级别的细粒度数据来调试应用程序的任何状态。任意宽度的结构化事件每个事件都包含数十到数百个维度，这些维度不仅可以根据各个方面进行切片，还可以串联起来，以帮助发现异常值和共性。

与日志记录（事件详细信息分散在多个日志行中）相比，无需猜测事件是否是暂时或实际相关的，因为所有信息都来自同一个数据块。

可观测性的核心在于处理任意宽度的结构化事件。当请求进入服务时，系统会初始化一个映射，并预先填充所有已知或推断出的与该请求相关的信息。当请求即将退出或出错时，系统会将其发送到一个任意宽度的结构化事件中，对于成熟的已检测服务，通常每个事件包含
100 个维度。

由于可观测系统存储并查询原始数据，因此不会错过关键信息，这些信息在指标和日志系统中则可能没有，并且终可以通过将事件后聚合，形成时间序列。

该框架还支持分布式跟踪，可以跟踪单个请求在由组成应用程序的各种服务处理过程中的进展。毕竟，通过将跟踪、跨度和父标识符存储为维度，可以将事件转换为跟踪。Honeycomb
保留了事件的上下文和粒度，因此用户可以组装跟踪视图来可视化日志数据并发现模式。这对于微服务来说尤其重要，因为微服务更难精确定位故障发生的位置以及可能导致性能下降的原因。

如果用户正在寻找可观察性产品，请确保它基于任意长度的结构化事件或跨度。如果不是，它就无法按高基数维度对数据进行切片------最终只能算作一种貌似漂亮的指标。

### 数据可视化

采用Apache superset实现数据可视化。Superset
是一个数据探索和数据可视化平台。Superset
能够与clickhouse数据源良好集成。

- 用于快速构建图表的无代码界面

- 功能强大的基于 Web 的SQL 编辑器，用于高级查询

- 用于快速定义自定义维度和指标的轻量级语义层

- 各种精美的可视化效果可用于展示您的数据，从简单的条形图到地理空间可视化

- 轻量级、可配置的缓存层有助于减轻数据库负载

- 高度可扩展的安全角色和身份验证选项

- 用于程序化定制的API

![IMG_256](media/image2.png){width="5.764583333333333in"
height="4.441666666666666in"}

根据链路数据实现的试图

![](media/image3.png){width="5.761111111111111in"
height="1.448611111111111in"}

![](media/image4.png){width="5.759027777777778in"
height="1.4493055555555556in"}

#### 采用Flink处理链路数据

采用 Flink 处理链路（SkyWalking Segment）数据的大致流程：

##### 整体流程

1.  Kafka 采集链路数据

SkyWalking Agent 通过 Kafka Reporter 将链路追踪数据（SegmentObject）写入
Kafka topic（如 topic-dics-long-skywalking-segments）。

2.  Flink 消费 Kafka 数据

Flink 作业（如 FlinkKafkaToClickHouseJob）通过 KafkaSource 并行消费
Kafka 中的 SegmentObject 数据，支持分区扩容和 offset 容错。

3.  数据解析与处理

使用自定义的 SegmentDeserializationSchema 反序列化 Kafka 消息为
SegmentObject。

通过一系列 Flink Operator（如
AvgSpanDurationAggregateFunctionOperator、DubboEntryAvgDurationAggregateFunctionOperator
等）对链路数据进行实时聚合、统计、过滤等处理。

4.  数据写入 ClickHouse

处理后的数据通过 SimpleClickHouseSink 批量写入
ClickHouse，实现高效的链路数据落库和分析。

5.  动态表结构管理

通过 NewKeyTableSyncTask 等机制，自动同步链路数据中的新字段到 ClickHouse
表结构，保证数据 schema 动态扩展。

##### 重点实现内容

1.  KafkaSource 配置与分区兼容

支持分区动态扩容保证新分区自动消费。如果没有提交offset就从最新消息消费。

.setStartingOffsets(OffsetsInitializer.committedOffsets(OffsetResetStrategy.LATEST))

并行度与分区数一致，充分利用 Kafka 吞吐。

2.  链路数据反序列化

自定义 SegmentDeserializationSchema，将 Kafka 字节流高效转为
SegmentObject，便于后续处理。

3.  多种实时聚合算子

通过 FlinkOperator 接口和
OperatorRegistry，灵活注册多种链路聚合算子（如平均耗时、最大耗时、分组统计等）。支持窗口聚合（如
7 秒窗口），并可自定义窗口长度。

4.  高效 ClickHouse Sink

SimpleClickHouseSink
支持批量写入、动态字段补全、异常重试等，保证数据高效、可靠入库。

5.  动态表结构与字段同步

NewKeyTableSyncTask 定时扫描新字段并自动 ALTER TABLE，适应链路数据
schema 动态变化。

6.  高可用与容错

启用 Flink Checkpoint，保证消费 offset 和数据处理的 exactly-once
语义。支持 Flink 作业重启、Kafka 分区扩容、offset 丢失等场景的自动恢复。

##### 典型代码结构

- application.yaml：集中管理 Kafka、ClickHouse、批量参数等配置。

- FlinkKafkaToClickHouseJob.java：主作业入口，负责环境初始化、Source/Sink/Operator
  注册、作业启动。

- operator 目录：各类链路聚合算子实现。

- sink 目录：ClickHouse Sink 实现。

- task 目录：表结构同步等后台任务。

##### 重点注意事项

- Kafka topic 分区扩容后需重启 Flink 作业，或确保 Source
  支持新分区自动消费。

- Flink 并行度建议与 Kafka 分区数一致，保证消费均衡。

- 动态表结构同步要做好异常处理，防止 ClickHouse ALTER TABLE
  失败导致数据丢失。

- Checkpoint 配置合理，保证作业高可用和数据一致性。

##### 算子参数存储

在大数据/Flink/流批一体等生产环境中，算子参数的最佳实践存储与管理方式如下：

1\. 配置中心/参数表（推荐）

数据库表（如 MySQL、ClickHouse、PostgreSQL
等）：集中存储所有算子参数，支持动态变更、热加载、权限管控，适合企业级多任务多算子统一管理。

配置中心（如
Apollo、Nacos、Zookeeper、Consul）：适合大规模分布式场景，支持参数动态推送、灰度、分组、版本管理。

2\. 配置文件

application.yaml/properties/json：适合参数量少、变更不频繁的场景，易于本地开发和小型项目。

缺点：参数变更需重启，难以动态管理。

3\. 环境变量/启动参数

适合敏感参数（如密钥、连接串）或容器化部署，便于与 CI/CD、K8s 配合。

推荐用数据库表或配置中心，表结构建议包含：命名空间(namespace)、算子类(operatorClass)、参数名(paramKey)、参数值(paramValue)、版本、描述等字段。

支持多值参数（如同一 paramKey 多行），便于扩展。

算子初始化时动态加载参数，支持参数热更新或定时刷新。

重要参数变更应有审计、回滚、权限控制。

具体实现：

Flink 原生的 DataStream API 下，算子参数"立即刷新"通常有两种主流方案：

方案一：Broadcast State（推荐，Flink官方最佳实践）

参数表变化时，通过定时 Source 或 CDC（如 Flink
CDC、定时轮询）读取参数表，将参数作为广播流（BroadcastStream）下发。

主业务流与参数广播流 connect，业务流每条数据处理时都能拿到最新参数。

参数变更后，所有算子实例自动感知并应用新参数，无需重启。

##### 每次从上次没有消费的记录开始消费

让 Flink KafkaSource 每次从"上次未消费的记录"开始消费（即断点续传）：

1.  setStartingOffsets(OffsetsInitializer.committedOffsets())，这样会优先从
    Kafka 的 groupId 已提交的 offset 处恢复消费。

2.  保证 groupId 配置唯一且稳定，不能频繁变更，否则会导致 offset
    记录丢失。

3.  Flink Checkpoint 必须开启，这样即使 Flink 任务重启，也能从最近一次
    checkpoint 的 offset 恢复。代码中启用
    Checkpoint（建议加在主类初始化后）：env.enableCheckpointing(60000);
    // 60秒一次，可根据实际调整。要检查 Docker Flink 是否已开启
    Checkpoint，需要：查看 Flink Web UI（一般
    http://localhost:8081），Job 详情页会显示 Checkpoint 状态。检查
    JobManager/TaskManager 日志，搜索 checkpoint 相关日志。检查 Flink
    任务代码是否有 enableCheckpointing 调用。在 Flink Web UI 查看当前
    Job 的 Checkpoint 状态。

4.  Kafka 端要开启 offset 自动提交（Flink 默认会在 checkpoint 时提交
    offset）。在 Flink 原生 KafkaSource 场景下，offset 自动提交由 Flink
    框架在 Checkpoint 时自动完成，无需在 Kafka 端单独配置
    enable.auto.commit=true。使用 KafkaSource +
    enableCheckpointing）已经满足生产级 offset 管理要求：Flink 会在每次
    Checkpoint 成功后自动将 offset 提交到 Kafka（EXACTLY_ONCE
    语义）。无需在 Kafka 配置中手动设置 enable.auto.commit，Flink
    会忽略该参数。

    实践总结：

- 只需保证 Flink 任务已开启 Checkpoint。

- KafkaSource 的 group.id 保持稳定。

- 不需要在 application.yaml 的 kafka 配置里加 enable.auto.commit
  相关参数。

  FlinkKafkaToClickHouseJob.java 代码中没有任何关于 checkpoint 的配置。

  这意味着 Flink 默认是不开启 checkpoint 的，Kafka offset
  也不会被周期性提交，只有作业正常停止时才会提交 offset。

#####  Flink Checkpoint 与 kafka 的 setStartingOffsets 是两个不同的机制

Flink Checkpoint 和 Kafka 的 setStartingOffsets
是两个不同的机制，但它们都影响 Flink 消费 Kafka 的起始 offset。

1.  Flink Checkpoint

- 是 Flink 的容错机制，定期保存作业状态（包括 Kafka offset）。

- 用于作业恢复、故障自动回滚，保证 exactly-once 或 at-least-once 语义。

- 优先级最高，恢复时直接用 Checkpoint 里的 offset。

2.  Kafka setStartingOffsets

- 是 KafkaSource 的起始 offset 策略（如
  committedOffsets、earliest、latest）。

- 只在没有可用 Checkpoint 时才生效（如首次启动、Checkpoint 丢失）。

- 决定"首次"或"无状态恢复"时从哪里开始消费。

两者机制不同，作用不同；Checkpoint 优先，setStartingOffsets
兜底；推荐生产环境两者都配置，保证健壮性和自动恢复。

##### 实现算子高效管理

算子（operator）、sink、serde、util
分包，主类只做组装是流式计算平台的主流架构模式。这种方案的核心优势如下：

- 高内聚低耦合：每个 operator、sink、serde、util
  都是独立包和类，便于单独开发、测试、维护和复用。

- 主类极简：主类（如
  FlinkKafkaToClickHouseJob）只负责流的组装、参数加载和算子链拼接，不承载具体业务逻辑，后续扩展不会导致主类膨胀。

- 易于扩展和团队协作：新增算子、sink
  只需实现新类并注册，主流程无需大改，适合多人协作和业务快速演进。

- 参数与算子解耦：参数通过配置/参数表/热刷新机制动态注入，算子只依赖参数接口，便于动态调整和生产运维。

便于自动化测试和 CI/CD：每个算子、sink
都可独立单测，主流程可做集成测试，保障系统稳定性。

分层分包、主类只做组装的 Flink 项目结构：

1.  operator 注册表（OperatorRegistry），支持自动注册和遍历所有算子。

2.  每个算子实现统一接口（如 FlinkOperator），便于主类自动组装。

3.  主类 main 方法通过注册表自动组装所有算子链和 sink，极简、可扩展。

##### SimpleClickHouseSink Simple 的意思

以 simple
开头是为了表达"简单实现/基础功能"，便于与后续可能的复杂版本区分，提升代码可读性和维护性。

1.  强调实现简单\
    "Simple"前缀表示该 Sink 实现逻辑相对简单、基础，功能上只做了最核心的
    ClickHouse 批量写入，没有复杂的容错、幂等、分布式协调等高级特性。

2.  区分复杂版本\
    项目中可能会有更复杂或功能更全的 ClickHouseSink（如支持动态
    schema、分布式事务、异步写入等），用 simple
    命名可以和这些复杂版本区分开。

3.  便于维护和扩展\
    如果后续需要实现 AdvancedClickHouseSink、AsyncClickHouseSink
    等，simple
    命名有助于代码结构清晰，开发者一眼能看出该类是"基础版"实现。

##### 动态表结构

无法预知span中会有哪些tag。所以需要适应随时出现的新的tag。新的tag总是会增强系统的可观测性。所以需要增加根据
segmentObject中span中tags 中，新出现的tag key，为其在 events
表中新增该字段，以便记录其 value 到 events 表中。实现步骤如下：

1.  在clickhouse 中新建表new_key

    CREATE TABLE new_key

    (

        keyName String,

        keyType String,

        isCreated Boolean,

        createTime DateTime

    )

    ENGINE = MergeTree()

    ORDER BY keyName;

    如果突然出现很多新tag
    key，那么可能会频繁修改表结构，导致数据库写入segmentObject
    的性能降低，使得监控告警失效，那么要把出现的新tag
    key缓存到clickhouse的 new_key 表中。

    新建一个flink 定时任务，读取该表并执行修改表结构动作，为新的tag
    key新增列，然后修改 isCreated 字段为 true。

##### 表结构变化通知所有 SimpleClickHouseSink 重新初始化数据库

- 集中式通知机制

新建一个全局的"表结构变更事件"发布/订阅机制（如单例的
TableSchemaChangeNotifier）。

每个 SimpleClickHouseSink 在 open 时注册监听器，收到变更通知时调用
databaseService.initConnection()。

- 实现方式举例

TableSchemaChangeNotifier 提供
registerListener/unregisterListener/notifySchemaChanged 方法。

NewKeyTableSyncTask 或其它表结构变更操作后，调用 notifySchemaChanged。

SimpleClickHouseSink 内部实现
TableSchemaChangeListener，收到回调时安全地重连。

- 线程安全与幂等

通知回调需线程安全，且重连操作要防止并发和重复。如静态单例、Spring
事件、Flink 广播等。

##### 把flink算子参数保存在kafka中

Flink 支持将算子参数（如 serviceNames、spanType 等）以配置流的形式保存在
Kafka（或其他消息队列）中。这样可以实现参数的实时热更新，常见做法如下：

1.  配置参数以 JSON、Map 等格式写入 Kafka 的某个 topic。

2.  Flink 用 SourceFunction（如 FlinkKafkaConsumer）消费该
    topic，形成参数流 DataStream。

3.  用 Broadcast State 将参数流广播到所有算子实例，业务流和参数流
    connect，业务流每次处理时读取最新参数。

优点：

- 参数变更只需向 Kafka 写入新配置，无需重启 Flink 作业。

- 支持多种参数来源（Kafka、数据库、配置中心等）。

  ParamConfigSource 是从 ClickHouse 拉取参数，也可以用
  FlinkKafkaConsumer 从 Kafka 拉取参数，方式一致。

  Kafka 作为参数热更新的配置流来源，是 Flink
  实践中非常常见且推荐的方案。

##### 算子参数热更新

在 Flink 中，算子的参数（如 serviceNames、spanType 等）如果直接通过
apply
方法传递，是静态的，无法在作业运行时热更新。要实现"参数热更新"，常见做法如下：

方案一：参数广播 + 配置流

1.  参数流：将参数（如 serviceNames、spanType）通过
    Kafka、配置中心等方式作为一条流输入 Flink。

2.  Broadcast State：用 Flink 的 Broadcast
    State，将参数流广播到所有算子实例。

3.  Connect：主数据流（业务数据）与参数流
    connect，业务流在处理时动态读取最新参数。

方案二：外部存储轮询

算子内部定时从外部存储（如
Redis、ZK、配置中心）拉取参数，更新本地变量。推荐实现（Broadcast State
示例）

1.  新增参数流（如 Kafka 配置 topic）。

2.  用 BroadcastProcessFunction 处理业务流和参数流。

3.  参数流更新时，自动推送到所有算子实例，达到热更新效果。

通过 Broadcast State，可以实现参数的实时热更新，且对 Flink
作业无感知，将参数流和业务流解耦，参数变更时无需重启作业。每次业务流（主流）处理一条数据时，都会从
Broadcast State 读取一次参数（即"每次处理业务前都读取最新参数"）。但
Broadcast State
本身是高效的本地状态存储，读取开销极小，不会像远程拉取那样有性能瓶颈。当参数流有新数据到来时，Flink
会自动更新 Broadcast State，后续业务流处理时就能用到最新参数。

##### Broadcast State 读取一次参数和读取本地变量的开销对比

不是完全一样，但非常接近。

- Broadcast State 在 Flink 里是 TaskManager 本地的 RocksDB/Heap
  状态，属于"本地状态"，读取速度极快，远高于远程存储（如 Redis、ZK）。

- 读取 Broadcast State 的开销，比直接读取 Java
  普通本地变量（如成员变量、静态变量）略高，因为需要通过 Flink 的 State
  API（如 ctx.getBroadcastState(\...)）做一次状态查找。

- 但这个查找是本地内存/本地
  RocksDB，通常是微秒级，绝大多数业务场景下可以认为"几乎等同于本地变量读取"，不会成为性能瓶颈。

结论：

Broadcast State
读取参数的开销，比普通本地变量略高，但远低于远程拉取，绝大多数场景下可以忽略不计。只有极致低延迟、极高
QPS 的场景下才需要关注。对于大部分 Flink 业务，完全可以放心使用
Broadcast State 实现参数热更新。

##### 算子参数热更新

大数据/流式系统中常见的"参数中心+变更通知"模式，参数放到 clickhouse
中，如果参数更新了，则放一条消息到 kafka topic，算子订阅
topic，收到更新消息则刷新参数。

方案流程：

1.  参数主存储在 ClickHouse param_config表中，保证参数持久化和历史可查。

2.  实现参数的增删改的方法。

3.  参数变更后，向 Kafka topic
    推送一条"参数变更通知"消息（可只包含变更key、时间戳、或简单标识）。

4.  Flink 算子订阅 Kafka topic，收到变更消息后，主动去 ClickHouse
    重新加载最新参数，刷新本地缓存。

5.  参数未变更时，Flink 算子不会频繁访问
    ClickHouse，只有收到通知才刷新，性能和一致性兼顾。

    优点：

- Kafka 只做"变更通知"，消息丢失或过期也没关系，参数永远以 ClickHouse
  为准。

- 参数可持久化、可审计、可回溯，且支持大批量参数。

- Flink 作业参数热更新。

- 支持多种消费端（不仅 Flink，其他服务也可订阅变更）。

  实现建议

- Kafka topic 可只存变更通知（如
  operatorName、version、timestamp），不必存全量参数。

- Flink 算子收到通知后，调用 OperatorParamLoader.loadParamList(db,
  operatorName) 重新加载参数。

- 可用 BroadcastProcessFunction 或自定义 SourceFunction
  实现参数刷新逻辑。

- 变更通知消息可加防抖/去重机制，避免频繁刷新。

##### 算子共享 kafka 数据流

SimpleClickHouseSink、DubboEntryAvgDurationAggregateFunctionOperator、AvgSpanDurationAggregateFunctionOperator
都称为 Flink 的"算子"（Operator），分别对应不同的处理逻辑或 Sink。

在 FlinkKafkaToClickHouseJob 代码中，这些算子是"共享同一个 Kafka
数据流"：

1.  通过 env.fromSource(kafkaSource, \...) 得到一个
    DataStream\<SegmentObject\>，即 Kafka 的主数据流。

2.  这个主数据流被分别传递给：stream.addSink(new
    SimpleClickHouseSink(\...))，直接写入 ClickHouse。

3.  以及所有注册到 OperatorRegistry 的 FlinkOperator（如
    AvgSpanDurationAggregateFunctionOperator、DubboEntryAvgDurationAggregateFunctionOperator），通过
    op.apply(stream, params) 进行处理。

这些算子都是基于同一个 Kafka
数据流（stream）进行各自的处理或下游写入。每个算子/下游 Sink
都会独立消费和处理这份流，不会互相影响。它们都消费同一个 Kafka
数据流，各自独立处理。

**TumblingEventTimeWindows与TumblingProcessingTimeWindows\**
flink
算子汇聚计算7秒窗口内数据。如果kafka数据已经积累了很多历史未消费数据，那么启动flink
任务时 7秒内有大量数据在同一个窗口，大量历史未消费数据，Flink
任务启动时会从最早的 offset 开始消费（如配置为
earliest），此时7秒窗口会聚合"消费到的所有数据"，而不是"真实产生的7秒内的数据"。

也就是说，窗口的划分是基于 Flink
的处理时间（ProcessingTime），而不是数据的事件时间（EventTime）。如果短时间内消费了大量历史数据，这些数据会被分配到
Flink 当前的 7 秒窗口，导致窗口内数据量异常大，窗口聚合结果也会异常。

启动初期，窗口聚合的数量和结果会很大（因为历史数据都被分配到当前窗口）。

等历史数据消费完，窗口才会恢复到"每7秒聚合实时数据"的正常状态。

解决方法：用事件时间（EventTime）+ watermark 做窗口，并设置 Kafka
offset。

- TumblingEventTimeWindows

定义：基于"事件时间"（event
time）的滚动窗口。事件时间是数据本身携带的时间戳（如日志时间、业务时间），窗口的触发依赖于
watermark（水位线）的推进。

应用场景：

数据流的时间戳与实际业务发生时间密切相关，需要严格按照业务时间分窗。

需要处理乱序、延迟到达的数据（如日志分析、用户行为分析等）。

需要保证窗口统计结果与真实业务时间对齐。

注意：watermark 推进慢或数据乱序严重时，窗口可能迟迟不触发。

- TumblingProcessingTimeWindows

定义：基于"处理时间"（processing time）的滚动窗口。处理时间是 Flink
任务节点的系统时间，窗口的触发只依赖于机器当前时间。

应用场景：

对实时性要求高，允许一定的统计误差（如实时监控、简单指标统计）。

数据时间戳不重要，或者数据时间戳不可用。

只关心"现在"窗口周期性输出，无需对齐业务时间。

注意：结果受机器时间影响，不能处理乱序和延迟数据。

如果只关心"每隔7秒输出一次当前窗口的平均耗时"，且不在意数据的业务时间戳（startTime），用
TumblingProcessingTimeWindows 更简单、稳定。

如果需要"严格按照 Entry span 的 startTime
分窗"，保证统计与业务时间对齐，且能正确设置 watermark，应该用
TumblingEventTimeWindows。

当前用的是
TumblingProcessingTimeWindows，适合实时性强、对业务时间不敏感的场景。

##### **forBoundedOutOfOrderness 具体含义和设置建议**

他是 Flink
事件时间处理中的一个重要参数，用于设置最大乱序容忍时间，即允许数据流中事件时间与实际到达时间的最大延迟。

具体含义

- WatermarkStrategy.forBoundedOutOfOrderness(Duration
  maxOutOfOrderness)表示 Flink 认为数据最多会乱序 maxOutOfOrderness
  这么长时间。

- Flink 会以 **当前已见最大事件时间** - maxOutOfOrderness
  作为水位线（watermark），只有事件时间小于水位线的数据才会被视为"迟到数据"。

- 这个参数不是窗口大小，而是窗口何时可以安全关闭、下游何时可以触发计算的依据。

设置建议

- 建议设置为实际乱序最大值的1.5\~2倍，以保证绝大多数数据都能被窗口正确处理。

- 如果你的数据流乱序很小（如绝大多数数据延迟不超过5秒），可以设置为10秒。

- 如果链路复杂、网络抖动大，建议先统计实际乱序分布，再设置（如30秒、60秒等）。

- 设置过大：窗口聚合、下游输出延迟变高，实时性变差。

- 设置过小：乱序数据容易被丢弃，数据完整性变差。

实际举例

- 你设置
  forBoundedOutOfOrderness(Duration.ofSeconds(10))，表示允许事件最多乱序10秒。

- 如果你设置
  forBoundedOutOfOrderness(Duration.ofSeconds(120))，则允许乱序2分钟，窗口会等更久才触发。

总结

- 核心作用：控制乱序数据的最大容忍时间，影响窗口聚合的延迟和数据完整性。

- 设置建议：根据实际数据乱序情况设置，常用10\~30秒，极端场景可适当放大。

如需更精确建议，可以先采集一段时间的事件时间与到达时间差异，统计最大乱序延迟后再设置。

##### **以 span的结束时间为业务时间窗口的事件时间**

在链路系统（如分布式追踪、APM、调用链分析等）中，以 span
的结束时间（endTime）作为业务时间窗口的事件时间是更合理的选择。

1.  业务完成的真实时刻

只有 span 结束，业务才真正完成。以 endTime
作为事件时间，统计的就是"在某个时间段内真正完成的业务量、耗时、错误率"等。

2.  避免提前统计未完成业务

如果用 startTime，窗口可能会提前统计还未完成的业务，导致数据不准确。

用 endTime，可以确保窗口内的都是已经完成的业务。

3.  与实际监控/告警需求一致

绝大多数 SLA、告警、报表等，都是以"完成时刻"为准。

4.  乱序影响更小

某些 span 可能很早开始但很晚才结束，用 endTime
能更好地反映真实的业务完成分布。

在 Flink 事件时间窗口（如
TumblingEventTimeWindows）中，timestampAssigner 应提取 span 的 endTime
作为事件时间。链路系统中，以 span 的 endTime
作为事件时间进行窗口聚合，是最符合业务语义和监控需求的做法。

##### Keyby 高基数字段

高基数字段（如 traceId、orderId、userId 等）用来做
keyBy，可以让数据更均匀地分布到所有分区（subtask）上，充分利用 Flink
的并行计算能力。

- 高基数字段：唯一值很多（如 traceId、订单号、用户ID），keyBy 后 hash
  分布更均匀，所有分区都能分到数据，负载均衡效果好。

- 低基数字段：唯一值很少（如 service 只有 3\~5 种），keyBy
  后只有少数分区有数据，其它分区可能空闲，资源利用率低。

- 高并发/大流量场景：优先选择高基数字段
  keyBy，保证所有算子实例都能分到数据，提升吞吐和并发。

- 业务聚合需求：如果你只关心某个业务维度（如每个 service
  的窗口聚合），可以 keyBy service，但要注意并行度不要远大于 service
  数，否则部分分区会空闲。

- 极端高基数：如 traceId
  这种几乎唯一，可以让分区极度均匀，但窗口聚合结果会非常分散（每个
  traceId 一个窗口）。

结论

高基数字段 keyBy：分区均匀，资源利用率高，适合大流量并行处理。

低基数字段 keyBy：分区不均匀，部分分区空闲，适合业务聚合但并发有限。

##### Stream 多个算子共享

如果用 WatermarkStrategy.noWatermarks()，那么所有基于事件时间（event
time）的窗口算子（如 window、windowAll、TumblingEventTimeWindows
等）都不会被触发，也不会输出结果，因为没有水位线（watermark），Flink
事件时间窗口永远不会"关闭"，窗口算子就不会输出。而且，stream
是多个算子共享的（即同一个 DataStream 可以被多个下游算子消费），但
WatermarkStrategy 是在 source 阶段就确定的，后续所有下游算子都只能用这个
source 的 watermark 语义。

只要任何一个算子需要事件时间窗口聚合，source 就必须用
forBoundedOutOfOrderness 或 forMonotonousTimestamps 等能生成 watermark
的策略，不能用 noWatermarks。否则所有事件时间窗口相关算子都不会有输出。

##### Flink subtask 要等于Kafka topic 分区数量

假设Kafka topic topic-dics-long-skywalking-segments 的分区数为
3（PartitionCount: 3）。 Flink 作业并发设置为 5，那么只有
subtaskIndex=2、3、4
子任务有数据，其他两个0，1就没有数据，不会触发窗口。

查看kafka分区数：

kafka-consumer-groups.sh \--bootstrap-server localhost:9092 \--describe
\--group skywalking-segments-consumer-group-myself\"

  ------------------------------------------- ------------------------------------- ----------- ---------------- ---------------- -----
                     GROUP                                    TOPIC                  PARTITION   CURRENT-OFFSET   LOG-END-OFFSET   LAG

   skywalking-segments-consumer-group-myself   topic-dics-long-skywalking-segments       0          4627051          4627119       68

   skywalking-segments-consumer-group-myself   topic-dics-long-skywalking-segments       1          4625690          4625765       75

   skywalking-segments-consumer-group-myself   topic-dics-long-skywalking-segments       2          4622021          4622100       79

   skywalking-segments-consumer-group-myself   topic-dics-long-skywalking-segments       3           31066            31151        85

   skywalking-segments-consumer-group-myself   topic-dics-long-skywalking-segments       4           30856            30930        74
  ------------------------------------------- ------------------------------------- ----------- ---------------- ---------------- -----

一共5个分区，CURRENT-OFFSET：该分区已被消费的 SegmentObject
数量（下一个要消费的 offset）、LOG-END-OFFSET：该分区当前的最大
offset（即 SegmentObject 总数），LAG：该分区未被消费的 SegmentObject
数量（LOG-END-OFFSET - CURRENT-OFFSET）。每一条 Kafka 消息对应一个
SegmentObject，所以这些 offset 数值就是 SegmentObject 的数量。

这样需要设置Flink 作业并发设置为 5

- 负载均衡：当Flink的并行度与Kafka的分区数相等时，每个Flink子任务可以对应消费一个Kafka分区，实现理想的负载均衡。

- 性能最优：每个子任务独立处理一个分区的数据，避免了资源竞争和空闲，吞吐量最高。

##### Flink全局窗口与并发任务的窗口如何对齐

在此应用中在 Flink窗口对齐机制如下：

1\. 并发任务的窗口（Keyed Window）

- 对每个 traceSegmentId 做 keyBy，然后用
  TumblingEventTimeWindows.of(Time.seconds(windowSeconds)) 做窗口聚合。

- 这一步每个并发 subtask（taskId）会独立处理属于自己 key
  的数据，窗口的起止时间完全由事件时间（endTime
  字段）和窗口大小（windowSeconds）决定。

- 只要所有数据的事件时间戳是统一的（比如都用 segment 的 endTime），所有
  subtask 的窗口边界（windowStart,
  windowEnd）是严格对齐的。例如，windowStart=1749088705000，windowEnd=1749088712000。

  2\. 全局窗口（windowAll）

- 你在 perTraceAgg（每个 traceSegmentId 的窗口聚合结果）之后，直接用
  windowAll(TumblingEventTimeWindows.of(Time.seconds(windowSeconds)))
  做全局窗口聚合。

- windowAll 不是 keyBy，而是所有数据都进同一个全局窗口，由一个 subtask
  处理（setParallelism(1)）。

- 只要 windowAll
  的窗口大小和对齐方式（TumblingEventTimeWindows，窗口长度、对齐点）与前面
  keyBy 的窗口完全一致，全局窗口的 windowStart、windowEnd
  就和所有并发任务的窗口严格对齐。

  3\. 为什么能对齐？

- Flink
  的窗口分配器（TumblingEventTimeWindows）是基于事件时间戳和窗口长度来分配窗口的，所有算子只要窗口参数一致，窗口边界就一致。

- 你在 perTraceAgg 和 globalAgg 都用
  windowSeconds，且事件时间戳来源一致（segment endTime），所以窗口对齐。

- 你日志里看到的 windowStart、windowEnd 在 perTraceAgg 和 globalAgg
  输出是一致的。

  4\. 典型日志对齐示例

- 并发窗口日志（taskId 不同，windowStart 一样）：

  traceSegmentId: \... windowStart=1749088705000 并行taskId: 2 \...

  traceSegmentId: \... windowStart=1749088705000 并行taskId: 3 \...

  全局窗口日志（windowStart=1749088705000）：

  \[GlobalAgg\] windowStart=1749088705000 windowEnd=1749088712000 \...

  5\. 注意事项

- 只要所有数据的事件时间戳分配一致，窗口长度一致，Flink
  的窗口边界就能对齐。

- 如果你用不同的窗口长度、不同的事件时间字段，或者有迟到/乱序数据，可能会导致窗口对不齐

  你的全局窗口（windowAll）和并发任务的窗口（keyBy）是严格对齐的，窗口起止时间完全一致。全局窗口就是把所有并发窗口的结果再聚合一次，窗口边界不会错位。

##### 全局聚合前，并发任务窗口没有都出现。就是说全局聚合前，只有部分任务窗口打印了日志

全局聚合窗口日志有时会早于所有并发任务窗口日志全部出现，即有些
windowStart 的 \[GlobalAgg\]
日志已经输出，但部分并发窗口日志还没打印。这是 Flink
窗口机制的正常现象，原因如下：

1\. Flink 窗口触发与并发机制

Keyed Window（并发任务）：每个 key（traceSegmentId）在各自的 subtask
上独立聚合，窗口触发依赖于该 key 的事件时间水位线（watermark）推进。

windowAll（全局窗口）：所有 perTraceAgg 的输出会被 shuffle 到一个
subtask，按全局水位线触发窗口。

2\. 为什么全局窗口日志会先于部分并发窗口日志出现？

watermark 推进不均衡：Flink 的 watermark 是所有并发 source
的最小值。只要有一个 subtask 的 watermark
达到窗口关闭条件，全局窗口就会被触发。

数据分布不均：有些 key 的数据在某些窗口周期内很少甚至没有，导致某些并发
subtask 的窗口迟迟没有数据或 watermark 推进慢。

日志输出时机不同：全局窗口的日志输出只依赖于 perTraceAgg 的输出流到达
windowAll，并不等待所有并发窗口日志都已打印。

3\. 具体表现

某个 windowStart 的 \[GlobalAgg\] 日志已经输出，但此时部分
traceSegmentId 的窗口日志还没出现，或者根本没有（因为该窗口周期内没有该
key 的数据）。

这并不影响全局聚合的正确性，因为全局窗口只聚合实际到达的 perTraceAgg
结果。

4\. 结论

全局窗口的触发与并发窗口日志输出不是严格同步的，全局窗口只要收到该窗口周期内的
perTraceAgg 输出就会聚合和输出日志。

某些并发窗口日志缺失，通常是该窗口周期内没有该 key
的数据，或者数据延迟到下一个窗口才到达。

你可以这样验证

检查 perTraceAgg 的输出数量，发现有些窗口周期内某些 key
没有输出（即没有数据）。

检查 watermark 日志，发现全局窗口的触发只依赖于最慢的 source watermark。

总结： 全局窗口日志先于部分并发窗口日志出现，是 Flink
窗口机制和数据分布的正常现象，不影响聚合正确性。只要你的事件时间、窗口参数一致，聚合逻辑就是对的。

Flink 实现按服务名、方法名（交易码）进行分组并汇聚组内最大耗时和平均耗时

1.  Kafka 消费排查

    用 kafka-consumer-groups.sh 查看消费组 lag、offset
    提交情况，确认没有频繁回退。

    用 Kafka 工具抽查同一分区同一 offset 是否有重复 traceSegmentId。

    Flink 并行度与分区数核查

2.  确认 Flink 作业并行度与 Kafka topic 分区数一致。

    检查 Flink KafkaSource 配置，确保 offset 策略为
    committedOffsets()，无 auto.offset.reset=earliest。

    traceSegmentId 唯一性采样

3.  在 flatMap 处采样输出 traceSegmentId，统计同一 traceSegmentId
    在窗口周期内出现的次数，确认是否有业务唯一性问题。

4.  乱序与窗口设置核查

    检查 span endTime 分布，适当调整 WatermarkStrategy 的乱序容忍时间。

    如需进一步定位

    可在 flatMap 处输出 (traceSegmentId, segmentObject.hashCode(),
    offset/partition) 等信息，辅助定位重复来源。

    可在窗口聚合日志中输出 traceSegmentId 的所有 endTime
    列表，分析是否为乱序/重复。

DataStream\<Tuple3\<Double, Long, Long\>\> perTraceAgg = durationStream

                .keyBy(t -\> t.f0)

               
.window(TumblingEventTimeWindows.of(Time.seconds(windowSeconds)))

                .aggregate(new AvgMaxAggregateFunction2(),

                        new ProcessWindowFunction\<Tuple2\<Double,
Long\>, Tuple3\<Double, Long, Long\>, String, TimeWindow\>() {

                            \@Override

                            public void process(String key, Context
context, Iterable\<Tuple2\<Double, Long\>\> elements,

                                    Collector\<Tuple3\<Double, Long,
Long\>\> out) {

                                Tuple2\<Double, Long\> result =
elements.iterator().next();

                                // 统计窗口内 traceSegmentId 的唯一数量

                                long count = result.f1;

                                LOG.info(\"traceSegmentId={}
windowStart={} 并行taskId: {} 窗口内消息数: {} 平均: {} 最大: {}\",

                                        key,
context.window().getStart(),
getRuntimeContext().getIndexOfThisSubtask(),

                                        count, result.f0, result.f1);

                                out.collect(Tuple3.of(result.f0,
result.f1, context.window().getStart()));

                            }

                        })

                .returns(Types.TUPLE(Types.DOUBLE, Types.LONG,
Types.LONG));

        // 步骤3：按 traceSegmentId 分组，基于事件时间做滚动窗口聚合

        DataStream\<Tuple3\<Double, Long, Long\>\> perTraceAgg =
durationStream

                .keyBy(t -\> t.f0)

               
.window(TumblingEventTimeWindows.of(Time.seconds(windowSeconds)))

                .process(new ProcessWindowFunction\<Tuple4\<String,
Integer, Long, Long\>, Tuple3\<Double, Long, Long\>, String,
TimeWindow\>() {

                    \@Override

                    public void process(String key, Context context,
Iterable\<Tuple4\<String, Integer, Long, Long\>\> elements,

                                        Collector\<Tuple3\<Double, Long,
Long\>\> out) {

                        long count = 0;

                        long sum = 0;

                        long max = Long.MIN_VALUE;

                        LOG.info(\"traceSegmentId={} windowStart={}
窗口内详细span:\", key, context.window().getStart());

                        for (Tuple4\<String, Integer, Long, Long\> span
: elements) {

                            LOG.info(\"  spanId={} duration={}
endTime={}\", span.f1, span.f2, span.f3);

                            count++;

                            sum += span.f2;

                            if (span.f2 \> max) max = span.f2;

                        }

                        double avg = count == 0 ? 0.0 : (double) sum /
count;

                        LOG.info(\"traceSegmentId={} windowStart={}
并行taskId: {} 窗口内消息数: {} 平均: {} 最大: {}\",

                                key, context.window().getStart(),
getRuntimeContext().getIndexOfThisSubtask(),

                                count, avg, max);

                        out.collect(Tuple3.of(avg, count,
context.window().getStart()));

                    }

                })

                .returns(Types.TUPLE(Types.DOUBLE, Types.LONG,
Types.LONG));

##### 测试方案

1\. 目标

验证 Flink
事件时间窗口在真实流式环境下的分布式聚合行为，确保多分区Kafka输入、多并发Flink任务下，窗口聚合（平均响应时间、最大响应时间）逻辑正确，且每个并发任务能独立处理各自分区的数据。

2\. 测试环境准备

Kafka：新建 topic test_flink_task，分区数设置为2。

Flink：应用并发（parallelism）设置为2，确保每个 task 只消费一个分区。

3\. 测试数据准备

向 test_flink_task topic
写入4条模拟的 [SegmentObject](vscode-file://vscode-app/c:/Users/Administrator/AppData/Local/Programs/Microsoft VS Code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html) 数据。

每条数据的 key 轮流变化（如 key-0、key-1），确保均匀分布到2个分区。

每条数据的 endTime 递增，保证 Watermark 能推进，窗口能及时关闭。

数据内容示例（伪代码）：

key-0, endTime=1000key-1, endTime=2000

key-0, endTime=3000

key-1, endTime=4000

4\. Flink 应用逻辑

Source：从 test_flink_task 读取 SegmentObject 流。

事件时间分配：用 span 的 endTime 作为事件时间。

keyBy：按 traceSegmentId 或其它业务key分组。

窗口：TumblingEventTimeWindows（如7秒）。

聚合：计算窗口内平均响应时间、最大响应时间。

Sink：输出到控制台或自定义 Sink，打印每个窗口的
key、窗口起止时间、平均/最大响应时间、当前 subtask id。

5\. 运行与验证

启动 Flink 应用，消费 Kafka topic。

观察日志或 Sink 输出，确认：

每个 Flink 并发 task 只处理自己分区的数据。

每个窗口聚合结果正确（平均、最大响应时间与输入数据一致）。

窗口能被及时触发（Watermark推进后有输出）。

6\. 关键点说明

Kafka Producer 发送时要指定不同 key，确保数据均匀分布到2个分区。

每个分区至少有1条正常数据+1条推进水位线的数据，确保窗口能触发。

Flink 并发数与 Kafka 分区数一致，保证每个分区被独立消费。

日志中建议输出 subtaskId、key、窗口信息，便于验证分布式行为。

##### 测试数据要求

topic test_flink_task 中的 segmentObject 数据是永久存在的方便反复测试。

1\. 在 Docker Kafka 中创建 topic

假设你的 Kafka 容器名为 kafka，Zookeeper 容器名为 zookeeper，端口为
9092，命令如下：

如有端口映射或网络不同，请根据实际情况调整 \--bootstrap-server。

docker exec -it demo-kafka-1 kafka-topics.sh \--create \--topic
test_flink_task \--partitions 2 \--replication-factor 1
\--bootstrap-server localhost:9092

删除命令

docker exec -it demo-kafka-1 kafka-topics.sh \--delete \--topic
test_flink_task \--bootstrap-server localhost:9092

2\. topic 数据永久保留（便于反复测试）

Kafka 默认不会自动删除消息，除非设置了保留策略。你可以通过如下命令设置
topic 永久保留：

docker exec -it demo-kafka-1 kafka-configs.sh \--alter \--entity-type
topics \--entity-name test_flink_task \--add-config retention.ms=-1
\--bootstrap-server localhost:9092

这样消息不会过期，便于反复消费测试。

3\. 用 Java 代码写入 protobuf 格式的 SegmentObject 到 Kafka

假设你已经有 segment.proto 并生成了 Java 类（如
segment.v3.Segment.SegmentObject），可以用如下 Java 代码写入 4
条测试数据到 Kafka：

import org.apache.kafka.clients.producer.\*;

import org.apache.kafka.common.serialization.ByteArraySerializer;

import segment.v3.Segment;

import java.util.Properties;

public class SegmentProducer {

    public static void main(String\[\] args) throws Exception {

        Properties props = new Properties();

        props.put(\"bootstrap.servers\", \"localhost:9092\"); //
docker端口映射到本地

        props.put(\"key.serializer\",
\"org.apache.kafka.common.serialization.StringSerializer\");

        props.put(\"value.serializer\",
\"org.apache.kafka.common.serialization.ByteArraySerializer\");

        Producer\<String, byte\[\]\> producer = new
KafkaProducer\<\>(props);

        for (int i = 0; i \< 4; i++) {

            String key = \"key-\" + (i % 2); // 轮流分到2个分区

            long endTime = 1000L \* (i + 1);

            // 构造 SegmentObject

            Segment.SegmentObject.Builder segBuilder =
Segment.SegmentObject.newBuilder()

                .setTraceId(\"trace-\" + i)

                .setTraceSegmentId(\"segment-\" + i)

                .setService(\"service-0\");

            Segment.SpanObject.Builder spanBuilder =
Segment.SpanObject.newBuilder()

                .setSpanType(Segment.SpanType.Entry)

                .setStartTime(endTime - 100)

                .setEndTime(endTime)

                .setOperationName(\"testOperation\");

            segBuilder.addSpans(spanBuilder);

            Segment.SegmentObject segmentObject = segBuilder.build();

            ProducerRecord\<String, byte\[\]\> record = new
ProducerRecord\<\>(

                \"test_flink_task\", key, segmentObject.toByteArray());

            producer.send(record);

        }

        producer.close();

        System.out.println(\"4条SegmentObject写入完成\");

    }

}

注意：请确保 segment.v3.Segment 相关类已由 protoc 生成并在 classpath
下。

4\. Flink 端反复消费测试

Flink Source 配置 auto.offset.reset=earliest，每次重启都能从头消费。

或者用 Flink SQL/Table API/自定义 Source，反复消费 topic。

##### 运行测试

1，调整 application.yaml 中 kafka配置，指向 topic test_flink_task；\
2，调整 FlinkKafkaToClickHouseJob 中 setStartingOffsets 为 earliest ；\
3，运行 FlinkKafkaToClickHouseJob main 方法，观察测试数据的消费效果。

env.setParallelism(2);

env.getConfig().addDefaultKryoSerializer(SegmentObject.class,
ProtobufSerializer.class);

// 启用 checkpoint，每60秒一次

env.enableCheckpointing(60000);

// 可选：设置 checkpoint 超时时间为30秒

env.getCheckpointConfig().setCheckpointTimeout(30000);

将这些配置 写入 application.yaml

##### 将算子计算结果存入clickhouse

##### 设置固定阈值

**算子参数热更新\**
1，新建方法，newParams 和
updateParams，功能分别是新增算子参数，更新算子参数；\
2，新增或者更新后 通知所有 算子，可以结合kafka消息来实现；\
3，算子收到通知更新参数，并按新参数运行，结合 FlinkOperator
接口来实现算子端监听 Kafka 并热更新参数；\
FlinkOperator 接口扩展一个参数热更新方法（如 onParamUpdate）。

- 算子实现该方法，收到 Kafka 通知后 reload 参数。

- Kafka 作为分布式通知通道，保证所有算子都能及时感知参数变更。

- 注意点和建议：

1.  Flink 算子本身是分布式运行的，监听 Kafka
    需在每个算子实例内实现（如在 open/init 方法里起一个 KafkaConsumer
    线程，收到消息后调用 onParamUpdate）。

2.  参数更新后，算子内部要保证线程安全（如参数用 volatile 或加锁）。

3.  参数变更后，新的参数只影响后续处理，不会影响已在窗口中的历史数据。

4.  如果参数变更频繁，建议加去重或节流，避免频繁 reload。

    可以将 open 和 onParamUpdate 的参数热更新实现抽取到一个抽象基类（如
    AbstractParamUpdatableOperator），所有需要参数热更新能力的算子都继承这个基类即可。这样可以极大减少重复代码，统一管理
    Kafka 监听和参数热更新逻辑。

    推荐做法如下：

<!-- -->

1.  新建抽象类 AbstractParamUpdatableOperator\<T, O\>，继承
    RichFlatMapFunction\<T, O\> 并实现 FlinkOperator。

2.  在该类中实现 open、close、onParamUpdate 及 KafkaConsumer 监听逻辑。

3.  子类只需实现 apply、getName 及自己的业务逻辑即可，参数变量直接用
    protected volatile Map\<String, List\<String\>\> params。

    这样所有算子都能自动获得参数热更新能力，且代码更易维护。\
    \
    1. 为什么推荐继承 RichFlatMapFunction？

    只有继承 RichFunction（如
    RichFlatMapFunction、RichMapFunction、RichProcessFunction 等）才能用
    Flink 的 open() 和 close()
    生命周期方法，在算子启动和关闭时做资源管理（如启动/关闭
    KafkaConsumer 监听参数变更）。

    这样每个算子实例都能独立监听参数变更，实现分布式热更新，且资源能被优雅释放。

    2\. 不继承 RichFlatMapFunction 能不能热更新？

    理论上你可以用其它方式（如外部线程、全局单例、广播流等）实现参数热更新，但这样会失去
    Flink 的生命周期管理，容易导致资源泄漏、线程无法关闭等问题。

    如果用 Flink 的 Broadcast State
    机制，也可以实现全局参数热更新，但实现复杂度更高，且不适合所有场景。

    3\. 继承 RichFlatMapFunction 的优势

    生命周期管理（open/close）

    线程安全和资源释放

- 需要参数热更新的算子继承 RichFlatMapFunction 或其它 RichFunction
  子类，这样最安全、最易维护。

- 不是唯一方式，但这是 Flink 官方和业界的最佳实践。

  在当前场景：

  1，消费kafka 中 segmentObject ；

  2，按 service、operator_name 分组，统计每 7
  秒内各组的平均耗时和最大耗时，

  3，最大延迟、 平均延迟分别对比其阈值，如果大于就告警。

  如何结合Flink Broadcast State机制，实现动态的
  阈值、告警模板的下发，热更新。

##### 系统配置

高峰期每秒 9000 个 segmentObject，系统需从 Kafka、Flink 到 ClickHouse
全链路进行容量与性能配置。以下是生产：

1\. Kafka 配置

分区数：不少于 8\~16 个分区（分区数越多，Flink 并行度越高，吞吐越大）。

副本数：2\~3，保证高可用。

Broker 数：至少 3 台，分摊压力。

消息保留：根据业务需求设置，避免积压。

2\. Flink 配置

并行度：与 Kafka 分区数一致或倍数（如
8、12、16），保证每个分区有独立消费算子。

TaskManager 资源：每个 slot 至少 1\<del\>2 核 CPU，2\</del\>4G
内存（视单条 segmentObject 大小和业务复杂度调整）。

Checkpoint：开启，间隔 1\~5 分钟，存储用 HDFS/S3，保证容错。

重启策略： fixed-delay 或 failure-rate，防止异常雪崩。

3\. ClickHouse 配置

表引擎：MergeTree，分区字段建议按天或小时。

写入批量：Flink Sink 建议批量写入（如 500\~2000 条/批），减少 ClickHouse
压力。

集群规模：高并发建议至少 3 节点，分片+副本，提升写入和查询能力。

磁盘与网络：SSD+千兆以上网络，避免 IO 瓶颈。

4\. 监控与扩容

Kafka Lag、Flink 延迟、ClickHouse 写入速率等需实时监控。

发现延迟、积压，优先扩展 Kafka 分区、Flink 并行度、ClickHouse 节点。

5\. 代码与参数

- Flink Source/Sink 批量参数、缓冲区、超时等需根据实际压测调优。

- 业务代码避免阻塞、慢操作，聚合窗口计算逻辑高效。

#####  Broadcast State

场景描述：

规则流：Kafka下发的阈值、告警模板流，广播到所有算子实例。

Broadcast State：保存每个 service/operator_name
的阈值和告警模板，支持动态更新。

告警逻辑：窗口聚合结果与 Broadcast State
中的阈值/模板实时比对，超阈值则输出告警。

1.  实现 各个算子的阈值 写入 kafka；

2.  规则流：Kafka下发的阈值、告警模板流，广播到所有算子实例。

3.  Broadcast State：保存每个 service/operator_name
    的阈值和告警模板，支持动态更新。

<!-- -->

1.  各算子阈值写入 Kafka

    将每个 service/operator_name 的阈值、告警模板等规则对象序列化为
    JSON（或 Protobuf），通过 Kafka Producer 写入专用 topic（如
    alarm_rule_topic）。

    规则格式建议包含
    service、operator_name、maxThreshold（高中低三个档次）、avgThreshold（高中低三个档次）、alarmTemplate
    字段。

    2\. 规则流 Kafka 下发并广播

    Flink 侧用 KafkaSource 消费 alarm_rule_topic，反序列化为规则对象（如
    ThresholdTemplate）。

    用 .broadcast(MapStateDescriptor) 广播成
    BroadcastStream，所有算子实例都能收到规则变更。

    3\. Broadcast State 保存并动态更新

    用 BroadcastProcessFunction 或 KeyedBroadcastProcessFunction，在
    processBroadcastElement 方法中将规则写入 Broadcast State。

    在 processElement
    方法中，主流每条数据都能实时读取最新规则，进行阈值比对和告警输出。

    将每个 service/operator_name 的阈值、告警模板等规则对象序列化为
    JSON，通过 Kafka Producer 写入专用 topic，
    alarm_rule_topic。规则格式包含
    service、operator_name、maxThresholdHigh、maxThresholdMid、maxThresholdLow、avgThresholdHigh、avgThresholdMid、avgThresholdLow、alarmTemplate
    等字段。

- 规则流有新规则：processBroadcastElement 自动更新 Broadcast State，所有
  Task/算子实例本地副本同步。

- 业务流每条数据：processElement 实时读取 Broadcast
  State，始终用最新规则判断，无需重启、无需手动同步。

- 高可用：Flink 保证 Broadcast State
  的一致性和容错，规则变更可随时生效。

1.  首先实现按AlarmRule去匹配算子输出

    告警规则对象AlarmRule 已经写入 kafka，下面需要实现：

<!-- -->

1.  规则流：Kafka 下发 AlarmRule（阈值、模板等），通过 Flink Source
    读取，广播到所有算子实例。

2.  Broadcast State：用 Flink 的 Broadcast State 保存每个
    service/operator_name 的阈值和模板，支持规则动态更新。

3.  业务流与规则流连接：业务流（如 ServiceAggResult）与规则流
    connect，业务流在处理时实时查规则，进行阈值判断。

    在算子的 步骤3：按照 规则进行阈值判断。注意当前阈值不分 高 中
    低三档，这个判断我可以手工实现。\
    \
    1. 规则流 Source + 广播；2. 业务流与规则流 connect；3.
    BroadcastProcessFunction 实现。

##### compacted topic

Kafka 的 compacted topic 是通过配置参数 cleanup.policy=compact
实现的。这样每个 key
只保留最新一条消息，历史的会被自动清理，非常适合做规则、配置、字典等"只关心最新值"的场景。

1.  新建 topic 时指定 compacted 策略：

kafka-topics.sh \--bootstrap-server localhost:9092 \--create \\

  \--topic alarm_rule_topic \\

  \--partitions 1 \\

  \--replication-factor 1 \\

  \--config cleanup.policy=compact

2.  已有 topic 修改为 compacted：

kafka-configs.sh \--bootstrap-server localhost:9092 \\

  \--entity-type topics \--entity-name alarm_rule_topic \\

  \--alter \--add-config cleanup.policy=compact

3.  验证 topic 是否为 compacted

kafka-topics.sh \--bootstrap-server localhost:9092 \--describe \--topic
alarm_rule_topic

- compacted topic 只会保留每个 key 的最新消息（以及部分旧消息，直到
  compaction 完成）。

- 适合规则、配置、字典等"只关心最新值"的场景，不适合日志、流水等需要全量历史的场景。

- 生产环境建议分区数、replication-factor 按需调整。

#### 动态阈值

动态阈值通过统计历史数据，按 service、operatorName 和 windowSize
分组，同时基于每天相同时间窗口的聚合结果（如每天 10:20 分，窗口大小 20
秒），计算均值和分位数生成低、中、高三档阈值，并将结果存储到 ClickHouse
的动态阈值表中。系统根据当前时间查询动态阈值表，匹配对应的阈值并通过
Kafka 下发，触发 Flink
的规则流热更新，实现实时告警规则的动态调整，适应业务流量的周期性变化和异常波动。

##### 基本流程

1\. 统计多天数据，按窗口期生成阈值

- 数据来源：从 flink_operator_agg_result 表中读取多天数据。

- 分组逻辑：按 service、operatorName 和 windowSize
  分组，同时按每天的相同时间窗口（如每天 10:20 分，窗口大小 20
  秒）聚合。

- 阈值计算：对每组数据计算均值，生成动态阈值。

- 存储：将生成的阈值记录到 ClickHouse 的动态阈值表（如
  dynamic_threshold）。

  2\. 动态阈值表结构

  CREATE TABLE dynamic_threshold (

  service String,

  operator_name String,

  window_start DateTime,

  window_size Int32,

  avg_duration_low Float64,

  avg_duration_mid Float64,

  avg_duration_high Float64,

  max_duration_low Float64,

  max_duration_mid Float64,

  max_duration_high Float64,

  success_rate_low Float64,

  success_rate_mid Float64,

  success_rate_high Float64,

  traffic_volume_low Float64,

  traffic_volume_mid Float64,

  traffic_volume_high Float64

  ) ENGINE = MergeTree()

  ORDER BY (service, operator_name, window_start);

  3\. 读取动态阈值表，触发热更新

- 查询逻辑：根据当前系统时间，查询动态阈值表中 window_start
  与当前时间匹配的阈值。

- 下发规则：将查询到的阈值写入 Kafka，触发 Flink 的规则流热更新。

##### 分时段建模

按小时/工作日/节假日分别统计，适应流量周期性变化。分时段建模是通过对业务流量的时间特性进行分析，按不同时间段（如小时、工作日、节假日）分别统计和生成阈值，以适应流量的周期性变化。

- 节假日标记：可维护一个节假日表，标记特殊日期，供 SQL 查询使用。

- 异常点过滤：结合异常检测算法（如 Isolation Forest），排除极端异常点。

- 规则兜底：允许人工设定最小/最大阈值，防止自动阈值失控。

##### 异常点过滤

结合异常检测算法（如 Isolation Forest），排除极端异常点。

##### 规则兜底

允许人工设定最小/最大阈值，防止自动阈值失控。

####  系统逻辑结构

![IMG_256](media/image5.png){width="5.825694444444444in"
height="4.182638888888889in"}

##### 可观测性流处理系统逻辑架构说明

该系统采用四层架构设计，构建了一个完整的可观测性数据流处理平台。

**数据采集层**：以SkyWalking
Agent为核心，从业务应用集群（上万台服务器）自动采集分布式链路追踪数据。通过自定义标签、环境变量采集等机制，将原始监控数据转换为结构化的SegmentObject事件，并通过Kafka
Topic进行异步传输。

**流处理核心层**：基于Apache Flink构建实时计算引擎。KafkaSource负责数据反序列化，FlinkService作为作业协调器统一管理。系统集成了算子注册中心、服务聚合算子、告警规则广播流等核心组件，支持事件时间处理、参数热更新、Checkpoint容错恢复等高级特性。动态Schema同步机制确保系统能够自适应新增的数据字段。

**数据存储层**：采用ClickHouse集群作为高性能存储引擎，分别存储原始事件数据、聚合计算结果和动态Schema信息。通过SimpleClickHouseSink、AggResultClickHouseSink等组件实现数据分流转储，AlarmGatewaySink负责将告警信息推送至邮件、短信、钉钉等通知渠道。

**运维管控层**：提供完整的运维管理功能，包括数据库连接管理、配置管理、数据映射转换等基础服务。集成Apache
Superset实现数据可视化分析，Prometheus/Grafana提供系统监控能力，FlinkServiceLauncher确保服务稳定启动。

系统具备十大核心特性：实时流处理、高维度数据支持、智能告警、动态Schema管理、高性能存储、精准分析、容错恢复、可视化分析、弹性扩展和高可用设计，为大规模分布式系统的可观测性提供了完整的技术解决方案。

#### 系统物理结构图

![IMG_256](media/image6.png){width="6.386111111111111in"
height="5.843055555555556in"}

本架构面向高并发、高可用的可观测性数据流场景，设计目标为每秒4万笔交易、160MB/s数据流，具备强大的横向扩展和高性能保障。系统分为六大核心层次：

1.  **网络架构层**：采用核心交换机与多台接入交换机，通过LACP链路聚合和100GbE/40GbE高速网络，确保数据在各集群间高速、无阻塞传输，满足大流量低延迟需求。

2.  **业务应用集群**：多机架部署，负责实时产生观测数据。通过负载均衡器和高速网络，将数据高效汇聚至Kafka集群。

3.  **Kafka消息中间件集群**：三节点高配Broker，支持高并发写入和消费，单集群总吞吐可达200MB/s（3副本600MB/s），P99延迟低于10ms，具备高可用和分区并发能力，保障数据可靠流转。

4.  **Flink实时计算集群**：双JobManager高可用架构，8台高性能TaskManager，整体并行度高达512。支持端到端100ms内低延迟处理，具备exactly-once语义和RocksDB状态后端，确保流式计算的准确性和容错性。

5.  **ClickHouse分析数据库集群**：三分片双副本，单节点48C96T/512GB/16TB
    NVMe，支持高并发写入（峰值500MB/s）和查询（QPS 1000+，P95\<200ms），采用高效压缩和冷热分层存储，数据可保留一年以上，单点故障零影响。

6.  **可视化与监控层**：包括Superset、Prometheus、Grafana和AlertManager等组件，支持千级并发查询、百万级指标采集和多渠道告警，保障业务与系统状态的全链路可视化和智能监控。

**总体特性**：

- 全链路高可用，单点故障零影响

<!-- -->

- 25%性能冗余，支持突发流量

<!-- -->

- 水平扩展设计，支持10倍容量增长

<!-- -->

- 监控完备，5分钟内故障发现

<!-- -->

- 采用开源技术栈，TCO降低60%

<!-- -->

- 支持弹性伸缩和灾备切换，满足未来业务增长和高可靠性需求

本架构为大规模分布式系统的可观测性与智能运维提供了坚实的基础。
