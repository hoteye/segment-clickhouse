**本行**

**智能运维可观测基础平台项目技术方案**

目 录

[1. 文档简介 8](#文档简介)

[1.1. 编写目的 8](#编写目的)

[1.2. 背景 8](#背景)

[1.3. 编写依据 9](#编写依据)

[1.4. 引用标准与规范 10](#引用标准与规范)

[1.5. 名词术语 10](#名词术语)

[2. 系统建设目标与原则 13](#系统建设目标与原则)

[2.1. 系统建设目标 13](#系统建设目标)

[2.2. 系统建设原则 14](#系统建设原则)

[3. 系统功能需求分析 15](#系统功能需求分析)

[3.1. 业务总体需求概述 15](#业务总体需求概述)

[3.2. 需求分析原则 17](#需求分析原则)

[3.3. 用户类别分析 17](#用户类别分析)

[3.4. 业务功能总体描述 18](#业务功能总体描述)

[3.4.1. 总体业务功能 18](#总体业务功能)

[3.4.2. 典型业务流程 19](#典型业务流程)

[3.5. 非功能要求总体描述 23](#非功能要求总体描述)

[4. 架构方案 31](#架构方案)

[4.1. 系统定位和范围 31](#系统定位和范围)

[4.2. 系统交互关系 31](#系统交互关系)

[4.3. 系统演进路线 32](#系统演进路线)

[4.4. 应用功能架构 34](#应用功能架构)

[4.4.1. 应用功能架构图 34](#应用功能架构图)

[4.4.2. 功能清单 34](#功能清单)

[4.5. 系统数据组成 36](#系统数据组成)

[4.6. 技术要求 37](#技术要求)

[4.6.1. 可观测基础数据采集 37](#可观测基础数据采集)

[4.6.2. 端到端 TCP 特征报文采集 49](#端到端tcp特征报文采集)

[4.6.3. 运维大数据 51](#运维大数据)

[4.6.4. 知识图谱 73](#知识图谱)

[5. 系统非功能性需求 77](#系统非功能性需求)

[5.1. 性能需求 77](#性能需求)

[5.1.1. 预估的业务量 77](#预估的业务量)

[5.1.2. 预估带宽 77](#预估带宽)

[5.1.3. 性能指标 78](#性能指标)

[5.2. 质量需求 79](#质量需求)

[5.2.1. 可用性 79](#可用性)

[5.2.2. 完整性 80](#完整性)

[5.2.3. 兼容性 80](#兼容性)

[5.2.4. 可维护性 81](#可维护性)

[5.2.5. 可扩充性 81](#可扩充性)

[5.2.6. 可管理性 82](#可管理性)

[5.2.7. 数据独立性 82](#数据独立性)

[5.2.8. 平台独立性 82](#平台独立性)

[5.3. 运维需求 83](#运维需求)

[5.3.1. 监控需求 83](#监控需求)

[5.3.2. 操作需求 92](#操作需求)

[5.3.3. 故障处理与恢复 93](#故障处理与恢复)

[5.4. 安全性需求 93](#安全性需求)

[5.4.1. 系统合规安全 93](#系统合规安全)

[5.4.2. 网络层安全需求 100](#网络层安全需求)

[5.4.3. 系统层安全需求 101](#系统层安全需求)

[5.4.4. 应用层安全需求 102](#应用层安全需求)

[5.4.5. 数据安全需求 103](#数据安全需求)

[5.4.6. 业务场景安全需求 103](#业务场景安全需求)

[6. 系统实施方案 105](#系统实施方案)

[6.1. 总体实施策略 105](#总体实施策略)

[6.2. 阶段划分及目标 106](#阶段划分及目标)

[6.3. 阶段实施工作内容 106](#阶段实施工作内容)

[6.4. 系统体系结构 107](#系统体系结构)

[6.4.1. 系统逻辑架构 107](#系统逻辑架构)

[6.4.2. 系统技术架构 108](#系统技术架构)

[6.5. 系统间接口 109](#系统间接口)

[6.5.1. 系统接口 109](#系统接口)

[6.5.2. 异常处理 111](#异常处理)

[6.6. 灾备方案 112](#灾备方案)

[6.6.1. 数据级灾备 112](#数据级灾备)

[6.7. 数据迁移实施方案 115](#数据迁移实施方案)

[6.7.1. 数据迁移总体策略 115](#数据迁移总体策略)

[6.7.2. 数据差异分析 115](#数据差异分析)

[6.7.3. 迁移方案说明 115](#迁移方案说明)

[6.7.4. 数据迁移程序开发 115](#数据迁移程序开发)

[6.7.5. 迁移测试方案 116](#迁移测试方案)

[6.7.6. 上线演练 116](#上线演练)

[6.7.7. 切换上线及验证 116](#切换上线及验证)

[6.7.8. 应急预案 116](#应急预案)

[6.8. 软硬件资源需求 116](#软硬件资源需求)

[6.8.1. 软硬件配置原则 116](#软硬件配置原则)

[6.8.2. 系统软件配置要求 117](#系统软件配置要求)

[6.8.3. 软硬件配置分析 118](#软硬件配置分析)

[6.8.4. 软硬件配置方案 120](#软硬件配置方案)

[6.9. 系统部署要求 122](#系统部署要求)

[6.10. 分行实施推广 123](#分行实施推广)

[6.11. 项目组织 123](#项目组织)

[6.12. 项目里程碑计划 125](#项目里程碑计划)

[6.13. 问题和风险 125](#问题和风险)

# **文档简介**

## 编写目的

本方案从总体上描述了智能运维可观测基础平台的建设目标和思路，明确规定了系统建设所要遵循的基本原则和要求。文档的内容主要包括系统建设目标与原则、核心业务需求分析、系统架构方案、系统实施方案等。

本方案用于指导本行智能运维可观测基础平台总体工程建设、系统设计开发以及相关业务系统的改造等工作。本方案供项目主管负责人、系统需求分析师、设计开发人员、测试人员进行需求理解，指导建设单位提供详细的技术方案，使之在系统的建设过程中，做出准确的抉择，不偏离规划的目标和要求。

## 背景

过去十年，企业数字化历经了从服务器到云化，再到云原生化的重要转型阶段。现如今，云原生技术已成为加速企业数字化转型、推动高效创新的最佳技术支撑。伴随着云原生技术的持续演进，云安全问题亦日益凸显，其重要性不容忽视。我国十四五规划中已明确指出，要着力提升云安全水平。有鉴于此，在云原生环境下可观测技术作为解决云安全问题的有效途径之一，正逐步崭露头角并受到广泛关注。

在云原生时代，基础设施与应用的构建和部署都发生了极大变化，例如：架构微服务化、运行环境容器化、业务系统依赖关系复杂化，运行实例生命周期短等。随着云原生应用的规模不断扩大，复杂度愈来愈高，网络流量和应用会话可视能力不足，而其中潜藏的问题和风险也随之增多。IT 团队需要面对数百万个容器或数千个微服务，而不再是数百个 VM 或几十个服务，而且这些容器可能只存活几分钟，云原生环境中的组件类型及数量比传统 VM 环境更多、更复杂。而一个容器具有与一台 VM 相同的 CPU、内存和网络等指标数据，VM 的数量是成百上千，但容器的规模可能是百万级的。因此，云原生环境会产生大量的监控数据，比传统的基于 VM 的环境多 100 到 1000 倍。

云原生可观测性越来越复杂，"数据规模"、"复杂性"、"成本失控"，将是云原生观测面临的三大难题。传统工具难以应对分布式微服务以及 serverless 环境，Kubernetes
模糊了软件和基础设施之间的界限，以至于传统工具不得不使用多个 Agent 来采集基本数据，这也直接丧失了信息关联的能力。

云原生时代的监控要求能够实时动态调整，而传统预先配置再监控的方式已经无法适应云原生的场景。在这个背景下，2018 年 CNCF 社区引入了云原生可洞察性（Observability）这一理念，同时随着操作系统内核支持 eBPF 技术，在无需加载内核模块的情况下，对内核进行观测和注入，从而实现各种高阶功能。通过 eBPF，我们可以深入到系统的最底层，对内核的运行情况进行精细化的观测和控制，从而为系统的稳定性和性能提供强有力的支持。

在面对行业的持续创新和应用快速迭代的挑战中，我们迫切需要引进新技术、新方法和新平台来提升和改善现有的研发及运维模式。云原生可观测性由传统监控演进而来，相比传统监控是从系统外部视角去观察系统的运行状态，云原生可洞察性是从系统内部出发，基于"白盒化"的思路去监测系统内部的运行情况。云原生可观测性贯穿了应用从开发到下线消亡的整个生命周期，包括开发测试、集成测试、上线部署发布等环境。通过分析应用的
Metrics（指标）、Traces（链路）、Logs（日志）等数据，构建完整的观测模型，从而实现故障诊断和根因分析。

云计算成为金融行业数字化转型的必备能力。技术的发展更新、业务的创新实践、系统的敏捷迭代，对保持云化系统稳定带来巨大挑战。Gartner 认为应用可观测是 2023 年重要战略技术趋势之一。面对云原生环境下复杂异构架构、超长链路调用、不明确的依赖关系、频繁迭代变更等现状，迫切需要提升智能运维可观测能力，增强系统韧性，防范可预见/不可预见的风险。

## 名词术语

- Kubernetes

简称
k8s，是用于自动部署、扩缩和管理容器化应用程序的开源系统，是一个编排容器的工具，也是管理应用全生命周期的一个工具。Pod 是 Kubernetes 中可以创建和部署的最小单位。一个 kubernetes 集群主要是由控制节点(master)、工作节点(node)构成，每个节点上都会安装不同的组件。控制平面组件包括资源操作的唯一入口服务 ApiServer、集群资源调度 Scheduler、控制 Pod 的状态和生命周期的控制器 ControllerManager、集群资源对象存储 ETCD；节点平面主要包括负责维护容器生命周期管理的 kubelet、提供集群内部的服务发现和负载均衡的 kube-proxy、以及容器运行时等组件。

- eBPF

eBPF(extended Berkeley Packet Filter) 是一种可以在 Linux
内核中运行用户编写的程序，而不需要修改内核代码或加载内核模块的技术。

- Prometheus

Prometheus 是一个开源的系统监控和报警系统。

- Kafka

Kafka 是一个分布式数据流处理平台，可以实时发布、订阅、存储和处理数据流。

- Zookeeper

ZooKeeper
是一种分布式协调服务，主要用于解决分布式系统中的数据同步、配置管理、命名服务等问题。

- Flink

Flink
是一个用于大规模数据流处理的框架，非常适合实时日志解析。它可以从 Kafka 读取日志数据，进行解析和转换，并将结果发送到数据库中。

- Redis

Redis（Remote Dictionary
Server）是一个开源的内存数据库，提供高性能的键值存储系统，常用于缓存、消息队列、会话存储等应用场景。它支持多种数据类型，包括字符串、哈希表、列表、集合、有序集合、位图和 hyperloglogs 等。

- Neo4j

一个高性能的 NoSQL
图形数据库，将结构化数据存储在网络结构而不是表中，基于图的数据库管理系统，使用图形理论来表示数据关系，适合处理高度互联的数据结构。

- VictoriaMetrics

VictoriaMetrics（简称 VM）是一个支持高可用、经济高效且可扩展的监控解决方案和时间序列数据库，可用于
Prometheus 监控数据做长期远程存储。

- CloudEvents

CloudEvents
是一种规范，用于以通用格式描述事件数据，以提供跨服务、平台和系统的交互能力。事件格式指定了如何使用某些编码格式来序列化
CloudEvent。

- ERSPAN

ERSPAN（Encapsulated Remote Switch Port
Analyzer）  是一种网络流量镜像技术，用于将本地网络设备的流量通过三层网络（IP 网络）封装并传输到远程采集器，实现跨网络的远程流量监控与分析。

- NetStream

NetStream 是一项基于"流"来提供报文统计的技术。它根据报文的目的 IP 地址、目的端口号、协议号、源 IP 地址等关键值来区分流信息，并针对流信息进行数据流统计，再将统计信息发送至服务器供分析。

- PFC（Priority Flow Control）

基于优先级的流量控制技术，通过发送反压帧暂停低优先级流量，保障高优先级业务（如 RDMA）的零丢包。

- ECN（Explicit Congestion Notification）

显式拥塞通知机制，通过标记 IP 头部通知网络拥塞，避免因丢包导致的吞吐量下降。

- NOF

NoF（NVMe over Fabric），是在不同种类网络中传输存储协议的技术路线总称。
NoF 可以分为在 FC 网络上传输的 NVMe over FC，在 IP 网络上基于 TCP 协议传输的 NVMe
over TCP，以及基于 RDMA 技术的 NVMe over RDMA。

# **系统建设目标与原则**

## 系统建设目标

面对云原生环境下复杂异构架构、超长链路调用、不明确的依赖关系、频繁迭代变更、协议复杂、网络规模大、网络风险增多、故障排查较慢等现状，迫切需要引入企业级 SRE 运维体系，保证系统稳定性、增强系统韧性，防范可预见/不可预见的风险，为保障云化系统的业务连续性提供坚实基础。

智能运维可观测基础平台基于 eBPF 等技术建设企业级指标数据图谱，实现平台服务层、基础设施层可观测能力建设，业务目标如下：

1.  完善运维体系：支持面向服务的大运维体系建设，共同确保云上服务的稳定运行和高效运维。补齐当前云原生主动运维能力，引入 SLO 指标管理、完善效果评价手段。

2.  构建统一底座：建立统一的弹性可观测底座，并固化到云基础设施，实现能力的统一，管理的统一，效能的统一。

3.  故障定位：将各层级异常指标关联到云上业务全链路拓扑，实现便捷快速的对异常进行准确定位。以解决当前交易链路无法跨平台跨语言跟踪全行业务系统，导致全链路会中断，排查问题难。

4.  助力业务：实现内核和平台底座的指标有效关联，提供纵向业务指标到基础设施的全链路观测能力。当前全链路仅仅停留在应用服务间横向链路聚合。云平台基础设施服务和硬件的观测链路无法统一；应用适配云原生的指标体系还有待补足，微服务/容器化应用内核态监控手段不足。

5.  资源运营：实现云平台资源的容量管理，建立应用画像。深层次剖析云资源使用现状，从资源使用视角建立云成本的可观测性。

6.  应用会话分析：实现 TCP 会话分析、系统访问关系知识图谱、应用服务自发现、无链接资源识别等能力，为上层应用稳定运行提供分析和辅助能力。

7.  运维效率提升：实现精细化网络资源监控、故障智能定位、异常处置辅助、网络风险评估与预测等能力，提升运维效率。

8.  网络可视化：实现网络协议可视化、会话路径可视化、流量调度可视化，以直观的图形展示网络结构、流量路径和系统内系统间画像。

## 系统建设原则

- 先进性

系统应采用符合信息技术发展趋势和本行"十四五"IT 规划要求的体系架构，利用符合国际、国内标准的云计算技术规范，引进成熟稳定的云原生可洞察技术。如：

1\. 采用先进的 eBPF 内核技术，实现日志、 指标、链路的全面融合。

- 扩展性

智能运维可观测基础平台软件架构应能方便的支持业务功能的扩展，对底层计算、存储、网络资源进行抽象，使 CPU、内存、存储、网络等硬件变成可以动态管理的"资源池"，具备高度可扩展、灵活弹性等特点，支持高可用和负载均衡，满足未来业务发展的需要。

- 前瞻性

智能运维可观测基础平台在保持前瞻性的同时，要充分考虑需求增加和业务拓展带来的与其它平台和系统的交互问题，因此平台建设要确保与 IT 规划中其它平台和系统有效衔接，满足邮政储蓄银行未来业务发展。

- 安全性

智能运维可观测基础平台应采用完善的身份认证机制、分级权限管理机制，以保证业务操作的合法性；应对用户敏感数据进行安全存储；应制定可行的安全控制机制，提供运行管理监控和故障处理手段，保证系统稳定、安全运行。

- 可操作性

智能运维可观测基础平台应为其它调用方提供标准的 API 接口，方便其它平台对接。

- 灵活性

智能运维可观测基础平台应采用模块化设计，提供全面、丰富的参数设置，能够及时满足评级规则中各种模型、规则的更改要求。

# **系统功能需求分析**

## 业务总体需求概述

智能运维可观测基础平台着眼"业务+容器+云平台+基础设施"全链路，通过业务可观测、整体拓扑、应用洞察、网络洞察和云平台基础设施洞察等先进可观测技术的引入，以及与本行现有监控系统、APM 系统和日志系统的融合，提升云原生环境下全局的可观测能力。

建设智能运维可观测基础平台，向下对接各种开源的协议与数据源，可以补齐云、容器环境下可观测指标的空白，可以形成任意调用的深入网络的完整链路数据；向上对各种平台和应用场景提供数据服务，为现有的运维管控平台、统一监控平台、云计算管理平台、大模型、运维/安全大数据平台等提供全面、统一的覆盖业务应用和容器、各类软硬件、网络等各类基础设施的可观测数据，支持问题定界、云资源规划、容量规划、应用效能、成本优化、异常检测、辅助排障和风险评估等领域。

智能运维可观测平台从下到上分别包括对象层、采集传输层、数据预处理层、数据存储层和数据管理层，同时还包括对外的应用场景层。从功能上包括云平台基础设施洞察、容量洞察、网络洞察、查询路由、整体拓扑、指标管理、探针管理、元数据管理、数据预处理、任务管理、异常检测和辅助排障、事件驱动、存储管理、平台自监控、数据模型、应用会话分析、运维知识构建、网络可视化、网络评估、专用网络监控、运营能力支撑等，以提升云和容器环境下全局的可观测能力。平台整体功能架构规划如下：

1.  云平台基础设施洞察：实现 Kubernetes 集群各个层级资源对象和关键组件的指标，并可以以图形化的方式串联起来，可以呈现纵向关联的资源分层拓扑和具体的依赖关系。

2.  容量洞察：根据业务系统和云资源的多维度指标数据分析，实现业务访问量与云资源使用量的关联分析，进而形成具体的应用画像比如资源偏好，并逐步提升云资源的最优化利用和精细化管理粒度。

3.  网络洞察：实时采集网络链路层、网络层、传输层、TCP/UDP、网络流量等监控指标，为系统和网络的拓扑关系、网络健康状态、网络性能评估以及网络故障排查等提供依据。

4.  查询路由：通过构建高效、可扩展的数据访问层提供标准化、统一 API、可访问所有底层数据的数据服务。

5.  整体拓扑：通过 eBPF 实现应用和云平台、容器平台、云基础设施之间的依赖关系，同时结合 CMDB 里的应用逻辑关系和物理设备关系的关联，绘制出完整的全链路拓扑图。

6.  指标管理：实现指标数据的打标和分级能力，指标要丰富完善且有分级，同时通过参考业务规范针对关键的 metric 加入业务视角标签。

7.  探针管理：对于预装探针的虚机可以自动实时检测到机器、应用或服务，可以及时发现探针配置的更改或状态变化，并可以支持多样化采样策略的配置和管理。

8.  元数据管理：以同步 CMDB、云管数据，纳管环境信息等相关的详细数据，便于进行数据打标和关联，同时更好的理解和使用数据。

9.  数据预处理：通过数据清洗、转换、聚合、降维和打标等技术，实现数据结构化，优化数据处理流程，为后续的数据建模提供基础支持。

10. 任务管理：结合现有的任务处理平台，简化任务开发工作，并可实现任务调拨、任务资源分配和任务运行监控指标展示等功能。

11. 异常检测和辅助排障：通过各种洞察、事件、告警和可观测能力，及时捕捉系统中的异常现象，再结合火焰图、热力图等各类 dashboard、日志和链路等辅助问题排障。

12. 事件驱动：可采集现有的经过事件汇聚或过滤的符合 CloudEvents 协议的标准化事件信息，并进行事件处理。

13. 存储管理：通过完善的数据索引、数据冷热备份和数据清理等机制，确保数据的高可用性和检索效率。

14. 平台自监控：可实现对智能运维可观测基础平台本身的自监控，相关日志可存储到现有的日志平台。

15. 数据模型：可实现数据模型的管理，并可以根据不同的运维场景和业务需求自定义数据模型。

16. 应用会话分析：通过全面的会话指标分析，构建端到端的访问关系，识别异常流量和无链接资源，提出优化建议，确保系统运行的可靠性与高效性。

17. 运维知识构建：构建全网的系统访问知识图谱，展示各个系统内及系统间的连接关系，记录新增的访问关系，且支持回溯对比。

18. 网络可视化：通过网络协议可视化、会话路径可视化、流量调度可视化，实现端到端网络路径可视化，提升网络优化效率与故障响应速度。

19. 网络评估功能：结合网络健康度评估功能，对网络性能、设备负载等关键指标进行趋势分析与风险预警，提前规避潜在故障，降低业务中断风险。

20. 故障处置辅助：实现故障的根因分析、处置建议等能力，缩短故障处置时间，提升业务连续性保障水平。

21. 专用网络监控：提升监控覆盖范围，实现动态基线预警功能，提高网络监控的精准度和响应速度。

22. 运营能力支撑：将现有数据转化为运维数据资产，提供基于业务系统的容量相关指标统计报表，为分析和预测提供原子化基础数据服务。

## 需求分析原则

- 完整性：需求全覆盖，包括智能运维可观测基础平台功能需求、性能需求、接口及外部系统集成等。

- 正确性和可行性：保证需求和技术方案的关联性，使用用户语言和需求模型正确描述功能需求，同时保证在现有开发能力和系统环境下需求的可实现。

- 需求的必要性：智能运维可观测基础平台所有功能都是基于容器建设需求、业务实际需求以及技术前瞻性需求，所列需求都是重要且必须的。

- 简明性：简明清晰，使用业务术语或缩略语，表达清晰明了。

- 可检测和可跟踪：可根据需求设计测试目标和测试进度，可跟踪需求缺陷。

## 用户类别分析

智能运维可观测基础平台项目用户主要为平台超级管理员、业务系统管理员、审计人员、业务系统运维人员，业务系统只读人员。

+----+------------+-------------------------------+------------------+
| 编 | 业务用户 | 可操作内容 | 所属机构 |
| 号 | | | |
+====+============+===============================+==================+
| 1 | 平台 | 具有整 | 总行 |
| | 超级管理员 | 个平台的操作配置权限，包括所 | |
| | | 有的资源分配、系统设置、全局 | |
| | | 资源监控、任务监控等运维权限 | |
| | | ，以及应用侧使用功能的权限。 | |
+----+------------+-------------------------------+------------------+
| 2 | 业务 | 具备指定项目中的 | 总行 |
| | 系统管理员 | 探针、平台任务发布管理、集群 | |
| | | 资源等的管理使用及运维权限。 | |
| | | | |
| | | 。 | |
+----+------------+-------------------------------+------------------+
| 3 | 审计人员 | 具备对系统管 | 总行 |
| | | 理、项目管理、安全管理等角色 | |
| | | 操作集中进行日志审计的权限。 | |
+----+------------+-------------------------------+------------------+
| 4 | 业务系 | 具备系统运维功能相关的权限 | 总行 |
| | 统运维人员 | | |
+----+------------+-------------------------------+------------------+
| 5 | 业务系 | 具备系统只读权限 | 总行 |
| | 统只读人员 | | |
+----+------------+-------------------------------+------------------+

## 业务功能总体描述

### 总体业务功能

建设智能运维可观测基础平台工程包括采集传输、数据处理、数据存储、数据管理、场景管理、平台管理等功能模块，提升云原生环境下全局可观测能力。平台整体功能架构规划如下：

![](media/image2.png){width="5.768055555555556in"
height="3.1104166666666666in"}

> 采集传输：网络洞察、指标管理等。
>
> 数据处理：数据预处理、任务管理、数据模型等。
>
> 数据存储：存储管理等。
>
> 数据管理：容量洞察、查询路由、整体拓扑、元数据管理、事件驱动等。
>
> 场景管理：云平台基础设施洞察、异常检测和辅助排障、应用会话分析、运维知识构建、网络可视化、网络评估功能、故障处置辅助、专用网络监控、运营能力支撑等。

平台管理：平台自监控、探针管理。

### 典型业务流程

#### **跨语言全链路关联**

在我行的系统建设过程中，出现了不同语言系统之间相互调用的情况，例如 Java 调用 C，C 调用 Java。目前，行内对于 Java 应用内部的调用链路情况进行了相对完整的覆盖，然而在业务属性的跨语言系统应用之间的相互调用追踪方面尚存在一些不足。对此，此次项目建设将健全行内跨语言全链路关联的监控追踪能力。

通过 ebpf 系统调用事件分析调用链路，可形成通用的不带业务属性的系统全链路全局拓扑图。

实现带业务属性的交易全链路全局拓扑图，可通过以下路径：

保证 Java 应用与 C 应用中全局流水号一致，业务码进行业务标识，保证全局流水号一致后，进行 Java 应用与 C 应用的全局串联。通过这种方式，可以让时间段内的调用业务链路，使用头部获取的业务码进行业务区分。

![](media/image3.png){width="5.764583333333333in"
height="2.622916666666667in"}

#### **eBPF 内核态指标采集上报流程**

智能运维可观测基础平台业务架构主要利用 eBPF 探针实时采集云上 Metric 指标数据，构建云上应用访问关系；其次利用弹性应用探针动态对故障应用加入代码级别数据的采集，提供 Trace 单次请求的数据，进行问题定位分析；然后对采集的数据和其他监控数据进行统一分析，最终建立以业务为出发点、融合容器监控，提供云上业务访问的可洞察性，同时进一步增强运维云上业务故障追踪能力。

在关联请求中，eBPF 探针将采集到的单次请求中的数据输出到导出器中、通过导出器统一将 eBPF 探针数据进行发送。eBPF 探针将数据统一发给数据接收器后，数据接收器将数据存储到 Kafka 中，数据分析器实时消费 Kafka 中的数据并进行分析，将相关的数据进行集群信息填充、指标拆分和聚合、慢请求过滤，最终存储到 Elasticsearch 中。呈现组件作为中间转换层，进行前端查询，数据中间转发及调用。数据展示、用户操作界面，前端组件获取前端查询数据，用于前端展示。

![](media/image4.png){width="5.736111111111111in"
height="2.0256944444444445in"}

![](media/image5.png){width="5.652777777777778in"
height="1.3680555555555556in"}

#### **端到端 TCP 特征报文采集流程**

智能运维可观测基础平台通过定制开发 Agent 程序采集服务器流量数据，将 Agent 程序部署到需要采集流量报文的服务器上，Agent 程序负责实时采集网络报文并发送给分析器。采集程序使用 libpcap 函数库利用 AF_PACKET 技术，通过创建原始套接字 socket(AF_PACKET,
SOCK_RAW)，直接从网络设备驱动程序中获取数据包。

![https://i-blog.csdnimg.cn/blog_migrate/a908d49918e688416ad8c8701560fb5f.png](media/image6.png){width="3.407638888888889in"
height="3.5125in"}

流量采集抓包 Agent 程序在服务器后台运行，实时读取网卡的数据链路层数据帧报文，首先添加 GRE 封装的 ERSPAN 报文头，然后构造添加 IP 报文头，通过 UDP 协议将处理后的报文数据发生给分析器。ERSPAN 的工作原理基于[GRE 隧道](https://www.baidu.com/s?rsv_dl=re_dqa_generate&sa=re_dqa_generate&wd=GRE%E9%9A%A7%E9%81%93&rsv_pq=df1bb89a001a4830&oq=erspan%E7%9A%84%E4%BD%9C%E7%94%A8%E5%92%8C%E5%8E%9F%E7%90%86&rsv_t=2dd66D924gMIa09aOSeaJGszn0+Fnn9rP+3CtDJLekW6BS832em9F+1hLCI&tn=baidu&ie=utf-8)封装技术。它将所有的被镜像报文通过 GRE 隧道封装成 IP 报文，然后路由到远端的镜像设备的目的端口。这种封装使得镜像报文可以在路由的网络间传输，不受二层网络限制，从而实现了远程流量监控和故障分析 ‌。

#### **知识图谱构建流程**

智能运维可观测基础平台通过对接 CMDB 及监控、日志等系统，从多源数据中提取配置项与指标信息，经清洗整合形成标准化数据；随后通过规则匹配与机器学习技术抽取实体、属性及关系，融合时对齐异构数据并消解冲突，构建统一知识体系；进而采用图数据库存储拓扑关系与属性，形成可视化网络；最终基于图谱实现故障定位、影响分析、智能决策支持及自然语言问答等应用，并通过实时监测、版本管理与质量评估实现知识持续迭代，形成从数据治理到智能服务的闭环运维支撑体系。

## 非功能要求总体描述

+----------+------------------------------------------+----------------+
| 非功能项 | 非功能要求 | 非功能需求分析 |
+==========+==========================================+================+
| 安全需求 | 智能运维可观测基础平台安全技术能力包含 | 暂无 |
| | 数据安全、访问控制安全、日志安全等能力。 | |
| | | |
| | 1、数据安全包括： | |
| | | |
| | 1) 支持数据 | |
| | 在传输和存储过程中的完整性和防恶意篡改。 | |
| | | |
| | 2) 支持数据加密，Secret 用来存储敏感的 | |
| | 加密信息，包含一个或多个加密的配置文件或 | |
| | 配置项，支持键值对和配置文件，实现敏感数 | |
| | 据加密存储并对第三方不可见，如用户的账户 | |
| | 密码、控制台登录证书、用户的隐私信息等。 | |
| | | |
| | 3) 支持数据 | |
| | 库数据备份与恢复，数据至少保存最近 2 份。 | |
| | | |
| | 2、访问控制安全包括： | |
| | | |
| | 1) 提供访问控制功能，依 | |
| | 据安全策略控制用户对受保护资源的访问，确 | |
| | 保只有授权用户能够对受保护资源进行访问。 | |
| | | |
| | 2) 根据 | |
| | 用户、业务系统的权限进行授权和访问控制。 | |
| | | |
| | 3) 所 | |
| | 有 API 访问均需要经过身份认证之后才能执行 | |
| | ，通过身份认证插件利用客户端证书、持有者 | |
| | 令牌或身份认证代理来认证 API 请求的身份。 | |
| | | |
| | 4 | |
| | ) 每个通过身份认证的 API 调用都将通过鉴权 | |
| | 检查，通过访问控制组件（RBAC）对身份与资 | |
| | 源操作权限进行匹配，API 请求属性被所有策 | |
| | 略评估允许之后才能继续，否则拒绝该请求。 | |
| | | |
| | 3、行为安全风险安全包括： | |
| | | |
| | 1) 支持日 | |
| | 志审计，记录用户访问过程的完整日志，包含 | |
| | 用户登录时间、操作事件、结果等信息，同时 | |
| | 确保只有必要的人员才能访问审计日志 | |
| | ，并且只给予他们完成任务所需的最小权限。 | |
| | | |
| | 2) | |
| | 支持审计日志持久化存储，至少 185 天以上。 | |
| | | |
| | 4、其他安全风险： | |
| | | |
| | 1) | |
| | 平台内部程序间相互调用数据时，需要在请 | |
| | 求 api 上添加认证或 token，以防止数据泄露。 | |
| | | |
| | 2) 定期漏洞扫描，根据漏洞扫描 | |
| | 报告，针对不同的漏洞支持组件升级或补丁至 | |
| | 安全版本，确保系统组件的安全性与稳定性。 | |
+----------+------------------------------------------+----------------+
| 性能要求 | 智能运维可观测基础平台性能指标如下： | 暂无 |
| | | |
| | 1. | |
| | 根据监控规模的数量，支持快速横向扩展。 | |
| | | |
| | 2. 支持容器的秒级数据采集能力。 | |
| | | |
| | 3. 单个 eBPF | |
| | 探针支持至少 1 万 tps 的高并发指标采集能力。 | |
| | | |
| | 4. 核心页面响应 | |
| | 在每秒 100 并发情况下的处理速度不超过 3 秒。 | |
| | | |
| | 5. 支 | |
| | 持 1000 用户同时登录使用相关功能，系统支持 | |
| | 最大并发操作用户数量按最大用户数 50%计算 | |
| | ，系统支持并发操作用户数量要求在 500 个。 | |
| | | |
| | 6. 指标采集数据 | |
| | 格式基于 OpenTelemetry 下，代理资源消耗为 | |
| | CPU 小于等于 10%，内存使用小于等于 200MB。 | |
| | | |
| | 7. 后台数据处理能力要实现 95%处理实现小 | |
| | 于等于 5s，且吞吐能力要达到大于 300 万/s。 | |
| | | |
| | 8. | |
| | 数据服务针对时序库数据最新 1 小时数据，A | |
| | PI 接口的 QPS 需要达到 800 请求/s，简单查询返 | |
| | 回结果要小于 2s,复杂聚合查询返回小于 7s。 | |
| | | |
| | 9. 平台内部各组件之间 | |
| | 需要有自监控数据证明时效性、数据准确性。 | |
| | | |
| | 10. 智能运维可 | |
| | 观测基础平台查询最近 1 小时单个集群内的链 | |
| | 路、指标数据并完成数据组装返回给业务系统 | |
| | 的时间要求在 10 用户情况下 3 秒内返回结果。 | |
| | | |
| | 11. 应用监控系统的灾备应实现双中 | |
| | 心应用双活。数据库进行双中心流复制。平台 | |
| | 业务灾备切换 RTO\<=15 分钟，RPO\<=10 分钟。 | |
| | | |
| | 12. 平台故障 | |
| | 恢复时间要求：平台故障恢复时间为 60 分钟。 | |
| | | |
| | 13. 平台可用 | |
| | 性时间要求：年度平台可用率应达到 99.95%。 | |
| | | |
| | 14. 运行时间要求:7\*24。 | |
| | | |
| | 15. 数据备份和恢 | |
| | 复的时间在每日晚间系统空闲时处理，如 22: | |
| | 00-次日 6:00 之间，每次最长不应超过 2 小时。 | |
| | | |
| | 16. 平台自身应用日志需要接入到 | |
| | 已有的全行 ELK 平台中，以供后续排查问题。 | |
| | | |
| | 17. 网络设备 | |
| | 关键指标的采集和告警延迟需控制在毫秒级。 | |
| | | |
| | 18. 监控 Agent 的资源占用需低于设 | |
| | 备总资源的 1-5%，避免影响被监控设备性能。 | |
| | | |
| | 19. 支持 10000 台以上设备各类指标分 | |
| | 析报表生成和输出，输出时间不超过 5 分钟。 | |
| | | |
| | 20. 历史指标和报表数据检索时间小于 5 秒。 | |
| | | |
| | 21. Kafka | |
| | > Streams 处理能力需达百万级事件/秒。 | |
| | | |
| | 22. 可同时支持 | |
| | 8000 台交换机 TCP 特征报文数据压缩和存储。 | |
+----------+------------------------------------------+----------------+
| 容量要求 | 智能运维可观测基础平台容量需求如下： | 暂无 |
| | | |
| | 1. 平台运行日志 | |
| | 、业务相关日志持久化存储至少 185 天以上。 | |
| | | |
| | 2. 可洞察指标类数据持久 | |
| | 化保存 365 天以上，可设置自定义保存周期。 | |
| | | |
| | 3. 链路数 | |
| | 据支持保留 7 天数据，支持自定义保存周期。 | |
+----------+------------------------------------------+----------------+
| 可 | 智 | |
| 靠性要求 | 能运维可观测基础平台要具备多节点协同，不 | |
| | 间断提供服务功能，同时提供平台服务的运维 | |
| | 监控、告警能力，助力服务实现高可用，保证 | |
| | 整个系统的稳定运行。可靠性具体要求如下： | |
| | | |
| | 1、管理可靠性：平台采用高可用集群方式 | |
| | 部署，保证一定的冗余能力，当某个服务节点 | |
| | 发生故障时，能够自动进行故障发现、恢复。 | |
| | | |
| | 2、 | |
| | 数据可靠性：平台具备自动数据备份能力，当 | |
| | 数据存储发生故障时，平台保证不丢失数据。 | |
| | | |
| | 3、性能可靠性：eB | |
| | PF 探针单个节点支持在 10000TPS 情况下，占用 | |
| | 1C2G 性能资源。默认 eBPF 探针会进行数据阈值 | |
| | 过滤，当业务量过大时，探针触发熔断机制。 | |
| | 系统吞吐量应能够通过灵活的扩展方案提供处 | |
| | 理能力的扩展。故障注入探针在不注入故障时 | |
| | 不对业务有影响，当故障撤销时能秒级响应。 | |
+----------+------------------------------------------+----------------+
| 易 | 应支持一站式自动化部署和运维 eBPF 探针，系 | 暂无 |
| 用性要求 | 统配置 eBPF 探针页面启停，权限能力页面可配 | |
| | ，系统设计风格保持一致性，比如输入内容校 | |
| | 验规则，页面展示风格，类似模块的交互等。 | |
| | | |
| | 支持容器化部署的能力，能够使用脚本一键部 | |
| | 署。可以通过云管平台 Web 界面轻松实现集群 | |
| | ，自由组合策略以应对多变的突发业务流量。 | |
| | | |
| | 支持用户自定义平台角色及对应 | |
| | 权限，所有操作都可进行细粒度的权限管控。 | |
+----------+------------------------------------------+----------------+
| 业务连 | 平台建设需要 | 暂无 |
| 续性要求 | 具备高可用能力，在单个节点出现故障而中断 | |
| | 时，能够不间断提供服务功能，不影响整个系 | |
| | 统的稳定运行。针对关键数据采取定期备份措 | |
| | 施，预防数据丢失。在故障节点中断后，具备 | |
| | 告警功能，提醒运维人员及时介入。按照应急 | |
| | 预案采用适当的应对措施，恢复至正常状态。 | |
| | | |
| | 针对平台的健康状况，需 | |
| | 定期巡检，发现并解决隐患，提前采取预防措 | |
| | 施，从源头上降低故障事件发生概率，从而保 | |
| | 证业务的连续性。需借助自监控数据的累积， | |
| | 利用自监控系统提供的图标进行统计，帮助平 | |
| | 台开发运维人员、做出合理决策，如扩容等。 | |
| | | |
| | 平台在业务设计、数据库设计、存 | |
| | 储设计等方面应充分考虑扩展性，保证根据使 | |
| | 用情况进行快速扩缩容。平台应具备自动巡检 | |
| | 及自恢复能力，同时具有完善的监控告警能力 | |
| | 与日志记录，当出现特殊情况时通知运维人员 | |
| | 及时处理，保障服务 7\*24 小时不间断运行。 | |
| | | |
| | 针对平台的健康状况，需 | |
| | 定期巡检，发现并解决隐患，提前采取预防措 | |
| | 施，从源头上降低故障事件发生概率，从而保 | |
| | 证业务的连续性。需借助自监控数据的累积， | |
| | 利用自监控系统提供的图标进行统计，帮助平 | |
| | 台开发运维人员、做出合理决策，如扩容等。 | |
| | | |
| | 平台在业务设计、数据库设计、存 | |
| | 储设计等方面应充分考虑扩展性，保证根据使 | |
| | 用情况进行快速扩缩容。平台应具备自动巡检 | |
| | 及自恢复能力，同时具有完善的监控告警能力 | |
| | 与日志记录，当出现特殊情况时通知运维人员 | |
| | 及时处理，保障服务 7\*24 小时不间断运行。 | |
+----------+------------------------------------------+----------------+
| 故障应 | 平台必须建立在 | 1)针对备 |
| 急处理及 | 成熟稳定的硬件环境和应用软件基础上，通过 | 份恢复策略，需 |
| 灾备需求 | 完善的备份恢复策略、可靠的运行管理监控和 | 要对数据和配置 |
| | 故障处理手段来保障系统的运行稳定及安全。 | 进行定期备份。 |
| | | |
| | 1、备份恢复策略， | |
| | 需要对数据和配置进行定期备份，定期检查。 | |
| | | |
| | 2、运行 | |
| | 监控，需要提供多指标的监控，并建立监控视 | |
| | 图，定期巡检，设定合理监控阈值进行告警。 | |
| | | |
| | 3、故障处理手段，需要提供常见问 | |
| | 题的应急处理预案，故障发生时能及时恢复。 | |
| | | |
| | 4、 | |
| | 故障定位，根据平台提供的监控、日志、事件 | |
| | 、告警等数据，快速准确捕获系统异常信息。 | |
| | | |
| | 5、故障处理，提供常见问题快速处理手册， | |
| | 支持操作员进行异常处理无需进行业务判断。 | |
| | | |
| | 智能运 | |
| | 维可观测基础平台补充应急及灾备要求，项目 | |
| | 采用集群部署模式。基于 ES 数据库集群架构实 | |
| | 现高可用。项目中涉及的平台组件均以集群方 | |
| | 式部署，避免单节点运行。平台基于高可用运 | |
| | 行设计，即：在单一数据中心内，平台集群的 | |
| | 所有组件均能避免单点故障导致的平台瘫痪。 | |
+----------+------------------------------------------+----------------+
| 可扩 | 平台需具备水平扩展能力，当负载超过阈值 | |
| 展性需求 | 时，可通过扩容等手段分散压力，同时保证业 | |
| | 务、数据的正常运转。根据平台资源的承载能 | |
| | 力，按照设计要求可扩容存储、计算等资源。 | |
| | | |
| | 平台需要具备良好的架构，具备 | |
| | 插件方式的扩展能力来支持多协议、多模式等 | |
| | ，同时需要具备前瞻性，设计良好的 Restful | |
| | API 接口 | |
| | ，方便与其它系统平台的对接和新功能开发。 | |
| | | |
| | 支持动态 | |
| | 添加监测网络设备，适应数据中心规模增长。 | |
+----------+------------------------------------------+----------------+
| 兼容性 | 支持多厂 | |
| | 商设备（如 Cisco、华为、华三等）的采集协 | |
| | 议（SNMP、NetFlow、gRPC、Telemetry 等）。 | |
+----------+------------------------------------------+----------------+
| 其他 | 智能运维可观测基础平台具 | |
| | 备故障隔离能力，当平台发生故障时，故障影 | |
| | 响不跨越模块，系统整体功能能够正常运行。 | |
| | | |
| | 智能运 | |
| | 维可观测基础平台具备故障预警机制，面对预 | |
| | 警能自动采取策略，降低或避免故障的影响。 | |
+----------+------------------------------------------+----------------+

# **架构方案**

## 系统定位和范围

智能运维可观测基础平台隶属全行业务架构中"IT 工具服务"部分。

![](media/image7.png){width="6.0208661417322835in"
height="2.4978248031496064in"}

智能运维可观测基础平台建设覆盖我行"十四五"云平台规划中的平台服务云规划与建设中"应用运行支撑类（数据库平台服务、中间件平台服务）和应用运维支撑类（监控告警、日志归集、配置中心、流量控制、链路跟踪）等服务能力的建设"部分。

## 系统交互关系

![](media/image8.png){width="5.738194444444445in"
height="1.6701388888888888in"}

智能运维可观测基础平台是基于现有各平台的业务流程以及数据接口情况进行集成架构设计的，在这个过程中明确了智能运维可观测基础平台与各平台对接的数据内容和步骤，其中智能运维可观测基础平台会同步 CMDB 的资产信息，并补全平台、容器、虚拟机、网络和应用等数据。业务系统通过统一的接口调用智能运维可观测基础平台，以获取聚合指标、eBPF
trace、错误系统等数据。通过平台/系统间的深度融合，进一步提升整体运营效率和全局稳定性，实现数字化转型的战略目标。

## 系统演进路线

依据系统现状并对照业务需求基线分析，具体建设策略如下表所示：

表 4-1：系统建设策略列表

---

系统名称 建设方式 改建内容

---

一体化运维平台 配合联调对接测试 实现平台自身的容灾和自愈

企业级运维管控平台 配合联调对接测试 通过 API 获取相关指标数据、链路数据；迁移应用监控的计算及存储到智能运维可观测基础平台。

云计算管理平台 配合联调对接测试 通过 API 获取云资源对象信息、关联关系、配置信息等，实时获取指标、变更信息数据。

容器云平台 配合改造 通过 API 获取容器资源对象信息、关联关系、配置信息等，实时获取指标、变更信息数据。

配置管理系统 配合改造及联调 获取配置项及变更数据，获取运维对象属性及对象上下游关系数据，实时获取对象属性、关系变更数据。

大数据平台 配合联调对接测试 配合数据接入

网络流量可视化管理系统 配合联调对接测试 通过 API 获取流量信息或通过消息总线订阅实时获取流量信息。

统一监控系统 配合联调对接测试 通过 API 获取 CPU/内存利用率、接口等基础信息，通过消息总线实时获取告警信息。

云计算管理平台（全行 ELK） 配合联调对接测试 通过日志平台标准的接口完成应用、系统、设备等日志数据的接入分析。

SDN 控制器及分析器 配合联调对接测试 智能运维可观测基础平台通过 API 获取 TCP 报文、监控指标、调优记录、调优前后路径及带宽变化情况等信息等数据。

网络运维大模型 配合联调对接测试 智能运维可观测基础平台通过 API 对接 AI 大模型，可通过大模型查询知识库，给出处置建议和案例。

知识图谱系统 配合联调对接测试 通过 API 对接知识图谱系统，建立系统间、系统内部的交互和依赖关系。

---

## 应用功能架构

### 应用功能架构图

![](media/image9.png){width="5.738194444444445in"
height="3.2069444444444444in"}

通过智能运维可观测基础平台实现全栈监控，可以一站式全面掌握从基础设施、云网资源、中间件、数据库到应用、业务系统的多维度可观测监控能力，通过可视化界面全维度展示各层业务指标，一站式服务消除了分散监控带来的复杂性，减少运维人员在多个工具间切换的成本，将底层技术指标与业务层表现相结合，实现从 IT 运维到业务运维的转变，确保用户的体验质量和业务连续性得到保障。智能运维可观测基础平台包括数据采集、数据传输、数据预处理、数据模型、数据冷热备份、数据索引、数据清理、元数据管理、数据资产管理、整体拓扑、事件驱动、数据服务、应用可观测、云平台基础设施可观测、网络可观测、异常故障可观测、平台自监控、探针管理等功能模块。

### 功能清单

+---------------+------------------+-----------------------------------+
| 功能模块 | 功能项 | 功能点 |
+===============+==================+===================================+
| 采集传输 | 数据采集 | AI 算力卡指标采集 |
| | | |
| | | 网络指 |
| | | 标采集（链路层带宽采集、链路层包 |
| | | 采集、网络数据采集、网络协议采集 |
| | | 、传输层网络拓扑、传输层带宽采集 |
| | | 、传输层 TCP 指标采集、传输层 UDP 指 |
| | | 标采集、传输层会话定义指标采集）\ |
| | | 网络流量采集 |
| | | |
| | | (ICMP 流量采集、TCP 特征报文采集) |
| | | |
| | | 网络信息采集 |
+---------------+------------------+-----------------------------------+
| 采集传输 | 数据传输 | 数据库数据接入\ |
| | | 中间件数据接入 |
| | | |
| | | （web 中间件数据接入、消息中间 |
| | | 件数据接入、其他中间件数据接入） |
| | | |
| | | 其他平台数据接入 |
+---------------+------------------+-----------------------------------+
| 数据处理 | 数据预处理 | 数据清洗\ |
| | | 数据转换\ |
| | | 数据聚合\ |
| | | 数据降维\ |
| | | 数据打标 |
+---------------+------------------+-----------------------------------+
| 数据处理 | 数据模型 | 数据建模\ |
| | | 实时分析\ |
| | | 模型管理 |
+---------------+------------------+-----------------------------------+
| 数据存储 | 数据冷热备份 | 数据冷热备份 |
+---------------+------------------+-----------------------------------+
| 数据存储 | 数据索引 | 数据索引 |
+---------------+------------------+-----------------------------------+
| 数据存储 | 数据清理 | 数据清理 |
+---------------+------------------+-----------------------------------+
| 数据管理 | 元数据管理 | 元数据采集管理\ |
| | | 元数据变更\ |
| | | 元模型管理 |
+---------------+------------------+-----------------------------------+
| 数据管理 | 数据资产管理 | 数据资产\ |
| | | 数据派生\ |
| | | 数据标签管理\ |
| | | 数据权限 |
+---------------+------------------+-----------------------------------+
| 数据管理 | 整体拓扑 | 拓扑洞察 |
| | | |
| | | （链路拓扑构建、 |
| | | |
| | | 拓扑链路回溯功能） |
+---------------+------------------+-----------------------------------+
| 数据管理 | 事件驱动 | 事件汇聚\ |
| | | 事件过滤\ |
| | | 事件标准化\ |
| | | 事件处理 |
+---------------+------------------+-----------------------------------+
| 数据管理 | 数 | 支持 API 接口\ |
| | 据服务(查询路由) | 支持权限认证 |
+---------------+------------------+-----------------------------------+
| 场景管理 | 应用可观测 | 支持日 |
| | | 志数据、指标数据、链路数据可观测 |
+---------------+------------------+-----------------------------------+
| 场景管理 | 云平 | 支持 |
| | 台基础设施可观测 | 资源对象、GPU 资源、K8S 组件可观测 |
| | | |
| | | 支持资源分层拓扑 |
+---------------+------------------+-----------------------------------+
| 场景管理 | 网络可观测 | 网络可视化 |
| | | |
| | | 专用网络、运 |
| | | 营能力、访问关系、网络评估可观测 |
+---------------+------------------+-----------------------------------+
| 场景管理 | 异常故障可观测 | 智能告警、智 |
| | | 能定位、异常处置、配置快照可观测 |
+---------------+------------------+-----------------------------------+
| 平台管理 | 平台自监控 | 用户权限管理\ |
| | | 慢阈值配置管理\ |
| | | 可洞察组件自监控管理 |
| | | |
| | | （性 |
| | | 能指标、组件日志采集与分析、自监 |
| | | 控告警、告警事件查询、告警统计）\ |
| | | 数据降采样配置管理\ |
| | | 用户审计 |
| | | |
| | | （操作审计、日志审计） |
+---------------+------------------+-----------------------------------+
| 平台管理 | 探针管理 | 探针批量配置\ |
| | | 探针实时启停\ |
| | | 探针阈值配置\ |
| | | 探针数据传输管理\ |
| | | 采集策略管理\ |
| | | 部署管理 |
| | | |
| | | （可视化部署、版本管理） |
+---------------+------------------+-----------------------------------+

## 系统数据组成

智能运维可观测基础平台包括监控数据、日志数据、链路调用数据、事件数据等。

![](media/image10.png){width="5.738194444444445in"
height="2.672222222222222in"}

## 技术要求

### 可观测基础数据采集

#### **可观测基础数据**

根据监控对象分类，包括：**应用类、基础软件类、云资源类、基础设施类**。

根据监控指标领域分类，包括：**应用领域、基础软件领域、云资源领域、网络领域、计算领域、**存储**领域**。

![](media/image11.png){width="4.9319444444444445in"
height="2.572221128608924in"}

---

**领域** **监控项** **目标实现接入指标数量**

---

应用领域 业务&应用 50

基础软件领域 主机 200

基础软件领域 数据库 71

基础软件领域 中间件 179

基础软件领域 容器 1000

云资源领域 云 1400

网络领域 网络 300

**总计** **3150**

---

对接并获取现有监控系统采集的系统指标数据，实现数据的实时采集、自动更新和统一管理。平台需支持多数据源，包括日志平台、APM、统一监控、容器平台、云管平台、网络流量可视化管理系统、CMDB 等。通过多数据源适配对接，统一进行数据处理、分析，为不同的业务场景提供个性化的数据需求服务。

平台通过 API 接口、SNMP、WebService 协议、ES、kafka 等方式实现现有日志平台、APM、统一监控、容器平台、云管平台、NPM、CMDB 等数据采集。采集到的数据进入数据处理模块，进行清洗、转换、聚合等操作，以确保数据的一致性和可用性。随后，数据被存储到统一的数据库中，支持高效的查询和分析。平台还提供一套丰富的 API 接口，供不同业务场景调用，满足个性化的数据需求。

#### **基于 eBPF 的数据采集**

##### 新技术功能介绍

eBPF（扩展 Berkeley Packet
Filter）是一项革新性的 Linux 内核技术，它允许用户在安全的沙箱环境中运行自定义代码以实现对操作系统核心功能的扩展和操控。从最初用于网络数据包过滤，如今已广泛应用于系统调用跟踪、性能分析、网络安全策略实施、网络功能虚拟化等众多领域。使用 eBPF 可以无须直接修改内核或加载模块，就可在运行时注入并执行内核空间程序，极大提升了系统的灵活性与可编程性。实际应用上，eBPF 助力提升系统可观测性，如实时监控性能瓶颈；在网络优化与安全方面也发挥关键作用，通过动态调整网络处理逻辑，实现精细化的数据包处理和安全防护策略，从而带来了显著的性能提升和运维效率改进价值。

eBPF 程序是事件驱动的，当内核或用户程序经过一个 eBPF Hook 时，对应 Hook
点上加载的 eBPF 程序就会被执行。Linux 内核中预定义了一系列常用的 Hook
点，利用 kprobe 和 uprobe 技术动态增加内核和应用程序的自定义 Hook
点。基于 Just-in-Time (JIT) 技术，eBPF
代码的运行效率可媲美内核原生代码和内核模块。得益于 Verification
机制，eBPF 代码将会安全的运行，不会导致内核崩溃或进入死循环。

###### eBPF 与 APM 比较

云原生时代，对于云数据的采集，APM 希望通过代码插桩的方式来实现，利用插桩，收集包括指标、追踪、日志、函数性能剖析等在内的各类数据。但插桩的行为实际上改变了原始程序的内部状态，从逻辑上并不符合从外部数据确定内部状态的要求。

eBPF 技术可以很好的解决并具有较大的优势。运行 eBPF
程序无需改变和重启应用进程，不需要应用程序重新发版，eBPF 允许用户在不修改内核源代码的情况下，通过加载和执行自定义的 eBPF 程序来扩展内核功能。eBPF 程序通过 Hook
机制与内核交互，它们可以对进入和离开内核的事件进行过滤和处理，以实现网络数据包的监控、性能统计、日程排障、定位定界和安全审计等功能。

eBPF
零插桩可以在不修改业务代码的前提下实现的分布式链路追踪和持续性能剖析能力，并且 eBPF
的能力还能够提供一些传统 APM agent
无法观测到的网络细节，在有些场景下，能够为我们带来不一样的视角。eBPF
的能力覆盖了从内核到用户程序的每一个层面，因此我们得以跟踪一个请求从应用程序出发，经过系统调用、网络传输、网关服务、安全服务，到达数据库服务或对端微服务的全栈路径，提供充足的中立观测数据，快速完成故障的定界。

Linux 内核自 3.15 开始对 BPF 进行扩展，扩展后的 BPF 被称为 eBPF，完整的 eBPF
可观测性能力需要内核版本大于
4.14。对于较低版本的内核如果要实现一些功能就需要引入 eBPF 相关的
patch 才可以。以下是 linux 内核版本和关键 feature 的支持能力列表：

![](media/image12.jpeg){width="5.738194444444445in"
height="5.0465277777777775in"}

###### eBPF 优势

相比于传统的监控方式，通过使用 eBPF 进行采集和监控可以显著提高系统的可靠性和可用性，具备以下的优势：

- 高效性：内核中运行，可以避免用户空间和内核空间之间频繁的上下文切换，从而提高监控和诊断的效率

- 无侵入性：无需修改应用代码即可进行监控

- 灵活性：可以捕获各种内核事件的信息，可以自定义 eBPF 程序以实现特定需求

- 安全性：可以通过内核验证机制进行验证，从而避免恶意程序的运行

- 可扩展性：可以根据需要动态加载和卸载，从而可以在不需要重启系统的情况下进行监控和诊断

![](media/image13.png){width="5.540972222222222in"
height="3.404861111111111in"}

###### eBPF 应用场景

结合以上 eBPF 的介绍，当满足对应的 linux 内核版本时，它的应用场景会非常广泛和较多的延申，主要包括以下几个方面，当然针对我们本次的方案，我们主要是用于数据采集方面。

- 网络优化

eBPF 兼具高性能和高可扩展特性，使得其成为网络方案中网络包处理的优选方案：

- 高性能：JIT 编译器提供近乎内核本地代码的执行效率。

- 高可扩展：在内核的上下文里，可以快速地增加协议解析和路由策略

```{=html}
<!-- -->
```

- 故障诊断

eBPF 通过 kprobe，tracepoints 跟踪机制兼具内核和用户的跟踪能力，这种端到端的跟踪能力可以快速进行故障诊断，与此同时 eBPF 支持以更加高效的方式透出 profiling 的统计数据，而不需要像传统系统需要将大量的采样数据透出，使得持续地实时 profiling 成为可能。

- 安全控制

eBPF 可以看到所有系统调用，所有网络数据包和 socket 网络操作，一体化结合进程上下文跟踪，网络操作级别过滤，系统调用过滤，可以更好地提供安全控制。

- 性能监控

相比于传统的系统监控组件比如 sar，只能提供静态的 counters 和 gauges，eBPF 支持可编程地动态收集和边缘计算聚合自定义的指标和事件，极大地提升了性能监控的效率和想象空间。

###### eBPF 与可观测性

随着本行基础设施逐渐的云化，系统也会变得越来越复杂，可观测性也必须不断发展才能跟上不断变化的需求。通过实现良好的可观测性，企业可以提高系统稳定性、优化性能和资源利用率、加速故障排查和问题解决。

eBPF 不能代表可观测性，可观测性也不完全通过 eBPF
来实现。它只是可观测领域的收集数据的一种手段。结合传统的 APM 或者各类日志、监控等数据，同时把 eBPF
作为可观测性的一种数据源的补充，可以给我们提供更细粒度的观测能力，或者提供一种全新的信号量，从而使得我们更好的掌控系统运行情况。

![](media/image14.png){width="5.260416666666667in" height="2.30625in"}

为了满足可观测性，我们需要采集丰富的系统指标数据，从全景图来看可以分为以下四类指标数据：

- 1 类型的 Metric 数据是 Linux /proc 下数据，Promethues 和 Zabbix
  等主流监控数据就来自于 /proc 下的统计数据，APM
  探针也会有部分统计数据如 TPS、平均时延、错误率等。

- 2 类型的数据当前是 APM 产品主要采集的数据，该类型数据大量通过 APM
  trace
  进行展示，并不是以常规指标形式展示，少部分数据以常规指标形式展示。

- 3 类型的数据，当前该类型数据采集工具缺失，如 BCC
  等工具是作为小工具临时使用，业界并未有监控工具将该部分数据作为可观测性数据
  7X24 小时运行保存展示。

- 4 类型的数据，当前主要还是专家型技术人员通过 BCC、Bpftrace、Ftrace
  等工具去获取内核函数执行情况。

![](media/image15.png){width="5.220138888888889in"
height="4.413888888888889in"}

对于 3 和 4 类型的数据，就是我们重点需要通过 eBPF 来实现的，有了这些数据基础，便于后续的全方位云上资源和应用等多维度的链路追踪和完整的拓扑关系展示。

##### 基于 eBPF 的采集实现

为了满足探针管理、云平台基础设施洞察、容量洞察、网络洞察、整体拓扑和异常检测辅助排障等全部或部分功能需求，从技术实现上首先要实现 eBPF 的能力并可以兼容和覆盖现有统一监控平台采集 agent 的全部功能。同时需要梳理所有需要满足的协议以及相关的指标。其次考虑到本行 linux 内核版本的特性和所使用中间件的情况，需要进行 eBPF 功能加强，甚至需要加强 cBPF。再就是因为从
eBPF
采集到的原始字节流中很难用通用的方法提取业务语义，所以必须和现有的 CMDB 等元数据系统进行关联，注入调用粒度和服务粒度的业务语义。最后就是针对具体的追踪、全链路、完整的拓扑关系、Trace 查询和一些关键的洞察通过 eBPF 采集技术来具体实现，并逐渐的深入和扩展。

目前本行的内核版本 70%以上都是 4.18 或以上，低版本核心的应用随着信创的改造，也会逐步迁移至高版本环境中。所以在可观测平台中，将针对内核版本 4.0 以上版本实现基于 BPF 的采集能力，其中通过内核中的 cBPF 获取和过滤网络数据包，而通过 eBPF 从内核空间扩展到用户空间，以获取更多的数据。

##### 基于 eBPF 采集的 agent 实现

Agent 是一种部署在服务器或其它基础设施设备上的轻量级软件，它可以实现对 IT 系统的实时监控、故障定界定位排查和性能优化等功能。它需要具有高度的灵活性和可扩展性，并能够根据不同的业务需求进行定制化的配置。

为了达成 agent 非功能上的高性能和高安全性要求，以及功能上的完整可覆盖云主机、k8s 等的数据采集和 agent 本身灵活下发及策略管理，从技术实现上会采用安全高性能并支持并发和跨平台的编程语言。

![](media/image16.png){width="5.955555555555556in"
height="3.3916666666666666in"}

对于 agent 采集的数据，从观测信号上会分为以下几类：

1、指标数据：

- 基于 eBPF（Linux 内核版本在 4.0+及以上）采集所有服务的全栈 RED
  黄金指标数据。

- 基于 cBPF（Linux Kernel 4.0+）采集所有服务的全栈 RED
  黄金指标、网络性能指标。

2.  链路数据：

- 基于 eBPF（Linux Kernel 4.0+及以上）分析 Raw Request
  数据的关联性，并聚合计算出完整的分布式调用链。

- 基于 cBPF（Linux Kernel 4.0+）数据，编写 WebAssembly Plugin
  在解析本行的全局业务流水号的基础上关联 Raw Request
  数据，计算出分布式调用链。

3.  性能剖析数据：

- 基于 eBPF（Linux Kernel
  4.0+及以上）并结合其它技术比如 Pyroscope 等采集程序进度内函数粒度的持续性能剖析数据，并与分布式追踪数据进行自动关联。

- 基于 cBPF（Linux Kernel
  4.0+）分析网络包的时序，生成网络性能剖析数据以协助推断应用性能瓶颈。

> eBPF 采集数据示例如下所示：

---

**数据源类型** **采集点**

---

eBPF 客户端进程

eBPF 服务端进程

---

> cBPF 采集数据示例如下所示：

---

**数据源类型** **采集点**

---

cBPF 客户端网卡

cBPF 客户端容器节点

cBPF 客户端宿主机

cBPF 客户端到网关宿主机

cBPF 客户端到网关

cBPF 本机网卡

cBPF 其他网卡

cBPF 网关到服务端

cBPF 网关宿主机到服务端

cBPF 服务端宿主机

cBPF 服务端容器节点

cBPF 服务端网卡

---

除了观测信号之外，agent 还需要可以采集到主流开源 Agent、SDK
的观测数据，例如 Prometheus、OpenTelemetry、SkyWalking、Pyroscope
等；同时还要可以采集到 CMDB 等标签元数据中的全部资源和服务信息，用于为所有观测信号注入统一标签，以实现完整链路数据展示和拓扑关系。

因本行目前存在多厂商多版本的私有云和多个 k8s 集群，所以 agent 必须要都能够独立运行在以上环境里，针对不同的环境会有不同的技术实现：

- 对于 Linux 服务器，以进程形态运行即可，可以采集服务器中所有进程的观测数据。

- 对于 k8s 集群的 Node 节点，以 Daemonset 的独立 Pod 形态运行即可，可以采集
  K8s Node 中所有 Pod 的观测数据。

- 对于每个 K8s Pod 中，以 Sidecar 形态运行即可，可以采集 Pod 中所有
  Container 的观测数据。

- 对于 KVM、Hyper-V
  等宿主机，以进程形态运行即可，可以采集所有虚拟机的观测数据。

- 对于独占的虚拟机，以进程形态运行即可，可以采集并分析来自 VMware
  VSS/VDS 的镜像网络流量。

- 对于独占的物理机，以进程形态运行即可，可以采集并分析来自物理交换机的镜像网络流量。

为了满足 agent 的灵活下发及策略管理，从技术实现上会采用声明式 API 对所有 agent 进行控制，这样所有 agent 的配置可以通过服务端进行统一管理和灵活下发，为了更好的策略和场景化管理，从技术实现上需要定制多种特定配置来实现：

- 最大资源限制，为了防止 agent 占用较多资源，甚至抢占其它业务应用的资源，通过对 agent 进行最大资源限制来实现，比如最大内存限制和最大 cpu 使用量限制等。

- 最大线程数数量，为了防止 agent 占用过多资源或过多线程，通过对
  agent 的最大线程数数量进行限制来实现。

- 采集正则配置，为了特定需要或采集数据可控，通过对网卡或特定指标的采集正则配置来实现，此配置可以灵活设置都需要对哪些网卡或指标进行数据采集，比如 pod 网卡、node 网卡、虚拟网卡、KVM 网卡、host 网卡、特定过滤条件下的数据流等。

- 为了实现特定的策略，比如必要时的熔断、必要时的放弃采集等场景，需要可以实现灵活的配置，比如是否允许 agent 继续采集、允许采集的范围或上报数据的配置，可以通过服务端额外的设置来实现，比如设置为 enable 或 diable，当为 disable 时即不再上报任何数据，当配置指标列表时只允许采集这些指标数据，当配置时间窗口时只在这个时间范围内进行采集等，而这些配置可以通过 server 端配置后按需自动下发到特定的 agent。

本行的 k8s 集群使用了不同的 CNI，对于这些不同的 CNI，在实现 agent 时会有不同的技术方案。

在常见 k8s 环境下，对于同一个 Node 上的两个 Pod 互访时，会通过采集 eBPF
Syscall 和 cBPF Pod NIC 两种位置的数据来实现；对于不同的 Node 上的两个
Pod 互访时，会通过采集 eBPF Syscall、cBPF Pod NIC 以及 cBPF Node NIC
三种位置的数据来实现。

![不同 K8s CNI 下的数据采集能力（Pod 与 Pod
通信场景）](media/image17.png){width="5.718055555555556in"
height="3.775in"}

但是在某些特定 CNI 下，由于流量路径的特殊性，很难完整地采集到以上的数据，所以要有特定的实现技术，以下进行部分 CNI 的举例说明，并没有包括全部的 CNI，特殊的 CNI 需要特定的技术去应对。

对于 Cilium cni，因 Cilium 使用 XDP (opens new window)将网络绕过了 TCP/IP
协议栈，会导致名为 lxc-xxx 的 Pod
NIC 上只能看到单向流量。同一个 Node 上的两个 Pod 互访时，只能采集到 eBPF
Syscall 一种位置的数据，而不同的 Node 上的两个 Pod 互访时，为了采集到 eBPF
Syscall 和 cBPF Node NIC 两种位置的数据，需要通过 Node eth0 来实现。

在 MACVlan、华为云 CCE Turbo (opens new window)等 CNI 环境中，使用
MACVlan 子接口而非 Veth-Pair + Bridge，此时在 Root Netns 中是没有对应的
Pod NIC，技术上可以通过 Node eth0 上的数据来实现，结合它可以看到所有 Pod
的所有流量，在实现时会新增额外的配置，当此配置为 true 时会将 Node NIC
上的流量等同于视为是在 Pod NIC 上采集到的。

在 IPVlan CNI 环境中，使用 IPVlan 子接口而非 Veth-Pair + Bridge，此时在
Root Netns 中是没有对应的 Pod NIC，且仅能在 Node eth0 上看到 Pod 进出
Node 的流量，同样需要采集  Node eth0 上的流量来实现。

对于特殊 k8s 集群或者 CRD，需要对资源进行特定的配置，比如 ingress 等，同时需要配置 Kubernetes
API 权限。

对于 agent 的非功能性要求特别是性能要求，通过多策略定制和配置来实现对于页面或者配置选项上，可以通过简单配置并下发即可。相关实现的策略包括：

- 特定数据是否脱敏，会减少很多数据量，进而减低 request 数据开销。

- 对于 Pod NIC、Loopback NIC 等网卡，可通过配置精简，减少采集流量大小。

- 对于采集流量方面，可通过各种特定表达式降低采集流量大小。

- 对于原始数据，可通过长度截取的方式配置长度大小，从而降低原始数据的长度。

- 针对内存缓冲区，支持配置长度降低内存缓冲区大小，比如 eBPF
  数据缓冲区大小、PCAP 组装缓冲区大小、TCP 包头缓冲区大小和 gRPC
  缓冲区大小等。

- 对于内存队列尺寸和哈希表尺寸也可以通过配置的方式进行降低。

### 端到端 TCP 特征报文采集

#### **功能描述**

为满足平台的应用会话分析、访问关系知识图谱构建以及故障定位、风险分析等核心能力建设，需要采集端到端的 TCP 特征报文，并从中提取关键指标进行深度分析和故障排查。利用 ERSPAN、AF_PACKET 等相关技术，获取网络设备、服务器等节点上的 TCP 特征报文流量，统一数据格式并存储到平台数据库中。

#### **技术方案**

网络设备侧 TCP 特征报文采集依赖于分析器，分析器已经支持
Kafka，平台可直接订阅 TCP 特征流相关的数据。

服务器侧 TCP 特征报文采集依赖于 AF_PACKET 和 BPF 技术。AF_PACKET 套接字允许用户空间的应用在数据链路层捕获数据包，从而可以查看数据链路层以上的传输层、应用层的所有内容。为了提高收发性能，该实现使用 PACKET_MMAP 机制，它提供了一个在用户空间和内核之间共享的环形缓冲区，用于发送和接收数据，减少用户空间和内核之间系统调用内存拷贝。BPF 是一种高效、灵活的机制，主要用于网络数据包捕获时的过滤，可根据自定义的筛选规则在捕获数据包时进行过滤。

**网络侧流程设计：**

(1) 分析器通过 API 接口对接平台；

(2) 分析器将 TCP 特征流信息通过 Kafka 上报给平台 TCP 特征报文采集模块；

(3) 通过网络信息采集模块获取设备 IP、设备名称等信息，并进行归一化处理；

(4) 防火墙策略计算：若路径经过防火墙，则查询五元组匹配策略，决定流量是否允许通过；若匹配 NAT 规则，则修改流量的源/目标 IP；

(5) 负载均衡策略计算：若路径经过负载均衡设备，目标地址会发生一次转换，则通过 VS/Member 查询修改目标 IP；

(6) 容器网路路径对接：针对输入的源 IP 反查容器网络拓扑，基于容器网络 Node 与物理接入交换机建立拓扑连接关系；

(7) 将处理后的数据写入新 Kafka 消息。

![](media/image18.png){width="5.732638888888889in"
height="2.097916666666667in"}

**服务器侧流程设计：**

(1) 在服务器上部署 agent 采集器，该采集器通过 AF_PACKET 抓取流量报文，通过 BPF 筛选出 TCP 特征报文（SYN、SYN
ACK、FIN），并记录时间戳、网卡等信息。

(2) agent 将抓取到的报文转发给平台 TCP 特征报文采集模块；

(3) 通过网络信息采集模块获取设备 IP、设备名称等信息，并进行归一化处理；

(4) 将处理后的数据写入新 Kafka 消息。

![](media/image19.png){width="5.736805555555556in"
height="2.3243055555555556in"}

### 运维大数据

#### **功能描述**

运维大数据平台通过全域数据采集、沉淀运维数据支撑智能分析、场景化应用，实现 IT 系统的高效治理与主动式运维。采用分层架构，覆盖数据采集、传输、计算、存储、分析到应用的全流程，包含数据采集层、消息总线、计算处理层、数据存储层、数据服务，实现运维数据的高效处理与深度应用。

系统性能要求：

1、吞吐能力：支撑  200+万笔/秒数据   实时处理。

2、端到端延迟：数据从采集到可查询延迟  \<5 秒。

3、高可用性：系统整体可用性  ≥99.95%，支持跨机房容灾。

4、数据一致性：保障  Exactly-Once  语义，无数据丢失或重复。

#### **技术方案**

![](media/image20.png){width="5.408794838145232in"
height="3.0267782152230973in"}

总体架构设计

该技术架构采用分层设计，分为数据采集层、数据整合层、数据存储层和应用层，支撑运维大数据的全流程处理与分析。

- 数据采集层：通过自建采集器，对接现有各类指标/日志采集数据，获取日志数据、调用链路采集等各类指标/监控数据，覆盖网络流量、应用端口、业务会话等维度，实现原始数据的高效汇聚。采集数据经消息缓存（如 Kafka）削峰填谷后进入整合层。

- 数据整合层：基于 Flink 计算集群实现实时/离线数据处理，完成数据清洗、关联分析与标准化。通过对象发现与关系采集模块，构建运维对象（如设备、服务）间的拓扑关系；任务管理模块统一调度采集、计算任务，运行监控模块实时跟踪作业状态及集群性能，确保数据处理链路的稳定性。

- 数据存储层：采用分层存储策略，时序数据、日志数据、调用链路数据等按类型存储，结合关系型数据库管理对象/拓扑数据，支撑上层灵活查询与分析。

- 应用层：通过指标、链路、日志、告警等多维度可视化，提供网络流量分析、故障定位、容量预测等场景化服务。事件驱动机制结合实时分析模块，实现异常检测与自动化告警。整体拓扑映射物理与逻辑资源关系，辅助全局运维决策。

处理的数据量巨大，系统按不同的处理任务类型划分集群。如 NPM 独立构建处理集群，
APM 独立构建处理集群，
eBPF 独立构建处理集群、聚合分析任务独立构建处理集群。因此，以下是不同类型数据的存储方案：

- 时序数据在处理后写入 Kafka 缓存，同时 Flink 消费进程负责数据落盘对应的时序数据库。

- 日志数据在处理后写入 Kafka 缓存，同时 Flink 消费进程负责数据落盘对应的 ES 数据库。

- Trace 数据在处理后写入 Kafka 缓存，同时 Flink 消费进程负责数据落盘对应的 ES 数据库。

##### 数据处理

###### 数据预处理

####### 数据清洗

数据清洗功能支撑对采集的原始数据进行缺失值填补、数据去重、异常值检测等处理，确保数据的准确性、完整性和一致性。

支持缺失值处理，对于数据缺失进行预警提示，并且可以选择采用填充、插值等方法来填补缺失值。包括均值、中位数、众数填充，或者使用自定义预测模型填充。

支持重复值处理，根据数据重复判别规则（如相同时间戳重复数据）及合并、清除策略，对数据进行重复性辨别，并对重复数据进行合并或清除处理。

支持异常值处理，结合业务逻辑定义阈值或使用统计方法识别和处理异常值，支持对不符合业务逻辑的异常数据（如 CPU 使用率小于 0）进行处理，包括删除异常值或将异常值替换为统计值（如平均值、中位数）。

数据清洗功能基于预设的判别规则和算法，通过自动化的手段对原始数据进行识别、分析和处理，以消除数据中的噪声和异常，提高数据的质量。

数据加载：从数据源（如 Kafka 消息队列、数据库等）加载原始数据。

缺失值处理：在数据加载过程中，根据预设规则实时监测数据的完整性，发现缺失值，发出预警提示。根据用户配置或默认策略，对缺失值进行填充。支持的填充方法包括均值填充、中位数填充、众数填充以及自定义预测模型填充。对识别出的缺失值执行填充操作，并记录填充详情，以便后续审计和追溯。

重复值处理：根据业务需求和数据特性，设定重复值判别规则。例如，对于时间序列数据，可以基于时间戳和关键字段的组合来判断数据是否重复。应用判别规则对数据进行遍历，识别出重复值。根据配置的策略，对重复数据进行合并或清除处理。合并时，可选择保留一条记录并合并相关字段的值；清除时，则直接删除重复记录。

异常值处理：结合业务逻辑和统计方法，定义异常值的阈值。例如，对于 CPU 使用率，可以设定一个合理的上下限作为阈值。遍历数据，将超出阈值的记录标记为异常值。根据用户配置的策略，对异常值进行处理。支持的处理方法包括删除异常值、将异常值替换为统计值（如平均值、中位数）等。处理过程中，需记录异常值的详细信息及处理结果，以便后续分析和审计。

数据验证与输出：对清洗后的数据进行验证，确保数据的准确性、完整性和一致性。验证内容包括但不限于数据的范围、格式、关联性等。将清洗后的数据输出到指定的存储介质（如数据库、文件系统等），供后续分析和使用。

####### 数据转换

数据转换实现将各数据源采集的原始数据从一种格式、类型或编码转换为另一种，实现相同类型数据的格式统一。

支持格式转换，将不同来源、不同格式的数据转换为统一的格式，如将 CSV 格式的数据转换为 JSON 格式的数据，便于后续的数据处理和分析。

支持数据类型转换，根据数据分析的需求，将数据转换为适当的类型，如将字符串类型的数据转换为数值类型，以便进行数学运算和统计分析。

支持数据编码，对于分类数据，采用适当的编码方法进行转换，以便将其转换为数值形式供后续分析使用。

通过制定明确的转换规则和方法，数据转换功能确保转换后的数据与原始数据在业务逻辑上保持一致，同时提高数据的可读性、一致性和可用性，为后续的智能运维工作提供数据基础。

数据转换功能主要基于中间件技术和规则引擎技术实现。中间件技术用于处理不同格式和类型的数据转换，而规则引擎技术则用于实现灵活的编码转换和数据校验。

数据格式转换：采用中间件的方式进行数据格式转换，实现不同格式数据的统一处理。通过定义一套标准的数据格式（如 JSON），针对每种原始数据格式（如 CSV、XML 等），开发相应的解析器和转换器。解析器负责将原始数据解析为中间格式，而转换器则负责将中间格式转换为标准格式。通过这种方式处理各种格式的数据，并将其统一转换为标准格式，以便后续处理和分析。

数据类型转换：为了确保数据的正确性和可分析性，根据数据分析的需求，将数据转换为适当的类型。如，分析场景需要进行数学运算，需要将字符串类型的数值数据转换为数值类型。通过数据类型转换模块，根据数据预定义的规则，自动转换为需要的数据类型。

数据编码转换：对于分类数据，需要将其转换为数值形式，以便进行后续分析。编码转换模块支持多种编码方法（如独热编码、标签编码等）。用户可以根据数据的特性和分析需求，选择合适的编码方法。编码转换模块自动将分类数据转换为数值形式，并将其与原始数据关联起来，以便后续处理和分析。

数据校验和一致性维护：为了确保转换后的数据与原始数据在业务逻辑上保持一致，在数据转换过程中，记录每个数据项的转换规则和转换结果，并进行校验以确保转换的正确性。提供数据溯源功能，允许用户追溯每个数据项的来源和转换过程，以便在发现问题时进行快速定位和解决。

####### 数据聚合

数据聚合根据规则对采集的原始数据进行分组、计算，形成高层级的聚合数据，为上层业务系统提供通用数据聚合能力。通过数据聚合将多个数据点的信息合并到一个汇总值中，以便更容易地进行分析和可视化。

支持指标聚合，对多个相关的指标进行聚合处理，如计算平均值、求和、最大值、最小值等，生成更具代表性的综合指标。

支持时间聚合，按照时间维度对数据进行聚合处理，如按日、周、月等时间粒度进行汇总。

业务系统可以通过调用平台的基础统计聚合逻辑函数（平均值、求和、最大值、最小值等）和分组聚合逻辑函数，提升数据聚合效率，降低开发维护成本。

数据聚合功能基于分布式计算和数据仓库技术，通过分布式计算框架实现大规模数据的并行处理和高效计算，通过数据仓库技术实现数据的存储、索引和查询。同时，结合业务需求和数据特性，设计合理的聚合规则和算法，以确保聚合结果的准确性和可靠性。

数据接入与预处理：从各个数据源接入原始数据，进行预处理操作，如数据清洗、去重、异常值处理等。

数据存储与索引：将预处理后的数据存储到分布式数据库或数据仓库中，并建立相应的索引以提高查询效率。同时，根据数据的特性和业务需求，设计合理的数据模型和数据结构，以便于后续的聚合操作。

聚合规则定义：提供灵活的聚合规则定义机制，允许用户根据业务需求自定义聚合规则。这些规则包括指标聚合规则（如平均值、求和、最大值、最小值等）和时间聚合规则（如按日、周、月等时间粒度进行汇总）。用户可以通过图形化界面或 API 接口进行聚合规则的配置和管理。

聚合计算引擎：高效的聚合计算引擎，负责根据预定义的聚合规则对存储的数据进行分组和计算。支持并行处理和分布式计算，能够处理大规模数据并提高聚合计算的效率。同时，提供多种聚合算法和优化策略，以适应不同的业务场景和需求。

聚合结果存储与查询：将计算得到的聚合数据存储到数据库中，并建立相应的索引以便于查询。提供高效的查询接口，允许业务系统通过 API 或图形化界面实时获取聚合数据。同时，支持对历史聚合数据的存储和查询，以便于进行趋势分析和对比分析。

####### 数据降维

数据降维通过数学变换或算法，将高维数据转换为低维数据，同时尽可能保留原始数据的关键信息和特征。通过数据降维有助于减少数据的存储和计算成本，提高数据处理的效率和准确性，从而为后续的业务监控、分析和决策制定提供有力支持。通过数据降维减少数据集中的特征数量，提高数据处理的效率并降低计算成本，如监测系统存储的容量使用情况，包括每个存储设备的总容量、已用容量、剩余容量等，通过数据降维，可以通过计算设备存储利用率反映存储使用情况。

数据降维主要基于数学变换和机器学习算法，通过线性变换（如 PCA）或非线性映射（如 t-SNE）等方法，将原始高维数据投影到低维空间中，同时尽可能保持数据的内在结构和关键信息。算法的选择和优化需考虑数据的特性、降维目标以及计算复杂度等因素，以实现降维效果与计算效率的平衡。

数据预处理与特征选择：针对预处理后的原始数据进行特征选择，识别并保留对后续分析重要的特征，剔除冗余或无关特征。

降维算法集成与应用：集成多种数据降维算法，如主成分分析（PCA）、线性判别分析（LDA）、t-SNE、U-map 等，以适应不同场景和需求。用户可根据数据特性和业务目标，选择最合适的降维算法。算法的应用考虑数据的规模、稀疏性、非线性关系等因素，确保降维效果的最佳化。

参数优化与模型训练：针对选定的降维算法，进行参数优化，如选择 PCA 时确定主成分的数量，或使用网格搜索、随机搜索等方法优化算法参数。通过交叉验证等技术评估降维效果，确保在低维空间中尽可能保留原始数据的关键信息，保存模型参数，以便对新数据进行快速降维处理。

降维结果评估：提供降维结果的评估指标，如降维后的数据保留率、聚类效果、分类准确率等，帮助用户量化降维效果。

降维模型部署与集成：将训练好的降维模型部署到智能运维观测平台中，实现与数据采集、处理、分析等环节的无缝集成。提供 API 接口，允许其他业务系统调用降维服务，实现数据的实时或批量降维处理。

####### 数据打标

数据打标功能可以为采集到的云平台、容器平台等数据添加自定义的标签，以便于分类、检索和分析。通过标签，用户可以快速定位到关心的数据，提高数据处理的效率和准确性。

通过添加特定的标签，比如系统号、中心编号、业务类型等关键字段。数据分析人员能够更精确地理解业务状况，洞察数据背后的趋势和规律，从而为运维决策提供有力的数据支持。

数据打标功能基于标签管理和标签存储技术。通过为数据添加额外的标签，实现对数据的细粒度分类和检索。标签的存储和管理采用数据库技术，确保标签数据的完整性和一致性。同时，通过权限管理机制，保障标签及其关联数据的安全性。

标签体系设计：标签体系应涵盖系统号、中心编号、业务类型等关键字段，以满足不同场景下的数据分类和检索需求。标签的设计应遵循简洁明了、易于理解的原则，同时确保标签的唯一性和可扩展性。

标签存储与管理：设计标签存储结构，用于保存标签及其与数据的关联关系。根据数据规模、查询性能要求，采用关系型数据库存储标签数据。提供标签管理界面或 API，允许用户创建、编辑、删除标签，并查看标签的关联数据。

数据打标流程：在数据采集或处理过程中，根据预设的规则或用户手动操作，为数据添加相应的标签。可以自动化完成，也可以由用户手动触发。自动化打标可以通过预设的数据映射关系或正则表达式来实现，而手动打标通过用户界面提供交互操作。

标签检索与分析：提供基于标签的数据检索功能，允许用户通过指定标签快速定位到关心的数据。同时，支持对标签进行统计分析，如统计某个标签下数据的数量、分布情况等，为运维决策提供有力支持。

标签权限管理：为了保障数据的安全性，对标签的访问和修改权限进行严格控制。根据用户的角色和职责，分配不同的标签权限，只有授权用户才能访问或修改特定标签及其关联数据。

###### 数据模型

####### 数据建模和模型管理

数据建模允许用户根据业务需求，定义并创建各类数据模型，确定数据的逻辑结构，如指标数据模型、链路数据模型、日志数据模型（涵盖应用、系统及中间件日志）以及 CMDB 资产数据模型。这些模型将作为数据收集、存储、处理和分析的基础，确保数据的准确性、一致性和高效性。

通过数据建模，用户可以自定义数据的结构、属性、关联关系等，以适应不同的运维场景和业务需求。同时，数据建模功能还支持模型的版本管理，便于跟踪和回溯模型的变更历史。

模型管理功能负责对数据模型进行全面的管理和维护。包括模型的创建、编辑、删除、查询、版本管理等操作。通过模型管理，用户可以方便地管理平台中的各类数据模型，确保模型的准确性和有效性。

支持模型分类管理，包括：实时监控告警模型，1 分钟内发现异常情况；实时定位模型，5 分钟内定位异常位置；异常处理模型（应急处理 SOP），15 分钟内解决问题。

数据模型创建：用户根据业务需求，在平台上创建新的数据模型，并定义模型的属性、字段和关联关系。

数据模型编辑：对已存在的数据模型进行编辑，修改模型的属性、字段或关联关系，以适应业务变化。

数据模型删除：对不再使用的数据模型进行删除操作，以释放系统资源。

数据模型查询：用户可以在平台上查询已有的数据模型，查看模型的详细信息和关联关系。

采用分布式存储系统（如 Hadoop HDFS、Ceph 等）和大数据计算框架（如 Apache
Spark、Presto 等），对海量数据进行高效存储和计算。利用数据流处理框架，如 Apache
Flink、Kafka 等，实现实时数据处理和分析。

####### 实时分析

数据实时分析实现对平台收集到的各类数据进行实时处理和分析，以提供实时的运维监控和决策支持。包括对性能指标基线预警模型、资源使用趋势分析模型、监控数据异常告警模型等。

通过数据实时分析，用户可以及时发现系统中的异常情况，快速定位问题根源，并采取有效的应对措施，实现 1 分钟对异常情况告警，5 分钟定位问题，15 分钟解决问题。

###### 事件数据处理

####### 事件驱动

统一整合各领域告警源数据，构建事件全生命周期治理策略，实现告警的标准化、智能化、体系化闭环管理，提高告警应对的效率和质量。减少、规避事件带来的损失和影响，持续提升业务的持续可用性。

![](media/image21.png){width="5.738194444444445in"
height="2.3604166666666666in"}

事件分析治理围绕提升告警时效性、加快影响分析、提高处置速度三个方面进行建设：

**1）提升告警时效性：**实现告警的实时接收和处理，缩短告警延迟时间；避免重复告警，提高告警信息准确性，对告警进行智能分类和优先级排序，优先处理影响较大的告警，并及时发送预警通知。

**2）加快影响分析：**自动识别和分析不同数据集之间的关联关系，帮助快速定位问题；对影响进行智能评估，确定其严重程度和范围。

**3）提高处置速度：**根据智能告警的特征和优先级，自动执行相应的处置流程加速事件的处置能力和效率；建立沟通协作、信息共享、知识沉淀等功能，加速问题排查和解决过程。

![](media/image22.emf){width="5.738194444444445in"
height="2.7444444444444445in"}

- **汇聚**：将日志、事件、指标等多源数据进行整合，运用信息熵分析技术，对告警进行筛选过滤，剔除其中的噪音告警，输出信息富化后的告警流，为后续分析提供高质量数据基础。

- **探索**：对富化后的告警流开展关联分析，借助主动检测手段，利用多维关联、时序相似、关联拓扑、语义相似等方法，挖掘数据间潜在联系，定位可解决问题、服务中断和业务中断的具体时间，构建关联关系拓扑数据。

- **推理**：基于关联关系拓扑数据，深入分析因果关系，对数据进行聚集处理，推荐可能性根因，降低问题平均诊断时间。同时，将成功案例和经验进行知识沉淀，使其能够广泛复用，不断优化推理模型。

- **协作**：依据相似情境，实现人机协作处置。通过反馈学习机制，持续提升协作效率，减少问题平均修复时间，确保技术方案在实际应用中不断完善和优化。

####### 事件汇聚

统一事件集成汇聚，旨在整合来自不同监控工具的各类事件数据，打破数据孤岛，为后续的分析处理提供全面、统一的数据基础，实现：

（1）多源数据接入：能够兼容多种不同类型、不同厂商的监控工具，如网络监控、日志监控、基础监控、应用性能监控（APM）等工具。无论是来自硬件设备、软件系统，还是业务流程中的监控数据，都可以实现无缝接入。

（2）提供数据源管理功能，可以配置相关的指标、事件、配置等数据，并支持对数据进行采集、传输、存储、清洗等操作。

（3）支持数据传递的高可用性和容错性，确保数据的可靠性和完整性。

通过高效的事件汇聚机制，实现跨平台、跨系统的统一事件管理，为后续的事件处理与分析提供坚实基础。

构建高可靠、可扩展的多源监控数据汇聚平台，通过标准化接入、高效传输、智能处理和安全存储，实现跨系统、跨平台的事件数据统一管理，为后续分析决策提供坚实数据基础。

**核心技术架构**

方案采用分层架构设计，包含四大核心模块：

**1、接入适配层**

- 支持插件化扩展，动态加载 Prometheus、Zabbix 等多种监控工具的适配器

- 维护元数据映射库，自动转换不同数据源字段格式

**2、数据通道层**

- 基于 Kafka 构建高性能消息队列，支持百万级 QPS 吞吐量

- 采用多副本机制（默认 3 副本）和自动分区重平衡，保障数据不丢失

- 支持事务性生产者，确保幂等性写入

**3、处理引擎层**

- 基于 Flink 实现流批一体处理，支持实时数据清洗与转换

####### 事件过滤

事件过滤实现对汇聚到平台的事件进行筛选和过滤，以去除重要等级低或重复的事件，减轻后续处理负担。通过设定灵活的过滤规则，如事件级别（警告、错误、严重错误）、事件类型（性能异常、安全告警）、关键词匹配等，实现对事件的有效筛选。

**1、规则配置中心**

- 可视化规则定义：支持通过界面或 API 配置过滤条件，包括：

- 基础条件：事件类型、时间戳、数据源、严重等级等字段匹配。

- 复杂表达式：支持正则表达式、数学运算（如阈值比较）、逻辑组合（AND/OR/NOT）。

- 动态参数：允许引用外部配置（如字典表、阈值库）或实时计算值（如事件频率）。

- 多维度分组策略：支持按主机、组件、业务线等标签对规则进行分组管理，便于批量应用与调整。

**2、动态过滤引擎**

- 规则优先级管理：支持自定义规则执行顺序，确保关键过滤逻辑优先处理。

- 实时数据处理：基于流处理框架（如 Flink/Kafka

  > Streams）实现实时数据过滤，延迟控制在毫秒级。

- 批处理扩展：支持离线数据批量过滤，适用于历史数据回溯场景。

####### 事件标准化

在集成汇聚多监控工具事件数据时，面临着不同监控工具数据格式与内容各异的挑战。需具备数据标准化与清洗，以及数据字段丰富的关键能力：

1、数据标准化与清洗

能够运用预先设定的规则和算法，对从多种监控工具采集到的原始数据开展处理工作。一方面，自动识别并剔除其中重复、错误或无效的数据，保证数据的质量。另一方面，将不同格式的数据统一转换，确保不同来源的数据具有一致性和可比性，为后续分析奠定坚实基础。

在事件标准化环节，平台会把来自不同源头的事件数据，全部转换为统一的
Events
协议格式。凭借对各种自定义或标准事件格式的解析能力，精准提取如事件 ID、事件类型、事件时间、数据源、数据内容等必要字段，并严格按照
Events
规范重新组装。经过标准化处理的事件，在平台内部具备更高的一致性和可互操作性，无论是处理还是分析都更加便捷高效，从而显著提升运维的效率与准确性。

2、数据字段丰富

为进一步提升事件数据的价值，平台通过引入规则库、字典表等方式，对事件数据进行字段补充。借助规则库中预设的逻辑和条件，以及字典表中丰富的参考信息，能够深入挖掘事件数据的潜在内容，有效提高事件数据的丰富程度，为后续深入分析和精准决策提供更全面的信息支撑。

将不同监控数据源中接入的事件数据，通过配置标准化映射至系统标准事件格式，支持直接映射，级联映射（多个字段通过规则连接），条件映射（设置复杂条件，当满足条件时触发映射）支持将标准化后的事件字段拼接作为告警的指纹。

采用分层架构设计，包含以下核心模块：

**1、数据解析层**

- 维护元数据映射库，记录各数据源字段对应关系

  **2、数据清洗层**

- 基于哈希算法实现实时去重（事件 ID + 时间戳指纹）

- 支持批流一体处理（Flink/Kafka Streams）

  **3、标准化转换层**

- 定义统一 Events 协议格式，包含事件 ID、类型、时间、来源等元数据

- 实现多维度映射规则（正则表达式、字段拼接、类型转换）

- 通过规则引擎动态执行标准化逻辑

  **4、字段丰富层**

- 集成规则库和字典表

- 支持错误码映射、地理位置解析、业务标签关联

关键技术实现

1、**动态配置管理**

- 可视化规则配置界面，支持条件组合、优先级设置

- 规则热加载机制（无需重启服务生效）

  2、**高性能处理引擎**

- 并行处理架构（多线程 / 分布式集群）

####### 事件处理

具备全面且强大的事件处理功能，以高效管理和优化各类事件，具体功能要求如下：

**告警数据优化处理**

1.  **基于规则与算法的优化**：利用预设的规则和先进算法，实现告警定级，精准判断告警的严重程度。同时执行降噪操作，压缩冗余事件数据，有效过滤掉无用事件，并将相关告警进行聚合。例如，在大规模服务器集群监控中，自动识别并合并来自同一服务的相似告警，减少冗余信息干扰。

2.  **多维度告警规则压缩**：支持按照主机、组件、告警分类等多维度对告警规则进行分组压缩。通过这种方式，能够依据不同维度的特点，对告警进行合理整合与管理，提升告警处理的针对性和效率。

3.  **智能文本相似度压缩**：平台具备智能压缩能力，尤其体现在文本相似度压缩方面。对于短时内产生的告警，能够通过智能匹配技术，将相似文本内容的告警进行压缩，避免重复处理相似告警信息，提升处理效率。

4.  **专家经验驱动的压缩**：支持专家依据丰富的运维经验，灵活配置压缩策略。当主告警引发一系列次生告警时，可按照专家设定的规则进行压缩合并，确保告警处理符合实际运维逻辑，减少不必要的告警干扰。

5.  **匹配压缩特殊场景处理**：在短时间内出现大量告警 -
    > 恢复信息的特殊场景下，如网络多次瞬断，平台能够进行智能匹配压缩，将这些相关信息合并为同一事件进行处理，避免因频繁告警信息导致的处理混乱。

**事件全生命周期协同管理**

1.  **多渠道协同告警处理**：实现事件全生命周期管理，支持企业微信、钉钉等多种主流即时通讯渠道协同处理告警。用户可以在这些渠道中对告警和故障进行认领、分派、处理、解决、关闭以及评论，打破信息孤岛，促进团队间高效协作。

2.  **第三方平台联动**：能够与第三方平台无缝联动，生成工单流转至相关处理流程。同时与自动化平台协作，实现故障协调处置的自动化和无缝衔接，提升故障处理的及时性和准确性，减少人为干预带来的延迟和错误。

3.  **告警升级与应急处置**：对于长时间未解决的告警，平台自动进行升级处理，并协同相关人员迅速展开排查和应急处置。通过及时有效的升级机制，确保重要问题得到足够关注，避免故障影响范围扩大。

4.  **故障改进闭环**：支持制定详细的故障改进措施，明确故障责任人及团队。通过这种方式，对故障进行深入分析和总结，从根源上解决问题，形成完整的故障改进闭环，不断提升系统的稳定性和运维效率。

**事件分析方案：**

- **自适应算法：**可以学习和适应不同的数据模式和变化，动态地调整模型参数和阈值，实现高效的自动化告警和事件管理。

- **多维度关联算法：**可以处理大量的实时数据流并自动多维度关联事件，从而提高事件处理的准确性和效率。

- **非监督式机器学习算法：**可以自动识别和发现未知的事件模式，并自动更新其模型，以及对新数据进行有用的分析。

- **智能编排算法：**可以自动识别不同的事件类型并调整不同类型的工作流程，以最大化其处理效率。

![](media/image23.png){width="5.738194444444445in"
height="2.1770833333333335in"}

**闪断过滤：**配置闪断过滤窗口使得告警和恢复告警在某个时间窗口内先后到达事件分析系统时，事件分析通知模块，不再发出频繁的通知。

**告警生成：**告警生成时，通过对历史告警数据的时序统计分析，得到告警的振荡、周期、频发、偶发、激增等时序特征。基于告警的时序特征和原始告警的严重等级得到告警的推荐等级和处理优先级。

**配置风暴预警：**当数据源在短时间内生成大量的告警时，发出风暴预警通知，并抑制该数据源的告警通知，防止用户被告警通知轰炸，直至风暴结束。

**跨告警源合并：**分组压缩（支持按分组标签进行合并；支持按照主机、组件、服务及自定义字段分组压缩）；根据配置的条件，事件因为同一原因的导致的，最后自动生成为同一条告警。

**告警分派及通知**：当告警出现创建，认领，关闭事件时通过配置的分派条件和用户接收告警的习惯，将通知通过各类预先配置的渠道通知给用户。

**告警升级**：配置升级策略，当告警产生之后，满足配置的过滤条件的告警持续一段时间内没有被解决，则将告警等级升级并发送通知给特定用户。

**规则聚合**：通过配置专家规则和关联规则，将一系列符合配置的规则的告警聚合成一个故障。

**算法聚合（语义、时序、拓扑算法）**：将告警通过语义，时序，拓扑的智能算法聚合成故障。

**知识沉淀**：当告警/故障被关闭时可以填写告警/故障处理时的经验总结并生成关联的知识，通过 DIA 系统的智能推荐算法，将沉淀的知识推荐给相似的告警/故障，也可手动创建知识。

##### 数据存储

###### 数据冷热备份

平台提供冷热备份相结合的策略。实时或频繁访问的"热"数据存储于高性能存储系统中，确保快速响应业务需求，同时，将较少访问的"冷"数据迁移到成本效益更高的存储介质上进行长期保存。保证数据的高可用性和即时访问效率，又优化了存储资源的利用，确保数据安全性的同时，也兼顾了经济性与可持续发展性，为企业的数据资产管理提供坚实基础。

数据冷热备份功能基于数据分类、存储分层和自动化迁移技术。通过对数据进行细粒度的分类，将不同访问频率和重要性的数据存放在不同的存储层次上，实现存储资源的优化利用。同时，通过自动化的数据迁移和备份机制，确保数据的高可用性和安全性。

存储系统架构：设计包含高性能存储系统和低成本存储介质的混合存储架构。高性能存储系统用于存放"热"数据，确保快速响应业务需求；低成本存储介质则用于存放"冷"数据，实现长期保存和成本优化。

数据分类与迁移策略：制定数据分类标准，根据数据的访问频率和重要性将数据划分为"热"数据和"冷"数据。设计数据迁移策略，自动将长时间未访问的"热"数据迁移至低成本存储介质，同时将因业务需求重新变为频繁访问的"冷"数据迁移回高性能存储系统。

数据备份与恢复机制：实现定期的数据备份机制，确保"热"数据和"冷"数据均能得到妥善备份。设计高效的数据恢复流程，能够在数据丢失或损坏时迅速从备份中恢复，保证业务连续性。

监控与管理界面：提供直观的监控界面，展示数据的访问频率、存储位置、备份状态等关键信息。设计管理界面，允许管理员手动调整数据分类、迁移策略、备份周期等参数，以适应不同的业务需求。

安全性与合规性保障：在数据迁移和备份过程中，采取加密、签名等安全措施，确保数据的安全性和完整性。遵循相关的数据保护和隐私法规，确保数据处理的合规性。

###### 数据索引

平台具备高效精确的数据检索与分析能力，通过直观的可视化界面简化数据检索流程。支持多种数据检索模式，加速从数据洞察到决策制定的快速转化，为运维团队提供了强有力的支持与保障。

数据索引功能基于索引构建、检索引擎和可视化界面等模块的协同工作。索引构建模块根据预处理后的数据构建高效的数据索引；检索引擎模块提供多种检索模式，支持快速查询和数据分析；可视化界面模块以直观的方式展示检索结果，帮助运维团队快速洞察数据。

数据索引架构：构建高效的数据索引架构，支持对云平台、容器平台、基础设施等生成的大量数据进行索引和检索。包含索引构建模块、检索引擎模块和可视化界面模块。

索引构建模块根据预处理后的数据，构建高效的数据索引，支持快速检索和查询。

检索引擎模块提供多种数据检索模式，如关键词检索、范围检索、组合检索等，满足不同的数据查询需求。

可视化界面模块通过直观的可视化界面展示检索结果，提供数据分析工具，帮助运维团队快速洞察数据背后的趋势和规律。

索引算法选择：选择适合的索引算法，如倒排索引、B 树索引、哈希索引等，根据数据的特性和查询需求进行优化。倒排索引适用于全文检索场景，B 树索引适用于范围查询场景，哈希索引适用于精确匹配场景。

分布式存储与检索：考虑到数据量庞大，采用分布式存储和检索技术，将数据和索引分布在多个节点上，提高系统的可扩展性和并发处理能力。

实时索引更新：实现实时索引更新机制，确保新增或修改的数据能够即时反映在索引中，保持数据的时效性和准确性。

流程设计如下：

1.  **索引构建**：根据预处理后的数据，选择合适的索引算法构建数据索引。

2.  **数据存储**：将预处理后的数据和索引存储在分布式存储系统中，确保数据的可扩展性和并发处理能力。

3.  **检索请求处理**：接收用户的检索请求，解析请求参数，调用检索引擎进行数据查询。

4.  **结果展示**：将检索结果以直观的方式展示在可视化界面上，提供数据分析工具帮助用户洞察数据。

5.  **实时索引更新：**监控数据源的变化，实时更新索引，确保数据的时效性和准确性。

###### 数据清理

平台提供数据存储配置能力，并提供磁盘数据清理能力，识别磁盘上占用空间较大的文件和目录，提供配置保留天数及手动执行清理功能。

数据清理功能基于数据存储配置和磁盘空间管理的协同工作。通过数据存储配置模块，制定合理的数据存储策略，确保数据的及时备份和删除。通过磁盘数据清理模块，识别并清理占用空间较大的文件和目录，释放磁盘空间。在整个过程中，通过数据恢复与备份功能，确保重要数据的安全性和可恢复性。

数据存储配置：允许用户根据业务需求和数据特性，制定不同的数据存储策略，如数据保留天数、数据备份频率等。提供自动化配置工具，根据存储策略自动分配存储空间，确保数据的及时备份和删除。实时监控磁盘空间使用情况，当空间接近阈值时，自动触发告警通知管理员。

磁盘数据清理：通过扫描磁盘，识别占用空间较大的文件和目录，提供详细的报告，包括文件大小、创建时间、修改时间等信息；允许用户为不同类型的数据设置保留天数，超过保留天数的数据将被标记为可清理；提供用户界面，允许管理员手动选择并清理指定的文件或目录；自动化清理，根据配置的保留天数，自动清理超过期限的数据，释放磁盘空间。

数据恢复与备份：在清理数据之前，进行数据备份，确保重要数据不会丢失。提供数据恢复功能，允许管理员在需要时恢复已清理的数据。

流程设计：

1.  存储策略制定：管理员根据业务需求和数据特性，制定数据存储策略，包括数据保留天数、数据备份频率等。

2.  磁盘扫描与识别：系统定期扫描磁盘，识别占用空间较大的文件和目录，并提供详细的报告。

3.  清理决策制定：根据存储策略和磁盘扫描结果，系统自动或手动制定数据清理决策，标记超过保留天数的数据为可清理。

4.  数据备份：在清理数据之前，系统自动进行数据备份，确保重要数据不会丢失。

5.  数据清理执行：根据清理决策，系统自动或手动执行数据清理任务，释放磁盘空间。

6.  清理结果报告：系统生成数据清理结果报告，包括清理的文件数量、释放的磁盘空间等信息。

7.  数据恢复（可选）：如果管理员需要恢复已清理的数据，可以使用数据恢复功能进行操作。

###### 数据部署与容灾

**总体采用同城双活，异地灾备总体方案：**

同城热备：单中心异常切换同城热备集群

异地灾备：跟随业务灾备切换、异地提供监控服务

全局应用：全局应用双活，数据北京为主合肥备份

![](media/image24.png){width="5.738194444444445in"
height="2.7465277777777777in"}

**采集层高可用容灾：**高可用一方面在于集群内组件的高可用，能够在故障后自动恢复，从而减少人为干预。我们的
Flink、Kafka，还是实际存储、远程存储，均是分布式解决方案，单实例故障后可自动容灾，因此不需要过多地关注。通过双采，以单发模式（主备模式）向后端发送数据，对实时接入数据的情况进行检测，若无实时数据则判定该实例故障，从而进行切主。

**计算与存储高可用保障：**虽然
Kafka、Flink、时序数据库都是高可用，但却并不能保证数据不会遗失。因此，在
Flink 或时序数据库宕机恢复后，可以基于已经引入的 Kafka 实现数据重传。因为
Flink
进行计算时会周期产出数据，如果通过 Kafka 重传的数据不满一周期，那么我们将向前推移多个周期并丢弃第一周期数据，从而保证最终计算数据在多次执行后均能保持一致性。

**两地五中心高可用：**为保证整体集群的无故障，构建了"两地五中心"方案。在北京同城构建三套中心，合肥同城构建两套中心，数据同时发往两套中心且其中数据完全一致，实现同城双活。单中心故障的情况下，通过切换最终仪表盘查询入口以获取最新正确数据。异地保障则配合客户业务，搭建一套实时存活灾备集群，在业务流量切换至异地灾备中心时，通过灾备中心监控服务对其监控。

##### 统一数据对外接口

###### API 接口

API 接口功能构建统一的数据组件支持，对多源异构数据的高效汇聚，对外提供标准化、高效的数据访问接口，实现数据服务的高效调用与访问，促进跨系统的数据互联互通。

系统间采用 API 接口作为主要的数据交互方式，支持可视化开发 API、SQL 创建 API、注册 API 三种方式开发或纳管外部 API，满足不同开发能力的用户。

接口设计：采用 RESTful 风格设计 API 接口，确保接口的通用性和易用性。接口 URL 将采用资源路径+操作方式的形式，如/api/v1/metrics 表示获取度量指标数据的接口。根据操作类型选择合适的 HTTP 方法，如 GET 用于数据查询，POST 用于数据提交，PUT 用于数据更新，DELETE 用于数据删除。通过 URL 参数、Query 参数或请求体传递请求参数。对于复杂的数据结构，将使用 JSON 格式进行传输。统一使用 JSON 格式作为响应格式，包含状态码、消息提示和数据体三部分。状态码用于表示操作结果，消息提示用于提供额外的信息，数据体则包含具体的业务数据。

数据交互：对平台内部数据进行标准化处理，确保对外输出的数据格式统一规范。采用 OpenTelemetry 标准作为数据交换的标准格式。对于大数据量的查询操作，将支持分页和排序功能。分页参数包括页码和每页条数，排序参数包括排序字段和排序方向。根据业务需求提供数据聚合功能，如按时间、地域、业务类型等维度进行聚合统计。

安全控制：采用 OAuth2.0 协议进行身份认证，确保只有授权用户能够访问接口。外部系统需要通过获取访问令牌的方式进行身份验证。根据用户的角色和权限对接口调用进行权限验证。将采用 RBAC（基于角色的访问控制）模型进行权限管理。对敏感数据进行加密传输和存储，确保数据的安全性。将采用 HTTPS 协议进行数据传输加密，并采用 AES 等加密算法对数据进行存储加密。记录接口调用的日志信息，包括请求时间、请求方法、请求参数、响应结果等，以便进行安全审计和故障排查。

###### 权限认证

API 接口的权限认证采用身份验证机制，确保每个 API 请求都能在严格的身份认证及权限控制下进行。保护敏感数据的安全性，防止未经授权的访问，实现了细粒度的权限管理，使得不同角色和部门的用户仅能访问到与其职责相匹配的数据资源，在提升数据利用效率的同时，保障了企业的信息安全与合规性。

> 身份验证通过验证访问令牌的有效性来确认请求者的身份，令牌在颁发时经过数字签名以确保其在传输过程中的完整性和不被篡改。确认请求者身份后，系统会根据其角色和权限信息对请求进行严格的权限校验，包括检查请求者是否拥有访问目标 API 接口的权限，以及是否具备执行特定操作的权限。此外，权限认证机制支持动态策略应用，允许管理员根据业务需求灵活调整角色的权限配置，无需修改代码或重启服务。
>
> 基于 OAuth2.0 的身份认证机制：
>
> 认证流程：外部系统首先通过用户授权获取访问令牌（Access
> Token）。此令牌将在后续 API 请求中作为身份验证的依据。
>
> 令牌管理：平台将维护一个令牌存储系统，用于存储和验证访问令牌的有效性。令牌包含用户的身份信息、有效期等关键信息，且令牌在过期后需要重新获取。
>
> 基于 RBAC（基于角色的访问控制）的权限管理：
>
> 角色定义：根据业务需求，预定义多个角色（如平台超级管理员、业务系统管理员、运维人员等），并为每个角色分配相应的权限。
>
> 权限分配：将具体的 API 接口与预定义的角色进行关联，确保每个角色只能访问其权限范围内的 API 接口。
>
> 动态权限调整：平台支持管理员根据业务需求动态调整角色的权限，以应对业务变化和安全策略更新。
>
> 细粒度的权限控制：
>
> 资源级权限控制：除了角色级权限控制外，还支持对特定资源（如数据表、数据集等）进行细粒度的权限控制。
>
> 操作级权限控制：对于每个 API 接口，支持定义多种操作权限（如查询、修改、删除等），确保用户只能执行其权限范围内的操作。
>
> 日志审计与监控：
>
> 日志记录：记录每次 API 请求的详细信息，包括请求时间、请求者身份、请求内容、响应结果等，以便进行后续审计和故障排查。
>
> 实时监控：对 API 接口的调用情况进行实时监控，及时发现并处理异常请求和潜在的安全风险。

### 知识图谱

#### **功能描述**

通过整合 CMDB 配置数据与多源运维信息，构建动态智能知识图谱，实现系统访问关系知识图谱、故障定位及根因分析等能力。

#### **技术方案**

##### 数据准备

明确数据来源：从 CMDB 中提取各类配置项（CI）信息，如服务器、网络设备、应用系统等，包括它们的属性（如型号、配置参数）和相互之间的关系（如连接关系、依赖关系）。同时，结合其他运维数据源，如监控系统产生的性能指标数据、日志系统中的操作日志、故障管理系统中的故障记录等，扩充数据维度。

数据清洗与预处理：对从 CMDB 及其他数据源获取的数据进行清洗，去除噪声、重复和错误数据。统一数据格式和编码，对缺失值进行处理，例如通过统计方法填充或根据相关规则推算。对于不一致的数据进行校正，确保数据的准确性和一致性。

##### 知识抽取

实体抽取：从 CMDB 数据和相关运维文档中识别出运维实体，如设备名称、系统名称、软件版本等。可以使用基于规则的方法（如正则表达式匹配）或基于机器学习的模型（如
BERT + CRF 模型）进行实体抽取。

关系抽取：识别实体之间的关系，如 "设备 - 部署 - 应用""系统 - 依赖 -
系统"
等。可以通过定义规则模板匹配文本中的关系描述，也可以采用机器学习的监督学习或半监督学习方法，利用已标注的关系数据训练模型，实现自动关系抽取。此外，还可以结合
CMDB 中已有的关系数据，对抽取结果进行验证和补充 。

属性抽取：抽取实体的属性信息，如服务器的 CPU
型号、内存大小，应用系统的版本号、负责人等。属性抽取可以基于模板匹配或语义分析的方法实现。

##### 知识融合

实体对齐：由于数据来源的多样性，不同数据源中可能存在表示同一实体的不同记录，需要进行实体对齐操作。可以使用基于相似度计算的方法（如编辑距离、余弦相似度）或基于机器学习的方法（如聚类算法、深度学习模型），将表示同一实体的不同记录合并为一个实体，并整合其属性和关系信息。

冲突消解：在融合过程中，可能会出现属性值冲突或关系冲突的情况。对于属性值冲突，可以根据预设的优先级规则（如以
CMDB
中的数据为优先）或通过人工审核来确定最终的属性值；对于关系冲突，需要分析冲突产生的原因，根据实际情况进行调整或补充说明。

##### 知识存储

选择合适的图数据库来存储运维知识图谱，如 Neo4j、JanusGraph
等。图数据库能够高效地存储和查询图结构数据，支持复杂的图遍历和关系查询操作。将抽取和融合后的知识以节点和边的形式存储在图数据库中，节点表示实体，边表示实体之间的关系，并为节点和边添加相应的属性信息。

##### 知识图谱的应用与服务

故障诊断与定位：当发生故障时，通过知识图谱查询与故障相关的实体和关系，分析故障可能的原因和影响范围。例如，根据设备故障信息，查找与之相关的依赖系统、连接设备等，快速定位故障根源。

智能运维决策支持：基于知识图谱中的运维知识和经验，为运维人员提供决策建议。如在进行系统变更或升级时，分析变更可能影响的实体和关系，评估潜在风险，提供合理的变更方案；根据资源使用情况和业务需求，推荐资源优化配置方案。

可视化展示：将运维知识图谱以可视化的方式呈现，使用户能够直观地了解 IT
系统的架构、组件之间的关系以及运维数据的关联。通过交互式界面，支持用户进行节点和关系的查看、筛选、查询等操作，方便用户进行运维分析和管理。

知识检索与问答：提供基于自然语言的知识检索和问答功能，用户可以通过输入自然语言问题，从知识图谱中获取相关的答案和信息。利用
NLP
技术理解用户的问题意图，并在知识图谱中进行查询和推理，返回准确的回答。

##### 知识图谱的更新与维护

实时监测与更新：建立数据监测机制，实时监测 CMDB
和其他运维数据源的数据变化。当有新的数据产生或已有数据发生变更时，及时进行知识抽取、融合和更新操作，确保知识图谱的时效性和准确性。

版本管理：对知识图谱的更新进行版本管理，记录每次更新的内容、时间和操作人员等信息。在需要时，可以回溯到历史版本，查看知识图谱的演变过程。

质量评估：定期对知识图谱的质量进行评估，评估指标包括实体和关系的准确性、完整性、一致性等。根据评估结果，及时发现和解决知识图谱中存在的问题，不断优化知识图谱的质量。

# **系统非功能性需求**

## 性能需求

### 预估的业务量

本系统预估业务量指标如下：

5 个渠道按照新核心指标量进行评估 400 万/5s 业务指标，
200 万/5s 资源指标。按照新核心乘 2 倍的量进行评估，业务指标大概在 800 万/5s，假设单指标在 40 字节左右存储 1 天大概在 5200G 左右，原始指标保留 14 天；降采数据按照 60 的压缩比，单指标在 80 字节左右，一天存储大概在 172G 左右，降采保留 13 个月（入口指标计算）。资源指标大概在 400 万/5s，假设单指标占用在 20 字节左右，存储 1 天大概在 1300G 左右（入口指标计算）。ebpf 采集的指标一天大概存储 1T 左右。对接数据库指标，一天存储大概 60G，保留 30 天，总共 1800G。

任务资源池系统，用户量分别为应用处约 500 个，系统处 300 个，网络和项目约 10 个，总计约 1000 个用户。平台业务数据保存在 pg 数据库中，需要申请一套 8C16G 的 pg 数据库资源。因平台业务需要上传插件文件，按照插件平均 5MB 大小，1000 个用户，每个用户平均上传 100 个插件估计每个服务器需要 1T 的磁盘。综上平台用户量和并发要求不高且平台所需要的计算资源直接使用日志项目已经建设的大数据集群，无需另外申请计算资源。所以使用两台 8C16G 做高可用、可以满足目前和未来一定时间的性能要求。

### 预估带宽

智能运维可观测基础平台提供统一带宽入口，具体带宽需求以业务实际需求为准。

### 性能指标

智能运维可观测基础平台性能指标如下：

1.  根据监控规模的数量，支持快速横向扩展。

2.  支持容器的秒级数据采集能力。

3.  单个 eBPF 探针支持至少 1 万 tps 的高并发指标采集能力。

4.  核心页面响应在每秒 100 并发情况下的处理速度不超过 3 秒。

5.  支持 1000 用户同时登录使用相关功能，系统支持最大并发操作用户数量按最大用户数 50%计算，系统支持并发操作用户数量要求在 500 个。

6.  指标采集数据格式基于 OpenTelemetry 下，代理资源消耗为 CPU 小于等于 10%，内存使用小于等于 200MB。

7.  后台数据处理能力要实现 95%处理实现小于等于 5s，且吞吐能力要达到大于 300 万/s。

8.  数据服务针对时序库数据最新 1 小时数据，API 接口的 QPS 需要达到 800 请求/s。

9.  平台内部各组件之间需要有自监控数据证明时效性、数据准确性。

10. 智能运维可观测基础平台查询最近 1 小时单个集群内的链路、指标数据并完成数据组装返回给业务系统的时间要求在 10 用户情况下 3 秒内返回结果。

11. 应用监控系统的灾备应实现双中心应用双活。数据库进行双中心流复制。平台业务灾备切换 RTO\<=24 小时，RPO\<=2 小时。

12. 平台故障恢复时间要求：平台故障恢复时间为 60 分钟。

13. 平台可用性时间要求：年度平台可用率应达到 99.95%。

14. 运行时间要求:7\*24。

15. 数据备份和恢复的时间在每日晚间系统空闲时处理，如 22:00-次日 6:00 之间，每次最长不应超过 2 小时。

16. 平台自身应用日志需要接入到已有的全行 ELK 平台中，以供后续排查问题。

17. 平台自身需要支持超过 3000 个指标存储、查询要求，各指标类型及数据如下表所示。实际各类监控项采集指标总数会有部分出入。

18. 网络设备关键指标的采集和告警延迟需控制在毫秒级。

19. 监控 Agent 的资源占用需低于设备总资源的 1-5%，避免影响被监控设备性能。

20. 支持 10000 台以上设备各类指标分析报表生成和输出，输出时间不超过 5 分钟.

21. 历史指标和报表数据检索时间小于 5 秒。

22. Kafka Streams 处理能力需达百万级事件/秒。

23. 可同时支持 8000 台交换机 TCP 特征报文数据压缩和存储。

---

监控项 目标实现接入指标数量

---

业务&应用 50

主机 200

数据库 71

中间件 179

容器 1000

云 1400

网络 300

总计 3150

---

## 质量需求

### 可用性

智能运维可观测基础平台需要具备高可用能力，在单个节点出现故障而中断时，能够不间断提供服务功能，不影响整个系统的稳定运行。针对关键数据采取定期备份措施，预防数据丢失。在故障节点中断后，具备告警功能，提醒运维人员及时介入。按照应急预案采用适当的应对措施，恢复至正常状态。

针对平台的健康状况，需定期巡检，发现并解决隐患，提前采取预防措施，从源头上降低故障事件发生概率，从而保证业务的连续性。需借助监控数据的累积，利用监控系统提供的报表功能对数据进行统计处理，帮助用户做出合理决策。

1.  管理可用性：平台采用高可用集群方式部署，保证一定的冗余能力，当某个服务节点发生故障时，能够自动进行故障切换。部署时，支持反亲和特性自动分散到不同服务器节点，平台服务具备自愈能力，平台服务故障时能够自动重启修复。

2.  平台可用性：智能运维可观测基础平台采用主备双中心部署模式，每个中心内的组件均采用高可用架构。有状态组件在两个中心采用主备数据同步，容器平台相关管理程序等无状态组件在两个中心内均作对等部署。当某一中心出现故障，通过切换保持业务连续性。

3.  数据可用性：平台具备自动数据备份能力，当数据存储发生故障时，平台保证不丢失数据。

4.  健壮性：针对关键数据采取定期备份措施，预防数据丢失。在故障节点中断后，具备告警功能，提醒运维人员及时介入。按照应急预案采用适当的应对措施，恢复至正常状态。当出现网络波动、单机硬件故障时，不影响整个系统对外服务连续性。

### 完整性

- 数据完整性

需要保障容器集群数据持久化存储，通过分布式部署及健壮的选主策略保证数据完整性。

- 接口交互完整性

平台通过 Restful
API 接口和其它系统交换数据，不允许其它系统直接访问和修改本系统的数据。需要保障接口报文的完整性。

- 文件传输的完整性

文件传输的完整性需求为保证文件传输的完整。

- 日志和事件的完整性

要求事件持久化及保持日志完整。

### 兼容性

- 系统兼容性：平台内部的各个子模块之间以及与外平台之间要求可以无缝兼容。智能运维可观测基础平台能够在不同的操作系统环境中正常运行和协同工作，包括统信、红旗，并支持适配行内要求的其它版本操作系统。

- 新增子系统：为未来的新产品新技术预留接口，以便平滑的升级换代，充分的利用原有资源。

- 新增外系统：平台应遵循开放标准，通过标准的架构和协议来设计。

### 可维护性

- 智能运维可观测基础平台有关键操作的记录访问信息，如资源创建时间、事件操作类型。

- 对于与环境相关的参数，确保这些环境参数可配置化，放在文件中，便于不同环境的部署管理，配置文件使用专用目录。

- 提供运维操作手册，快速定位系统问题。

- 提供方案满足运维要求，如网络、中间件等。

- 同一个逻辑实体的不同实例的部署无差异。

- 平台可维护性：具备保持系统稳定、减少故障和修复过程中的停机时间、对应用程序进行更新和维护的能力。支持自动化部署和配置、弹性伸缩和扩容、健康检查和自动恢复、版本控制、日志和监控、安全管理、持续集成和交付。

- 业务可维护性：业务在运营过程中，具备良好的可扩展性和可维护性，以便于快速响应市场变化和业务需求的能力。

- 平台提供日常故障处理文档、智能运维可观测基础平台应急预案手册、平台支持人员信息、产品维护手册等，提高业务的维护性。

### 可扩充性

- 系统结构具备灵活的可伸缩性，可以随业务量的增加，通过增加资源来扩充系统的整体处理容量，满足业务不断发展的要求。

- 业务变更时，代码要求具有可扩充性。

- 业务变更时，系统对此变更的支持能力，要求系统具有参数化配置能力。

- 平台需要具备良好的架构，具备插件方式的扩展能力来支持多协议、多模式等，同时需要具备前瞻性，设计良好的 Restful
  API 接口，方便与其它系统平台的对接和新功能开发。其中，Restful
  API 接口有认证规范，并且记录拒绝或者正常请求的链接，能够看到请求链接的请求具体的 ip 和用户信息。

- 支持动态添加监测网络设备，适应数据中心规模增长。

- 要求系统采用组件化、分层设计。

- 支持全维度的横向扩容，在横向扩容过程不会使业务服务能力下降。

### 可管理性

- 应支持通过云管平台纳管智能运维可观测基础平台，具备控件、组件、服务等相关信息的维护。

- 应支持一站式自动化部署和运维智能运维可观测基础平台，具备探针全生命周期管理。

- 可以通过云管平台 Web 界面轻松实现工作负载的扩容和缩容，自由组合策略以应对多变的突发业务流量。

- 通过统一的探针、故障原子库管理，包括创建、编辑、删除、部署、扩展和升级等操作。

### 数据独立性

智能运维可观测基础平台数据需独立于应用，即应用与平台数据分离，互不影响。应用程序无需关心物理数据库的存放位置或方式，只需处理数据的逻辑结构，即使数据的物理存储发生改变，应用程序也无需改变。

### 平台独立性

通过智能运维可观测基础平台北向接口，应用程序或服务可以与平台进行交互通信，而无需关心底层基础设施和操作系统的细节。这种解耦使得应用程序或服务能够独立于底层平台，并且具备更高的可移植性和灵活性，从而实现平台独立性。

## 运维需求

### 监控需求

依据《本行信息系统应用监控通用需求(2023 年)》，智能运维可观测基础平台监控需在监控资源范围、监控指标、监控数据获取等方面满足需求。

1、智能运维可观测基础平台需要支持业务、应用资源、平台组件、网络性能等资源的监控，保证容器集群稳定运行。

1.  提供对容器环境的运行状态监控。

2.  提供容器主机资源运行指标的监控。

3.  提供对应用资源用量、变化趋势统计等指标的监控。

4.  提供平台自身使用中间件的运行状态、资源消耗等监控。

5.  提供对网络侧设备资源运行指标的监控。

2、智能运维可观测基础平台需要提供完整细粒度监控指标采集能力，满足多业务场景需求。

1.  对容器环境的监控指标应覆盖健康检查、cpu 使用率、内存使用率、磁盘使用率、网络流量情况等数据。

2.  对平台组件，包括系统组件和核心组件，提供组件状态、cpu、内存、网络、磁盘等通用指标。

3.  对业务调用关系指标进行采集，辅助业务系统构建业务调用链路关系。

3、智能运维可观测基础平台需要支持配置使用已有的监控采集数据，满足使用已有的监控能力需求。

1.  支持接入已有的监控采集（如 prometheus 技术栈等）配置监控项。

2.  支持将配置的监控项集采完成后，可以在业务系统实时查看关联监控项的变化情况。

3.  支持通过调用分析器接口实现对网络侧设备指标的获取。

4、提供 API 方式获取监控数据，满足场景层业务系统查询监控数据的需求。

5、可视化需求：基于全方位业务指标采集数据，建立业务数据分析模型，通过识别云上业务系统的运行态势，形成业务全链路拓扑。通过下钻分析，对业务系统运行指标数据进行多维度分析展示，实现业务、应用、中间件、数据库、虚拟云平台、容器平台、云平台、基础设施、各组件、网络流量等多角度的统计分析，实现云上业务运行健康情况实时可视化能力。

6、智能运维可观测基础平台通过自身监控指标的综合分析、云平台控制面数据对接、云平台数据面接口探测，实现对具体云产品单个实例的可用性进行实时测算和周期性分析。

7、智能运维可观测基础平台通过监控自身组件信息，系统全方位监控从探针、接收、处理、消息队列、搜索引擎到数据库各层级组件的状态、性能指标、资源使用情况以及事件流转数据，实现对分布式系统各环节深度监控与日志关联分析，确保系统健康与高效运行。

---

**序号** **大类** **监控指标** **指标子项** **指标说明** **指标出处** **备注（注明本期工程是否新增/修改/删除）**

---

1 交易类 交易全流程耗时 交易全流程耗时 ★ 本系统接收到请求到处理完成的交易耗时、采集频率为 60 秒（依据各系统实际情况，重点关注本系统交易的处理耗时，设置超时时长、起始笔数等指标） 行内标准 新增

2 交易类 交易全流程耗时 服务超时监控 应用系统服务处理耗时、采集频率为 60 秒（依据各系统实际情况，单个应用服务的交易处理耗时，设置超时时长、起始笔数等指标） 行内标准 新增

3 交易类 成功率 整体成功率（交易、系统)★ 多中心、失败（交易、系统）响应码、采集频率 10 秒（最长不超过 300 秒）、起始笔数最多不超过 100 笔 行内标准 新增

4 交易类 成功率 中心成功率（交易、系统）★ 单中心、失败（交易、系统）响应码、采集频率 10 秒（最长不超过 300 秒）、起始笔数最多不超过 100 笔 行内标准 新增

5 交易类 成功率 节点服务成功率（交易、系统） 节点、失败（交易、系统）响应码、采集频率 10 秒（最长不超过 300 秒）、起始笔数最多不超过 100 笔 行内标准 新增

6 交易类 成功率 发起方成功率（交易、系统）★ 本系统的发起方、失败（交易、系统）响应码、采集频率 10 秒（最长不超过 300 秒）、起始笔数最多不超过 100 笔 行内标准 新增

7 交易类 成功率 单支交易成功率（交易、系统） 单支交易码、失败（交易、系统）响应码、采集频率 10 秒（最长不超过 300 秒）、起始笔数最多不超过 100 笔 行内标准 新增

8 交易类 成功率 服务方成功率（交易、系统）★ 本系统的服务方、失败（交易、系统）响应码、采集频率 10 秒（最长不超过 300 秒）、起始笔数最多不超过 100 笔 行内标准 新增

9 交易类 成功率 SAF 实时成功率 采集周期 180 秒、取样周期 180 秒、起步计算笔数 100 笔(每个系统根据实际情况可调） 行内标准 新增

10 交易类 交易量环比骤变 发起方交易量环比骤变 本系统的发起方、每 300 秒取近 7 天的同一时段的过去 1800 秒的、平均交易量（去最小和最大值）、工作日环比、节假日环比 行内标准 新增

11 交易类 交易量环比骤变 服务方交易量环比骤变 本系统的服务方、每 300 秒取近 7 天的同一时段的过去 1800 秒的、平均交易量（去最小和最大值）、工作日环比、节假日环比 行内标准 新增

12 交易类 交易量环比骤变 省份交易量环比聚变 省份、每 300 秒取近 7 天的同一时段的过去 1800 秒的、平均交易量（去最小和最大值）、工作日环比、节假日环比 行内标准 新增

13 交易类 交易量环比骤变 异常响应码环比聚变 异常响应码、每 300 秒取近 7 天的同一时段的过去 1800 秒的、平均交易量（去最小和最大值）、工作日环比、节假日环比 行内标准 新增

14 交易类 交易量环比骤变 节点交易量环比聚变 节点、每 300 秒取近 7 天的同一时段的过去 1800 秒的、平均交易量（去最小和最大值）、工作日环比、节假日环比 行内标准 新增

15 交易类 长时间无交易监控 系统长时间无交易 本系统的发起方、末笔交易时间、忙闲时段、节假日 行内标准 新增

16 交易类 长时间无交易监控 中心长时间无交易 单中心、末笔交易时间、忙闲时段、节假日 行内标准 新增

17 交易类 长时间无交易监控 节点长时间无交易 节点、末笔交易时间、忙闲时段、节假日 行内标准 新增

18 交易类 交易统计 交易量统计 应用系统、小时/天、交易量 行内标准 新增

19 交易类 交易统计 告警统计 实时告警、历史告警、分析统计 行内标准 新增

20 交易类 交易统计 交易量峰值趋势 应用系统、天、历史最大交易量 行内标准 新增

21 交易类 交易统计 性能分析统计 应用系统、交易码\\服务名、小时、最大处理时长、最小处理时长、平均时长 行内标准 新增

22 交易类 交易统计 SAF 积压监控 应用系统、采集周期 180 秒、当前 SAF 表内所有"待发送状态"的记录数量 行内标准 新增

23 交易类 系统性能 系统 TPS 监控 应用系统、采集频率 30 秒（最长不超过 300 秒）、交易量 行内标准 新增

24 交易类 系统性能 中心 TPS 监控 单中心、采集频率 30 秒（最长不超过 300 秒）、交易量 行内标准 新增

25 交易类 系统性能 节点 TPS 监控 节点、采集频率 30 秒（最长不超过 300 秒）、交易量 行内标准 新增

26 作业类 文件监控 收发文件 接收时间、接收状态、发送时间、发送状态 行内标准 新增

27 作业类 文件监控 文件处理 处理时长、处理状态、批量文件处理失败率 行内标准 新增

28 作业类 消息监控 消息监控 接收时间、发送时间、发送状态 行内标准 新增

29 作业类 日终监控 日终运行监控 日终最晚发起时间、日终最晚结束时间、步骤最晚发起时间、步骤的最晚完成时间、日终步骤状态、特殊任务（如日切状态） 行内标准 新增

30 配置类 服务数监控 服务数监控 运行的服务数、配置的服务数、差值 行内标准 新增

31 配置类 应用进程监控 应用进程监控 进程状态（正常、异常）、进程数量 行内标准 新增

32 配置类 端口状态监控 端口状态 端口状态（正常、异常） 行内标准 新增

33 配置类 容器监控 容器状态 容器（pod）状态（正常、异常） 行内标准 新增

34 微服务类 微服务访问成功率 服务访问成功率 微服务、Http 状态码、采集频率为 60 秒 行内标准 新增

35 微服务类 微服务访问成功率 接口访问成功率 访问接口、Http 状态码、采集频率为 60 秒 行内标准 新增

36 微服务类 微服务访问超时 微服务服务超时 微服务、超时访问、采集频率为 60 秒（依据各系统实际情况，设置超时时长、起始笔数等指标） 行内标准 新增

37 微服务类 微服务访问超时 微服务接口超时 访问接口、超时访问、采集频率为 60 秒（依据各系统实际情况，设置超时时长、起始笔数等指标） 行内标准 新增

38 中间件类 消息中间件 服务队列 中间件组件（RabbitMQ，RocketMQ、IBMMQ、Kafka、Tuxedo 等）、服务队列长度、服务队列状态、通道数等 行内标准 新增

39 中间件类 消息中间件 实例连通性 中间件组件（RabbitMQ，RocketMQ、IBMMQ、Kafka、Tuxedo 等）、实例状态（正常、异常） 行内标准 新增

40 中间件类 负载中间件 连接状态 中间件组件（Apache、Nginx 等）、等待中连接数、读取连接数、写入连接数、连接状态 行内标准 新增

41 中间件类 Web 中间件 Java 堆内存 中间件组件（Tomcat、Jboss、、Weblogic、Zuul 等） 行内标准 新增

42 中间件类 Web 中间件 实例连通性 中间件组件（Tomcat、Jboss、、Weblogic、Zuul 等） 行内标准 新增

43 中间件类 行内开源软件目录内其它中间件 实例连通性 中间件组件（Nacos、FastDFS、zookeeper 等纳入行内开源软件目录的软件） 行内标准 新增

44 自身类 监控服务状态 服务状态 应用监控平台、程序服务状态（正常、异常） 行内标准 新增

45 自身类 数据处理监控 数据处理服务 应用监控平台、数据处理末笔时间 行内标准 新增

46 自身类 数据采集监控 数据采集服务 应用监控平台、数据采集末笔时间 行内标准 新增

---

### 操作需求

- 日常操作

提供丰富准确的平台使用手册和完善的运维文档等。

- 版本升级

每一次版本升级必须有配套的详细操作手册，无需版本升级人员进行业务判断。

- 定期维护

能够支持 pgsql 中的配置信息需要定期备份，按一定周期进行自动数据备份。

能够支持参数化设置历史数据保留时间，对于过期数据进行自动清理。

能够支持对生产日志进行分级控制，可设定不同的日志输出等级，如调试、一般信息、出错信息等，以便灵活控制日志输出量，如调试时增加日志输出，在生产稳定后使用出错信息输出等级以减少日志输出量。

建立统一日志规范，特别是提供监控使用的监控日志，避免各个系统日志输出无标准、无规范而造成运维监控效率低下。

### 故障处理与恢复

平台必须建立在成熟稳定的硬件环境和应用软件基础上，通过完善的备份恢复策略、可靠的运行管理监控和故障处理手段来保障系统的运行稳定及安全。

1.  针对备份恢复策略，需要对数据和配置进行定期备份。

2.  针对多容器集群，需要提供跨集群的管理，并配套应用的高可用部署。

3.  针对运行管理监控，需要提供多指标的监控，定期巡检，设定合理监控阈值。

4.  针对故障处理手段，需要提供常见问题的应急处理预案和快速处理手册，支持操作员进行异常处理无需进行业务判断，故障发生时能及时恢复。

5.  针对故障定位，根据智能运维可观测基础平台提供的监控、日志、事件、告警等数据，快速准确捕获系统异常信息。

6.  故障处理，提供常见问题快速处理手册，支持操作员进行异常处理无需进行业务判断。

智能运维可观测基础平台提供高质量监控服务，配合业务方容灾和高可用方案设计，保障业务连续性。

## 安全性需求

### 网络层安全需求

- 系统结构安全

1.  应保证关键网络设备的业务处理能力具备 50%的冗余空间，满足业务高峰期需要。

2.  应根据不同用户的工作职能、重要性和所涉及信息的重要程度等因素，划分不同的子网或网段，并按照方便管理和控制的原则为各子网、网段分配地址段。

- 访问控制

1.  支持基于策略的网络控制，用于隔离应用并减少攻击面，每个 Namespace 可以配置独立的网络策略，来隔离 Pod 之间的流量。针对业务容器，可以自定义配置节点端口/负载均衡服务来明确访问控制。

2.  提供访问控制功能，依据安全策略控制用户对受保护资源的访问，确保只有授权用户能够对受保护资源进行访问。

3.  根据用户、业务系统的权限进行授权和访问控制。

4.  采用基于 TLS 认证且非对称加密的方式颁发证书，请求集群 API 时服务端与客户端会互相确认证书合法性。证书时效默认 1 年，同时对证书时效性进行监控，及时对即将过期的证书进行轮换更新。

5.  所有 API 访问均需要经过身份认证之后才能执行，通过身份认证插件利用客户端证书、持有者令牌或身份认证代理来认证 API 请求的身份。

6.  每个通过身份认证的 API 调用都将通过鉴权检查，通过访问控制组件（RBAC）对身份与资源操作权限进行匹配，API 请求属性被所有策略评估允许之后才能继续，否则拒绝该请求。

7.  kubelet 服务作为集群内部服务，整体保护在防火墙内，不对外提供服务。对内的服务通过 TLS 证书与其它组件通信来确保安全。

- 安全审计

应对网络系统中的网络设备运行状况、网络流量、用户行为等进行日志记录。

审计内容描述：审计内容应包括用户名、源 IP 地址、目的 IP 地址、物理地址、协议、操作结果等。对于数据操作，特别是涉及个人敏感信息的操作，包括但不限于采集、查询、修改、删除、下载、导出等关键操作，应形成准确、完整的审计日志。

审计内容保护：对审计日志、文件、数据库进行安全保护、防止恶意删除及修改。日志保存时间应至少 6 个月以上。涉及个人信息、支付清算、反洗钱等国家法律法规和监管要求有特殊要求的，从其规定。

- 备份网络

各数据中心间要求有可实时生效的双备份线路。

### 系统层安全需求

本行需推进以下功能应对智能运维可观测基础平台的常见风险和威胁：

推动智能运维可观测基础平台安全规划：规划包含智能运维可观测基础平台探针安全现状评估，基于云原生安全漏洞和安全事件等分析提炼探针安全防护能力要求，规划容器云安全防护整体架构和具体技术、功能要求，对应安全产品技术路线、工具选型，技术标准制订与发布、建设资源及路径规划等项工作内容。

开展智能运维可观测基础平台安全建设：按照容器云安全防护规划的具体要求，完成智能运维可观测基础平台安全建设。建设可能包含对现有环境或工具的改造、新技术或工具的引进、流程的优化、容器安全基线、人员培训、渗透测试安全评估等项工作内容。

强化智能运维可观测基础平台安全管理：明确容器服务云环境安全管理要求，制订相关管理制度、流程文件，针对环境发生安全威胁、事件的处置，定期的智能运维可观测基础平台安全评估和持续改进等工作内容。

应急服务响应：制订邮储银行智能运维可观测基础平台的安全应急处理预案，保证整个流程严谨而有序。在服务维护过程中，尽最大的努力避免意外情况。并针对不同项目的实施特点，对项目实施的突发风险进行合理预估和详细分析，针对各类突发事件设计相应的预防与解决措施预案，为极端情况下发生的安全问题提供完整的应急处理流程。

### 应用层安全需求

智能运维可观测基础平台通过以下规范措施来确保平台的稳定性和安全性：

1.  访问控制：建立合理的用户权限管理机制，确保只有经过授权的用户可以访问平台内部，根据不同的用户角色权限，对平台的功能和资源进行限制和控制。

2.  日志管理：建立完善的日志管理机制，记录平台的操作日志、异常日志和安全事件日志等，以便于管理人员及时发现和排查潜在问题，并及时进行应对和修复。

3.  配置管理：建立合理的配置管理机制，对平台的各种配置信息、参数和组件进行统一管理和维护，确保配置的正确性和一致性，并避免因配置错误引起的系统故障和安全问题。

4.  健康监测：建立完善的健康监测机制，对平台的各种组件和服务进行实时监测和分析，发现和解决潜在的性能和安全问题，确保平台的可用性和稳定性。

5.  安全防护：建立多层次的安全防护机制，包括网络防护，主机防护、应用防护等，保护平台的安全性和可靠性，避免攻击和侵害。

6.  数据备份：建立完善的数据备份机制，对平台内部的重要数据和配置信息进行备份和恢复，以应对数据丢失或者损坏的情况。

### 数据安全需求

数据安全包括：

1.  支持数据在传输和存储过程中的完整性和防恶意篡改。

2.  支持数据加密，Secret 用来存储敏感的加密信息，包含一个或多个加密的配置文件或配置项，支持键值对和配置文件，实现敏感数据加密存储并对第三方不可见，如用户的账户密码、控制台登录证书、用户的隐私信息等。

3.  支持数据库数据备份与恢复，数据至少保存最近 2 份。

### 业务场景安全需求

1.数据安全性：云监控需要收集、处理和存储大量敏感的业务性能和运营数据，包括但不限于 CPU 使用率、内存占用、网络流量、应用日志等。因此，确保数据在传输过程中的加密以及存储时的加密保护，防止数据泄露或被非法访问，是首要的安全需求。

2.访问控制与身份验证：为了防止未经授权的访问，云监控系统应实施严格的访问控制机制，如基于角色的访问控制(RBAC)、多因素认证等，确保只有经过验证和授权的用户或系统组件才能访问监控数据和配置监控规则。

3.告警与应急响应：在检测到异常或潜在威胁时，能够迅速触发告警并自动执行预定义的应急响应措施，如发送通知给相关人员、启动备份流程或采取其他安全措施，以减少安全事件的影响。

4\.
合规性与审计：对于涉及特定行业规范或法律法规要求的企业，云监控服务需提供符合 GDPR、HIPAA 等标准的数据处理方式，并具备详细的审计日志，记录所有访问和操作行为，以便进行合规审计和追溯。

5\.
高可用性和灾难恢复：云监控系统自身需要具备高可用性设计，确保监控服务不间断。同时，应有相应的灾难恢复计划，确保在遭遇区域性故障或大规模攻击时，监控服务能快速恢复，避免监控盲区。

6\.
隔离性：在多租户环境下，云监控平台需确保不同客户的数据和监控配置相互隔离，防止信息泄露或配置错误导致的交叉影响。

7\.
监控数据的隐私保护：对于含有个人数据或企业敏感信息的监控项目，应实施额外的隐私保护措施，如数据脱敏、匿名化处理等，确保在分析和展示监控结果时不会泄露隐私信息。

# **系统实施方案**

## 总体实施策略

本方案对智能运维可观测基础平台建设划分为四个周期，系统建设内容和目标如下：

第一步（智能运维可观测基础平台部署）：智能运维可观测基础平台技术方案评审，平台部署基础环境确认，智能运维可观测基础平台在测试环境下完成开发及部署；

第二步（云管平台、CMDB 等系统对接）：智能运维可观测基础平台将通过统一、标准化的 API 向上提供接口，与现有的云计算管理平台（简称"云管平台"）进行对接集成；智能运维可观测基础平台同步 CMDB 的权限及应用资产信息，补全平台虚拟机应用的数据。

第三步（业务应用试点）：选取一个项目组，完成智能运维可观测基础平台试点，检验效果。

第四步（业务推广）：逐步新增功能：如扩展流分析功能、扩展会话分析功能、扩展智能排障场景、扩展风险预测分析场景等。
逐步扩大覆盖范围：从云内扩展到云外，从总行推广到分行，逐步实现智能运维可观测基础平台的全网设备覆盖。

总体实施策略采用先局部试点后全面推广的方式，有步骤的投入生产，逐步释放工具能力。

---

序号 系统名称 依赖关系 建设要求

---

1 云计算管理平台 强依赖 按照智能运维可观测基础平台提供的标准 API 进行能力对接，并提供可视化 Web 界面。

2 CMDB 一般依赖 智能运维可观测基础平台同步 CMDB 的权限及应用资产信息，补全平台虚拟机应用的数据，同时 CMDB 需要扩展字段，通过平台补充虚机应用服务信息。

---

## 阶段划分及目标

---

阶段 阶段目标

---

第一阶段 智能运维可观测基础平台基础建设需求分析与确认

第二阶段 智能运维可观测基础平台技术方案

第三阶段 智能运维可观测基础平台详细设计及功能开发

第四阶段 智能运维可观测基础平台对接云管平台、CMDB 等系统

第五阶段 智能运维可观测基础平台准生产试运行

第六阶段 智能运维可观测基础平台正式运行

---

## 阶段实施工作内容

第一阶段

以智能运维可观测基础平台业务需求说明书，并与业务人员，项目实施人员明确本项目实施的设计规范、需求分析功能范围和要求。

第二阶段

基于智能运维可观测基础平台的全栈监控、全栈分析、故障排查、任务资源池管理、日志备份管理、灾备环境演练等平台能力，进行技术方案编制。

第三阶段

本阶段根据需求，系统性的做好详细设计以及开发实现。同时对接数据源系统，完成数据丰富、采集等。

第四阶段

智能运维可观测基础平台建设完毕后，将通过统一、标准化的 API 向上提供接口，与现有的场景层系统对接集成，实现智能运维可观测基础平台初步的查询服务能力。

第五阶段

智能运维可观测基础平台在试运行阶段，将跟踪系统运行状态，对发现的问题阶段性生成问题报告并对问题进行排查，安排人员按改进方案进行整改。当试运行阶段满足系统预期目标时，则系统验收通过。

第六阶段

智能运维可观测基础平台正式上线，统一对应用、中间件、系统等进行监控管理，支持快速构建和运行可弹性扩展的容器化探针，为业务的全链路观测提供支撑。

## 系统体系结构

### 系统逻辑架构

智能运维可观测基础平台逻辑架构说明：智能运维可观测基础平台集成架构设计基于现有各平台的业务流程以及数据接口情况，明确智能运维可观测基础平台与各平台对接的数据内容和步骤，智能运维可观测基础平台同步 CMDB 的资产信息，补全平台虚拟机应用数据。业务系统调用智能运维可观测基础平台，可以获取到聚合指标、eBPF
trace、错误系统数据，通过平台/系统间的深度融合，进一步提升整体运营效率和服务质量，实现信息化建设的战略目标。

![](media/image25.png){width="5.738194444444445in"
height="3.076388888888889in"}

图 6.3 智能运维可观测基础平台逻辑架构

### 系统技术架构

![](media/image26.png){width="5.738194444444445in"
height="4.398611111111111in"}

图 6.4 智能运维可观测基础平台技术架构

系统采用先进的架构设计，紧密贴合信息技术发展趋势及邮储银行 IT 战略规划，实现全程技术自主可控，充分保障系统的前瞻性和安全性。整体系统技术架构分为五个部分：

- 探针层：通过 eBPF 技术采集东西向流量，结合自研日志探针采集资源状态信息以及资源类指标，特点是低侵入性、成本小。

- 数据处理层：接收以及处理端使用消息中间件 Kafka 等进行消峰处理，满足大数据计算场景需求。

- 数据存储层：数据处理完成后写入 VictoriaMetrics、ElasticSearch
  、Starrocks 中，使用 PostgreSQL 存储配置等信息、 Nebula 存储关系数据。

- 应用程序层：后端服务采用 Springboot 和 Flask 等技术，可以提升软件架构的灵活性及可扩展性。

- 展示层：前后端分离，使用 Nginx 负载均衡，请求后台服务交互数据，可以降低前端开发成本，提高易用性。

## 系统间接口

### 系统接口

---

服务请求方 服务提供方 交互过程描述 消息格式 传输协议 传输方式 集成模式

---

云计算管理平台 智能运维可观测基础平台 apiServer 云管平台向智能运维可观测基础平台 apiServer 发起调用请求 K8S 原生 API 接口规范 HTTP 实时 直接调用
、Prometheus API 接口规范

统一监控 智能运维可观测基础平台 通过调用智能运维可观测基础平台数据服务查找对应监控数据 Prometheus Http 实时 直接调用
API 接口规范或标准化 json

智能运维可观测基础平台 CMDB 通过 ESB 或直连 API 获取 CMDB 数据 HTTP 实时 直接调用

智能运维可观测基础平台 云平台 调用云平台监控组件各自 API 或 Kafka 中数据 Prometheus  
 API 接口规范或标准化 json

智能运维可观测基础平台 容器平台 调用容器平台监控组件 Kafka 中数据 Prometheus API 接口规范 实时 直接获取

大数据平台（运维大数据） 智能运维可观测基础平台 直接调用智能运维可观测基础平台 kafka 消息队列中的数据 Prometheus Http 准实时 直接获取
API 接口规范或标准化 json

智能运维可观测基础平台 一体化运维平台 通过页面调用脚本，实现服务启动、停止 Shell 脚本、页面端请求 Web 实时 直接调用

---

### 异常处理

- 通讯异常

在接口调用过程中，如果由于通信异常导致连接中断，由服务使用者负责重新发起连接请求，发送方和接收方需要对报文有重传、查重等异常处理机制。

- 批量文件传输异常

批量接口文件传输过程中，主要处理以下异常情况：

接口数据文件、接口控制文件从数据提供方上传到数据共享系统异常，主要由数据提供方负责处理并作相应重传、补传操作。

在必要的时候，数据提供方和数据共享系统双方须紧密配合并支持对方的工作，共同解决传输异常问题。

- 文件内容异常

接口数据文件和接口控制文件的异常，由数据提供方负责参考文件接口规范以及接口校验报告文件，重新抽取或者修改相应文件内容，必要时修改相应的数据抽取程序，并重传出错的接口数据文件、接口控制文件。

## 灾备方案

### 数据级灾备

智能运维可观测基础平台系统采用数据级灾备建设方式，灾备中心部署和主中心相同的数据库服务，数据层采用一主多从的数据流方式，主中心一主节点两从节点，灾备中心均是从节点，当主节点崩溃时，自动切换到从节点。当主中心的节点全崩溃时，手工切换到灾备中心，将其中一台从节点升级为主节点。当主中心恢复之后，手工切换回主中心。

#### **灾备建设基本指标信息**

+---+---------+-----------------------+-------------------------------+
| 序 | 指 | 指标信息 | 备注 |
| 号 | 标名称 | | |
+===+=========+=======================+===============================+
| 1 | 网 | 第 2 级 | 取值范围： |
| | 络安全 | | |
| | 等级保 | | 第 1 级、第 2 级、第 3 级、 |
| | 护级别 | | |
| | | | 第 4 级、第 5 级。 |
+---+---------+-----------------------+-------------------------------+
| 2 | 灾备建 | 2 级 | 取值范围： |
| | 设等级 | | |
| | | | 1 级、2 级、3 级、4 级、5 级。 |
| | | | |
| | | | 按照《本行 |
| | | | 信息系统灾备恢复能力等级评估 |
| | | | 模型》评估本系统的灾备等级。 |
+---+---------+-----------------------+-------------------------------+
| 3 | 灾备建 | 数据级灾备 | 根据系统灾备建设实际情况选择 |
| | 设模式 | | ：数据级灾备、应用级热备灾备 |
| | | | 、应用双活级灾备、双活级灾备 |
+---+---------+-----------------------+-------------------------------+
| 4 | 系统部 | 边缘计算 | 按照灾备建 |
| | 署情况 | ：数据中心本地化部署 | 设部署方案，选择实际的部署位 |
| | | | 置：丰台、亦庄、廊坊、合肥。 |
| | | 可 | |
| | | 观测应用：北京亦庄（ | |
| | | 主），合肥南岗（备） | |
+---+---------+-----------------------+-------------------------------+
| 5 | 恢 | RTO\<=24 小时 | RTO、RPO 指标要和灾备等级 |
| | 复时间 | | 匹配，在系统性能和资源允许的 |
| | 目标 RTO | RPO\<=2 小时 | 情况下，可以"低级别高建设"。 |
| | | | |
| | 恢复点 | | |
| | 目标 RPO | | |
+---+---------+-----------------------+-------------------------------+

#### **灾备部署模式**

灾备中心(合肥南岗)是数据的物理备份，通过 pg_basebackup 执行数据库基础备份，每 30 秒对归档日志进行检测，当 WAL 日志写满后生成归档后对文件进行增量备份，以达到数据备份。如下图所示：

> ![](media/image27.png){width="4.661111111111111in"
> height="2.9451388888888888in"}

图 6.5 数据库灾备数据传输示意图

当主数据库所在的数据中心遭到破坏全部宕机，可以在灾备中心新建数据库，从备份数据库中通过 pg_dump 回放数据进行恢复。

智能运维可观测基础平台系统通过定时任务脚本将应用部署的介质（包括配置）备份到数据中心的备份机上，当前节点被破坏时，可实现新建节点从备份机上拉取对应的介质和配置进行应用服务的恢复。

#### **数据同步方案**

数据库集群通过 corosync+pacemaker 来管理，部署采用主+同步流复制+异步流复制以满足数据库高可用使用，如下图所示。

> ![](media/image28.png){width="3.6458333333333335in"
> height="2.298611111111111in"}
>
> 图 6.6 数据库主从同步模式

当主数据库（A）发生故障时，接收同步复制的从数据库（B）提升为主数据库，开始接管主的工作，而异步复制从数据库（C）转为同步复制；如下图所示：

![](media/image29.png){width="3.486111111111111in"
height="2.951388888888889in"}

> 图 6.7 主库宕机

当数据库（A）恢复后，数据库（A）成为数据库（B）的异步备库。

![](media/image30.png){width="3.2847222222222223in"
height="2.6319444444444446in"}

图 6.8 数据库恢复

## 数据迁移实施方案

### 数据迁移总体策略

无数据迁移需求。

### 数据差异分析

无数据迁移需求。

### 迁移方案说明

无数据迁移需求。

### 数据迁移程序开发

无数据迁移需求。

### 迁移测试方案

无数据迁移需求。

### 上线演练

无数据迁移需求。

### 切换上线及验证

无数据迁移需求。

### 应急预案

无数据迁移需求。

## 软硬件资源需求

### 软硬件配置原则

#### **业务系统主机设备要求**

智能运维可观测基础平台可构建于物理裸金属服务器、虚拟机、容器云平台等基础设施环境上，根据信息处理量和交换量的大小决定其配置规模。平台建设要充分利用现有的软硬件资源，同时也应考虑建设带来的必要软硬件设备投资。

#### **主机配置应当满足以下条件**

1.  满足平台的功能要求和最繁忙时业务处理的需要。

2.  满足实时处理和批量处理对平台资源占用的要求。

3.  满足不同业务对平台响应时间的要求。

4.  满足业务信息存储容量的要求。

5.  配置经济合理，系统维护方便。

6.  在设计年限内，服务器主机系统的磁盘利用率最大不超过 75%。

7.  服务器要考虑使用主流机型。

8.  服务器应具有较大的扩充能力和灵活的扩充方式，须保证系统能够在规模和性能两个方面向上扩展，以保证未来不断发展的要求，支持整个服务器系统的无间断扩充。服务器需 7×24 小时连续运行，因而要求其具有极高的安全可靠性和稳定性。

9.  具备开放性、高可用性、高可靠性、先进性和安全性。

10. 风扇、电源等应有冗余备份。

#### **磁盘阵列应满足以下条件**

1.  要求与主机服务器兼容，确保其能与主机服务器无误连接，并确保双机切换时的正确接管，保证数据的安全。

2.  阵列应支持 FC、IB、IP 等多种通道接口类型。

3.  磁盘平均无故障时间 ≥100 万小时。

4.  厂商具备经验证适配过的 CSI 驱动文件。

5.  阵列配置至少 4 个以上光纤通道接口。

6.  在管理软件支持下可以实现磁盘数据的在线（不停机）备份，保证系统 7×24 小时运行。

7.  电源、风扇等应有冗余备份。

8.  支持数据的远程拷贝。

### 系统软件配置要求

系统软件配置原则要符合软件体系结构的相关要求。在选用分布式存储、镜像服务、数据库等开源产品时，应尽量考虑开源软件的成熟度和稳定性。

### 软硬件配置分析

#### **系统技术指标分析**

智能运维可观测基础平台支持根据监控规模自动横向扩缩容，为满足所需业务、技术要求，考虑主机系统的技术指标主要有三项：CPU 用量、内存容量和硬盘容量。

#### 处理能力

业务集中处理型主机系统处理能力表现为单位时间完成交易的能力（简称并发处理能力）。按目前全国业务的需求及发展，主机处理能力要求如下：

主机联机处理能力：

根据邮政储蓄工程设计规范中的主机处理能力公式：

主机处理能力（TPMC）按下列公式计算：

![](media/image31.wmf){width="1.49375in" height="0.6104166666666667in"}

其中 P── 主机处理能力，单位为每分钟处理的交易量（tpmC）；

m1── 预测近期年的日均交易量，单位为笔；

ε1── 忙日集中系数，取 2 ～ 5； （此处取值 4） 5

ε2── 忙时集中系数，取 0.2 ～ 0.25；（此处取值 0.25） 0.25

K1── 平均交易复杂度； （此处取值 15） 20

J1── 主机处理能力保留系数，取 0.7。0.8

根据公式算出 P≈70 万 tpmC

按照业界的经验值，应用服务器的处理能力为数据库服务器的处理能力的 50％计算，数据库服务器处理能力为 140 万 tpmc。

#### **内存容量**

内存容量选择时还要考虑到主机正常运行时，内存利用率不应大于 70%，才能保证系统在业务高峰时正常运行；其次是考虑内存容量应与主机系统 CPU、I/O 吞吐能力相匹配，不同厂商的主机系统需求不同。

一般按照一个 CPU 配置 2-4G 内存，具体配置由 CPU 速度与内存速度决定。

#### **磁盘容量**

ebpf 采集数据主要存储在 ES 中，预估单中心一天产生 1T 的数据，如果是保存 365 天，则需要 365T 的磁盘。业务指标存储大概 1 天需要 5200G，365 天大概需要
1853T。资源指标占用 1300G，30 天预计需要 38T 的磁盘。

5 个渠道按照新核心指标量进行评估 400 万/5s 业务指标，
200 万/5s 资源指标。按照新核心乘 2 倍的量进行评估，业务指标大概在 800 万/5s 假设单指标在 40 字节左右存储 1 天大概在 5200G 左右，原始指标保留 14 天，总共 71T；降采数据按照 60 的压缩比，单指标在 80 字节左右，一天存储大概在 172G 左右，降采保留 13 个月，总共 67T。原始指标和降采数据一共需要 138T，存储在时序数据库中，按照压缩比 1:10 的压缩比，需要 14T。

资源指标大概在 400 万/5s，假设单指标占用在 20 字节左右，存储 1 天大概在 1300G 左右（入口指标计算）,保留 14 天，需要 18T。

ebpf 采集的指标一天大概存储 2T 左右；
Trace 数据一天产生 865G，Trace 数据保留 7 天，需要 6T；原始指标数据一天大概在 1183G，保留 14 天，总共 153T，降采数据按照 1:5 的压缩比，则降采数据 1 天需要 237G，保留 13 个月，共需 93T。

对接数据库指标，一天存储大概 60G，保留 30 天，总共 1800G。

任务资源池数据分为文件和业务数据，业务数据保存在 pg 数据库中，我们申请本行数据库资源，不单独部署。文件数据有集群相关的配置文件和用户上传的自定义插件，按照插件平均 5MB 大小，1000 个用户，每个用户平均上传 100 个插件估计每个服务器需要 1T 的磁盘。

### 软硬件配置方案

#### **系统应用软件**

智能运维可观测基础平台为云原生基础设施平台，该平台为采购成熟产品，因此各类系统软件选型需根据厂商产品情况具体提供。在选用各类应用软件时，应尽量考虑利用开源软件列表中软件选型及版本。

---

**应用软件名称** **软件版本** **用途** **软件分类（开源软件/通用软件）** **是否包含在行内产品目录** **备注**

PostgreSQL 15.6 业务数据库 开源软件 是 如行内基线有变化，以行内基线为准

Nginx 1.23.2 http 服务器 开源软件 是

Redis 7.0.15 缓存数据库 开源软件 是

VictoriaMetrics 1.93.9 时序数据库 开源软件 是

Flink 1.15.2 流式数据处理 开源软件 是

Kafka 3.7.0 分布式消息系统 开源软件 是

Grafana 10.1.2 监控 dashboard 系统 开源软件 是

Prometheus 2.45.3 监控系统 开源软件 是

Haproxy 2.4.25 负载均衡系统 开源软件 是

ElasticSearch 8.11.4 数据存储 开源软件 是

---

#### **全国中心配置建议**

智能运维可观测基础平台与云平台一体化建设，智能运维可观测基础平台建设基于虚机、物理机、容器形态，其中物理机规格与云平台保持一致，虚机统一采用 32C64GB 规格。软硬件配置表见下表：

---

**用途** **资源类型** **模型** **配置** **操作系统** **部署软件** **数量** **部署地点** **备注**

可观测 计算资源 虚机模型 2 16vCPU、32GMem 麒麟 V10SP2 前后端、配置中心 200 合肥 虚拟机

探针数据接收端 计算资源 虚机模型 3 32vCPU、64GMem 麒麟 V10SP2 数据接收、数据处理 600 合肥 虚拟机

业务数据接收端 计算资源 虚机模型 1 8vCPU、16GMem 麒麟 V10SP2 业务指标、资源指标接收 1200 合肥 虚拟机

中间件 计算资源 虚机模型 1 32vCPU、64GMem 麒麟 V10SP2 中间件 700 合肥 虚拟机

数据库 计算资源 虚机模型 2 32vCPU、64GMem 麒麟 V10SP2 数据库 1200 合肥 虚拟机

探针 计算资源 虚机模型 2 2C4G 麒麟 V10SP2 eBPF agent 每个节点部署一个 合肥 虚拟机

动态基线处理 计算资源 虚机模型 2 32vCPU、64GMem 麒麟 V10SP2 动态基线模块 60 合肥 虚拟机

负载均衡器 计算资源 虚机模型 3 32vCPU、64GMem 麒麟 V10SP2 软负载均衡 48 合肥 虚拟机

存储 存储资源 时序数据库 麒麟 V10SP2 高性能时序数据库 13PB 磁盘 合肥

                   存储资源                   非关系型数据库   麒麟V10SP2     数据库                   10PB磁盘           合肥

---

## 系统部署要求

北京建设主库，合肥建设备库，整合全局数据，同时在北京等地数据中心，授权账户可登录任意中心的系统。

每个中心部署 1 套可观测系统集群，系统部署在云平台上，以虚拟机+容器的方式运行。

可观测系统通过消息总线实现应用集群、计算集群、存储集群、大数据集群等各个子模块的连接，并通过物理网络通道与外部数据源以及关联系统连接；

智能运维可观测基础平台高可用架构如下图所示：

![](media/image32.png){width="5.738194444444445in"
height="3.972916666666667in"}

## 分行实施推广

1.  不涉及

## 项目组织

![](media/image33.emf)

软件开发与测试阶段组织结构图

1.  项目领导小组

由参与工程的各方领导组成，对项目的重大事件进行决策并对项目全过程进行监督及协调。

2.  工程项目组

负责整个项目的实施，组织、协调并监督各工程小组的工作情况及进度，对项目领导小组负责，对具体方案具有决定权。

3.  专家顾问组

提供对系统规划、系统分析和技术咨询服务。

4.  质量控制组

该小组直接对软件开发项目组负责，对应用程序设计编制及测试过程、内容、结果等各种项目质量要素进行过程控制和阶段复审，具有质量否决权。

5.  业务需求组

负责制定本项目涉及的业务需求，并对业务需求的内容变更负责。

6.  总体组

由相关的技术专家组成，负责所有系统的需求分析、系统设计、技术管理、组织与项目开发有关的技术培训以及对开发小组的协调等工作。

7.  开发小组

按照设计文档的要求，完成相关设备的软件配置、流程编码、与各核心业务系统接口编码等工作并产生相关的开发和配置文档。

8.  系统组

负责设备到货，各服务器、网络设备、系统软件的集成、集成环境的测试、软件的安装和性能调试。

9.  测试组

严格按照业务需求及相关文件，编写测试计划和测试案例，完成系统的功能测试、性能测试以及联调测试，测试结束后，提交测试报告，并完成修改后的再测试。

10. 文档管理组

负责在整个项目过程中的所有文档、资料、技术报告、软件介质的汇总管理，监督和跟踪其它项目小组提交的文档。

11. 后勤组

负责合同管理、材料管理、安全保证、后勤保障和其它部门的各种协调工作。

12. 工程协调组

负责跟其它外接系统的工程协调，主要是与业务系统的工程协调。

## 项目里程碑计划

---

任务名称 开始时间 完成时间

---

工程启动 2025 年 5 月 31 日 2025 年 6 月 10 日

需求分析 2025 年 6 月 11 日 2025 年 7 月 31 日

系统设计 2025 年 7 月 1 日 2025 年 7 月 31 日

软件开发 2025 年 8 月 1 日 2026 年 6 月 1 日

系统测试 2025 年 10 月 1 日 2026 年 5 月 31 日

系统上线 2026 年 3 月 1 日 2026 年 6 月 30 日

---

## 问题和风险

无
