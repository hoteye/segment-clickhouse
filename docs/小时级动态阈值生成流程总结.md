# 基于 events 表的小时级动态阈值生成流程总结

## 📋 概述

本文档详细记录了当前工程中通过分析 `events` 表中历史原始交易数据，并按小时进行信息汇总生成告警阈值的完整技术流程。该系统实现了从历史数据分析到实时告警的智能化闭环，具备小时级精度的差异化阈值策略。

## 🏗️ 整体架构流程图

```mermaid
graph TD
    A[Segment数据流] --> B[EventsClickHouseSink]
    B --> C[events表]
    
    D[EventsBasedThresholdGenerator] --> E[分析前7天events数据]
    E --> F[按小时分组统计]
    F --> G[生成24小时阈值规则]
    G --> H[hourly_alarm_rules表]
    
    I[HourlyRulePublishProcessFunction] --> J[定时读取当前小时规则]
    J --> K[推送到Kafka alarm_rule_topic]
    K --> L[RuleBroadcastStreamFactory广播流]
    L --> M[AggAlertBroadcastFunction热更新]
    
    C --> D
    H --> I
    M --> N[实时告警判断]
    
    style A fill:#e1f5fe
    style C fill:#f3e5f5
    style H fill:#f3e5f5
    style N fill:#ffebee
    style D fill:#e8f5e8
    style M fill:#fff3e0
```

## 🗄️ 1. 数据收集阶段

### 核心表结构：events

```sql
CREATE TABLE events (
    start_time    DateTime64(3),     -- 请求开始时间
    end_time      DateTime64(3),     -- 请求结束时间
    service       String,            -- 服务名
    operation_name String,           -- 操作名称
    span_type     String,            -- Span类型
    is_error      UInt8,             -- 是否错误 (0=成功, 1=失败)
    -- 其他字段...
) ENGINE = MergeTree()
ORDER BY (start_time);
```

### 数据写入流程

1. **数据源**：Flink消费Kafka中的Segment数据流
2. **原始存储**：通过 `EventsClickHouseSink` 直接写入ClickHouse的 `events` 表
3. **数据特点**：保存完整的原始交易数据，包含详细的请求信息

### 关键代码组件

- **数据写入**：`com.o11y.stream.sink.EventsClickHouseSink`
- **数据特点**：原始数据，包含完整的请求开始和结束时间

## 📈 2. 数据分析与阈值生成阶段

### 核心组件

- **生成器**：`EventsBasedThresholdGenerator` - 实现基于原始数据的智能阈值算法

### 分析SQL查询

```sql
SELECT 
    toHour(start_time) as hour_of_day,  -- 按小时分组 (0-23)
    service, 
    operation_name as operator_name,
    -- 计算响应时间（毫秒）- 使用正确的时间差计算
    avg((end_time - start_time) * 1000) as avg_duration,
    max((end_time - start_time) * 1000) as max_duration,
    quantile(0.75)((end_time - start_time) * 1000) as duration_p75,
    quantile(0.90)((end_time - start_time) * 1000) as duration_p90,
    quantile(0.95)((end_time - start_time) * 1000) as duration_p95,
    quantile(0.99)((end_time - start_time) * 1000) as duration_p99,
    -- 计算成功率和错误率
    sum(is_error) / count(*) as error_rate,
    1 - (sum(is_error) / count(*)) as success_rate,
    -- 统计信息
    count(*) as total_count,
    sum(is_error) as error_count,
    count(*) - sum(is_error) as success_count,
    -- 标准差
    stddevSamp((end_time - start_time) * 1000) as duration_std
FROM events 
WHERE start_time >= now() - INTERVAL ? DAY  -- 默认分析前7天
AND start_time < now() 
AND service IS NOT NULL 
AND operation_name IS NOT NULL 
AND is_error = 0  -- 只统计成功的请求
AND (end_time - start_time) * 1000 < ?  -- 过滤异常长的响应时间（60秒）
AND (end_time - start_time) > 0  -- 过滤负数响应时间
GROUP BY hour_of_day, service, operator_name 
HAVING total_count >= ?  -- 保证样本充足性（至少10条）
ORDER BY hour_of_day
```

### 智能阈值算法

#### 三级阈值计算策略

```java
// 小时级特征调整因子
HourlyAdjustmentFactor factor = getHourlyAdjustmentFactor(hourOfDay);

// 基于分位数设置阈值，更加科学合理
// LOW: 基于P75，轻微异常
// MID: 基于P90，中度异常  
// HIGH: 基于P95，严重异常
rule.avgDurationLow = max(durationP75 * factor.avgDurationFactor, avgDuration * 1.2);
rule.avgDurationMid = max(durationP90 * factor.avgDurationFactor, avgDuration * 1.5);
rule.avgDurationHigh = max(durationP95 * factor.avgDurationFactor, avgDuration * 2.0);

// 最大延迟阈值（基于P99和标准差）
rule.maxDurationLow = max(durationP90 * factor.maxDurationFactor, maxDuration * 1.1);
rule.maxDurationMid = max(durationP95 * factor.maxDurationFactor, maxDuration * 1.3);
rule.maxDurationHigh = max(durationP99 * factor.maxDurationFactor, maxDuration * 1.5);

// 成功率阈值（已经过滤了失败交易，这里设置更严格的阈值）
rule.successRateLow = min(successRate * 0.99, 0.99);
rule.successRateMid = min(successRate * 0.97, 0.97);
rule.successRateHigh = min(successRate * 0.95, 0.95);

// 交易量阈值（基于历史均值）
rule.trafficVolumeLow = totalCount * 1.5 * factor.trafficVolumeFactor;
rule.trafficVolumeMid = totalCount * 2.0 * factor.trafficVolumeFactor;
rule.trafficVolumeHigh = totalCount * 3.0 * factor.trafficVolumeFactor;
```

#### 小时特征识别

| 时段类型 | 小时范围 | 阈值策略 | 调整因子 |
|---------|---------|---------|---------|
| **高峰期** | 9-11, 14-16, 20-22点 | 阈值相对宽松 | factor > 1.0 |
| **低峰期** | 0-6点 | 阈值相对严格 | factor < 1.0 |
| **平峰期** | 其他时段 | 标准阈值 | factor = 1.0 |

#### 数据过滤策略

1. **成功请求过滤**：`is_error = 0` 只统计成功的请求
2. **异常时间过滤**：`(end_time - start_time) * 1000 < 60000` 过滤超过60秒的异常请求
3. **负数时间过滤**：`(end_time - start_time) > 0` 过滤时间计算错误的数据
4. **样本充足性**：`total_count >= 10` 确保有足够的样本进行统计分析

#### 多维度阈值覆盖

1. **平均延迟阈值**：基于P75/P90/P95分位数
2. **最大延迟阈值**：基于P90/P95/P99分位数，识别慢请求异常
3. **成功率阈值**：基于历史成功率，监控服务可用性（低于阈值告警）
4. **交易量阈值**：基于历史均值，检测流量激增（高于阈值告警）

## 🗃️ 3. 规则存储阶段

### 规则表结构：hourly_alarm_rules

```sql
CREATE TABLE hourly_alarm_rules (
    hour_of_day UInt8,               -- 小时序号 (0-23)
    service String,                  -- 服务名
    operator_name String,            -- 操作员名
    operator_class String,           -- 操作员类
    
    -- 多级阈值（高中低三档）
    avg_duration_low Float64,        -- 平均延迟低阈值
    avg_duration_mid Float64,        -- 平均延迟中阈值
    avg_duration_high Float64,       -- 平均延迟高阈值
    max_duration_low Float64,        -- 最大延迟低阈值
    max_duration_mid Float64,        -- 最大延迟中阈值
    max_duration_high Float64,       -- 最大延迟高阈值
    success_rate_low Float64,        -- 成功率低阈值
    success_rate_mid Float64,        -- 成功率中阈值
    success_rate_high Float64,       -- 成功率高阈值
    traffic_volume_low Float64,      -- 交易量低阈值
    traffic_volume_mid Float64,      -- 交易量中阈值
    traffic_volume_high Float64,     -- 交易量高阈值
    
    alarm_template String,           -- 告警模板
    analysis_days UInt8,             -- 分析的历史天数
    sample_count UInt32,             -- 样本数量
    generated_time DateTime,         -- 规则生成时间
    last_updated DateTime,           -- 最后更新时间
    version UInt32,                  -- 规则版本号
    
    PRIMARY KEY (hour_of_day, service, operator_name)
) ENGINE = MergeTree()
ORDER BY (hour_of_day, service, operator_name);
```

### 存储特点

- **完整覆盖**：每个服务+算子组合生成24条记录（每小时一条）
- **数据一致性**：支持批量清理和重新生成
- **元数据丰富**：包含样本数量、生成时间等便于运维调试
- **版本管理**：支持规则版本控制和回滚

## ⏰ 4. 定时下发阶段

### 核心组件：HourlyRulePublishProcessFunction

基于Flink的ProcessFunction + Timer机制实现精确的整点触发。

#### 工作流程

```java
// 每小时整点触发的核心逻辑
public void onTimer(long timestamp, OnTimerContext ctx, Collector<String> out) {
    int currentHour = LocalDateTime.now().getHour();
    
    // 1. 查询当前小时的所有规则
    Map<String, AlarmRule> ruleMap = loadHourlyRules(currentHour);
    
    // 2. 推送到Kafka实现热更新
    publishRulesToKafka(ruleMap, currentHour);
    
    // 3. 注册下一个小时的定时器
    long nextCheckTime = calculateNextCheckTime();
    ctx.timerService().registerProcessingTimeTimer(nextCheckTime);
}
```

#### 查询当前小时规则

```sql
SELECT service, operator_name, operator_class,
       avg_duration_low, avg_duration_mid, avg_duration_high,
       max_duration_low, max_duration_mid, max_duration_high,
       success_rate_low, success_rate_mid, success_rate_high,
       traffic_volume_low, traffic_volume_mid, traffic_volume_high,
       alarm_template
FROM hourly_alarm_rules 
WHERE hour_of_day = ?
```

#### 定时机制特点

- **精确触发**：基于Flink Timer的毫秒级精度
- **故障恢复**：支持Flink checkpoint和状态恢复
- **避免重复**：使用ValueState记录上次执行时间
- **自动循环**：每次执行后自动注册下次定时器

## 🔄 5. 热更新与实时告警阶段

### 广播流架构

#### Kafka Topic配置

**Topic**: `alarm_rule_topic`

**关键配置**：
```properties
# 启用Log Compaction策略
cleanup.policy=compact
min.cleanable.dirty.ratio=0.1
segment.ms=60000
delete.retention.ms=86400000
partitions=1
```

#### 消费策略

- **起始位置**：`earliest()` 确保启动时获取最新规则
- **消费组**：`alarm-rule-consumer-group` 固定消费组管理offset
- **并行度**：单并行度确保规则消费顺序性

### 广播流处理

#### RuleBroadcastStreamFactory

```java
// 构建规则广播流的核心方法
public static BroadcastStream<Map<String, AlarmRule>> buildRuleBroadcastStream(
        StreamExecutionEnvironment env,
        Map<String, String> kafkaConfig,
        MapStateDescriptor<String, Map<String, AlarmRule>> ruleStateDescriptor) {
    
    // 从Kafka构建数据源
    KafkaSource<Map<String, AlarmRule>> ruleSource = KafkaSource
        .<Map<String, AlarmRule>>builder()
        .setBootstrapServers(kafkaConfig.get("bootstrap_servers"))
        .setTopics(kafkaConfig.get("alarm_rule_topic"))
        .setGroupId(kafkaConfig.get("alarm_rule_group_id"))
        .setStartingOffsets(OffsetsInitializer.earliest())
        .setDeserializer(new AlarmRuleDeserializationSchema())
        .build();
    
    // 创建广播流
    return env.fromSource(ruleSource, WatermarkStrategy.noWatermarks(), "alarm-rule-source")
              .setParallelism(1)
              .filter(Objects::nonNull)
              .broadcast(ruleStateDescriptor);
}
```

#### AggAlertBroadcastFunction热更新

```java
// 实时告警判断的核心逻辑
public void processElement(ServiceAggResult value, ReadOnlyContext ctx, Collector<AlertMessage> out) {
    String key = value.getKey(); // service|operatorName
    Map<String, AlarmRule> ruleMap = ctx.getBroadcastState(ruleStateDescriptor).get("all_rules");
    
    if (ruleMap != null) {
        AlarmRule rule = ruleMap.get(key);
        if (rule != null) {
            AlertMessage alert = buildAlertReport(rule, value);
            out.collect(alert);
        }
    }
}

// 规则热更新处理
public void processBroadcastElement(Map<String, AlarmRule> ruleMap, Context ctx, Collector<AlertMessage> out) {
    // 使用固定key存储规则映射，实现热更新
    ctx.getBroadcastState(ruleStateDescriptor).put("all_rules", ruleMap);
    
    if (ruleMap != null && !ruleMap.isEmpty()) {
        LOG.info("[热更新] 收到新规则消息，规则总数：{}，keys：{}", 
                ruleMap.size(), ruleMap.keySet());
    }
}
```

### 告警级别判断

#### 多指标多级阈值分析

```java
// 平均延迟告警判断
if (rule.avgDurationHigh != null && value.avgDuration != null && 
    value.avgDuration > rule.avgDurationHigh) {
    conclusion.append("[HIGH] 平均延迟超过高阈值，建议立即排查服务性能瓶颈。\n");
    alertLevel = "HIGH";
    triggered = true;
} else if (rule.avgDurationMid != null && value.avgDuration != null && 
           value.avgDuration > rule.avgDurationMid) {
    conclusion.append("[MID] 平均延迟超过中阈值，建议关注服务近期变更。\n");
    alertLevel = "MID";
    triggered = true;
} else if (rule.avgDurationLow != null && value.avgDuration != null && 
           value.avgDuration > rule.avgDurationLow) {
    conclusion.append("[LOW] 平均延迟超过低阈值，建议持续观察。\n");
    alertLevel = "LOW";
    triggered = true;
}

// 成功率告警判断（低于阈值告警）
if (rule.successRateHigh != null && value.errorRate != null && 
    (1 - value.errorRate) < rule.successRateHigh) {
    conclusion.append("[HIGH] 成功率低于高阈值，建议立即排查异常原因。\n");
    alertLevel = "HIGH";
    triggered = true;
}

// 交易量告警判断（高于阈值告警）
if (rule.trafficVolumeHigh != null && value.totalCount != null && 
    value.totalCount > rule.trafficVolumeHigh) {
    conclusion.append("[HIGH] 交易量高于高阈值，建议关注流量激增原因。\n");
    alertLevel = "HIGH";
    triggered = true;
}
```

## 🎯 关键特性总结

### 1. 基于原始数据的智能化阈值

- **数据源优势**：直接基于 `events` 原始表，数据更准确完整
- **精确过滤**：只统计成功请求，避免失败请求对阈值的影响
- **异常过滤**：过滤异常长的响应时间和负数时间，提高数据质量
- **统计学基础**：使用P75/P90/P95/P99分位数确保阈值的统计意义

### 2. 小时级精度

- **业务感知**：识别高峰期、低峰期、平峰期的不同特征
- **差异化策略**：针对不同时段采用差异化阈值倍数
- **精确触发**：整点下发对应时段的专门规则

### 3. 零停机更新

- **Broadcast State**：基于Flink广播状态的分布式热更新
- **状态一致性**：确保所有并行实例同步更新规则
- **无中断服务**：规则更新过程中告警服务持续运行

### 4. 数据可靠性

- **Log Compaction**：Kafka压缩策略保证规则数据持久化
- **Earliest策略**：确保消费者启动时获取最新有效规则
- **故障恢复**：支持Flink checkpoint和自动恢复

### 5. 运维友好

- **完整日志**：每个环节都有详细的监控日志
- **状态管理**：支持规则版本控制和状态查询
- **异常处理**：完善的异常处理和降级机制

## 📊 性能与扩展性

### 数据量估算

- **历史数据**：分析前7天数据，支持千万级记录查询
- **规则数量**：每个服务-算子组合24小时规则，支持万级规则管理
- **实时处理**：毫秒级规则匹配，支持万级TPS实时告警

### 扩展能力

- **新指标扩展**：表结构和算法支持新监控指标
- **新算子接入**：统一的算子注册机制
- **多集群部署**：支持多数据中心和多环境部署

## 🔧 运维建议

### 监控指标

1. **规则生成监控**：监控每日规则生成成功率和耗时
2. **下发延迟监控**：监控规则从生成到生效的延迟
3. **告警准确性**：监控告警的准确率和误报率
4. **系统资源**：监控ClickHouse查询性能和Kafka延迟

### 调优建议

1. **样本数量调整**：根据业务量调整最小样本要求（当前10条）
2. **分析周期调整**：根据业务稳定性调整历史分析天数（当前7天）
3. **阈值敏感度**：根据告警效果调整阈值计算参数
4. **异常时间阈值**：根据业务特点调整最大响应时间过滤阈值（当前60秒）

---

## 📝 变更记录

| 版本 | 日期 | 变更内容 | 作者 |
|------|------|----------|------|
| 1.0 | 2024-12-19 | 初始版本，基于flink_operator_agg_result表 | AI Assistant |
| 2.0 | 2024-12-19 | 更新为基于events表的实现 | AI Assistant |

---

**文档状态**：✅ 当前版本  
**最后更新**：2024-12-19  
**适用版本**：EventsBasedThresholdGenerator 实现 